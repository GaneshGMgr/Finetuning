# Fine-Tuning Repository

Welcome to the **Fine-Tuning Repository** — a curated collection of notebooks, scripts, and resources dedicated to fine-tuning a variety of deep learning models using popular frameworks such as Hugging Face Transformers and Keras.

---

## Repository Overview

This repository aims to provide practical, hands-on examples and detailed explanations on how to adapt pretrained models to specific tasks across multiple architectures including transformer-based models (BERT, Llama 2, Mistral), as well as classical models like LSTM and CNN. Whether you are new to fine-tuning or looking for advanced techniques, this repository serves as a comprehensive resource.

---

## Contents

### Notebooks

- **BERT_Finetuning.ipynb**  
  A thorough walkthrough on fine-tuning BERT models for NLP tasks using Hugging Face. Covers tokenization, dataset prep, training, and evaluation steps.

- **Fine_Tuning_with_Mistral_QLora_PEFt.ipynb**  
  Demonstrates advanced fine-tuning methods on Mistral models leveraging QLoRA and PEFT for parameter-efficient training.

- **Pretrained_Model_Deeplearning.ipynb**  
  Introduces pretrained deep learning models and explains fundamentals of transfer learning.

- **Why_finetuning_was_challanging_in_LSTM.ipynb**  
  Discusses challenges and solutions encountered when fine-tuning LSTM architectures.

- **huggingface_crash_course.ipynb**  
  A beginner-friendly crash course focusing on Hugging Face Transformers—model loading, tokenization, and training basics.

- **transfer_learning_finetuning_cnn.ipynb**  
  An example workflow for transfer learning and fine-tuning CNNs on custom datasets.

---

### Folders / Projects

- **Fine-tune_Gemma_Models_Keras**  
  Contains scripts and notebooks specifically for fine-tuning Gemma models using Keras.

- **Fine_tune_Llama_2_Model**  
  Resources and notebooks focused on fine-tuning Llama 2 models.

---
