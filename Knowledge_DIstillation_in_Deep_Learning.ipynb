{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sunnysavita10/Complete-LLM-Finetuning/blob/main/Knowledge_DIstillation_in_Deep_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzverclTnOYi"
      },
      "source": [
        "# Step-by-step Explanation — Knowledge Distillation (Teacher → Student) on MNIST\n",
        "\n",
        "Reference: [Distilling the Knowledge in a Neural Network (Hinton et al., 2015)](https://arxiv.org/pdf/1503.02531)\n",
        "\n",
        "# Knowledge Distillation Explained \n",
        "\n",
        "This explains **Knowledge Distillation** — a way to train small, efficient models (students) by learning from big, powerful models (teachers).\n",
        "\n",
        "---\n",
        "\n",
        "## What is Knowledge Distillation?\n",
        "\n",
        "Knowledge Distillation is a technique where a **small model (student)** learns from a **large, well-trained model (teacher)** to get similar accuracy but with less computational cost.\n",
        "\n",
        "---\n",
        "\n",
        "## Key Concepts\n",
        "\n",
        "### 1. Ground Truth Labels (Hard Labels)\n",
        "\n",
        "These are the **true answers** in your dataset. For example, if you show a picture of a dog, the label is “dog.”  \n",
        "- The model learns to predict exactly this label.  \n",
        "- Think of this like a teacher saying: *“This is definitely a dog.”*\n",
        "\n",
        "### 2. Soft Output (Soft Labels)\n",
        "\n",
        "The teacher model doesn’t just give one answer. Instead, it gives probabilities for **all possible classes**.  \n",
        "For example, for a dog picture, the teacher might say:  \n",
        "- Dog: 85%  \n",
        "- Wolf: 10%  \n",
        "- Fox: 5%\n",
        "\n",
        "This gives a **softer**, more detailed understanding of the teacher’s belief.\n",
        "\n",
        "### 3. Dark Knowledge\n",
        "\n",
        "The “dark knowledge” is the **extra information hidden in the teacher’s soft output** — the relationships between classes.  \n",
        "- For example, the teacher knows dogs and wolves are similar, so it assigns some probability to wolves.  \n",
        "- This subtle information helps the student learn better than just using hard labels.\n",
        "\n",
        "---\n",
        "\n",
        "## How Knowledge Distillation Works\n",
        "\n",
        "1. Train a **teacher model** on your dataset to get high accuracy.  \n",
        "2. Use the teacher to generate **soft outputs** (probability distributions) for the training data.  \n",
        "3. Train a smaller **student model** using a combination of:  \n",
        "   - The teacher’s soft outputs (soft loss).  \n",
        "   - The true labels from the dataset (hard loss).\n",
        "\n",
        "---\n",
        "\n",
        "## Why Use Knowledge Distillation?\n",
        "\n",
        "- Smaller models are faster and require less memory — great for mobile or embedded devices.  \n",
        "- Learning from soft outputs helps the student model understand nuanced class similarities, improving its accuracy.\n",
        "\n",
        "---\n",
        "\n",
        "## Simple Analogy\n",
        "\n",
        "| Concept          | Analogy Example                     |\n",
        "|------------------|-----------------------------------|\n",
        "| Hard labels      | Teacher says: “This is a dog.”     |\n",
        "| Soft output      | Teacher says: “85% dog, 10% wolf, 5% fox.” |\n",
        "| Dark knowledge   | The teacher’s understanding of how animals are related |\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step-by-step Explanation — Knowledge Distillation (Teacher → Student) on MNIST\n",
        "\n",
        "Reference: [Distilling the Knowledge in a Neural Network (Hinton et al., 2015)](https://arxiv.org/pdf/1503.02531)\n",
        "\n",
        "Below is a clear, ordered explanation of the workflow you pasted (MNIST, teacher/student MLPs, teacher training, distillation loop, result). Each step explains *what* happens and *why*.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Dataset load (MNIST)\n",
        "- **What:** Load the MNIST dataset (images of digits 0–9).  \n",
        "- **Preprocessing:**\n",
        "  - Normalize pixel values (e.g. scale to [0,1] or mean/std normalization).\n",
        "  - Flatten or keep as 2D depending on MLP vs. CNN (for a simple MLP flatten to 784-d vector).\n",
        "  - Convert labels to integer class indices `0..9`.\n",
        "- **Batches:** Create `DataLoader`/batches (e.g. `batch_size=64` or `128`) for efficient training.\n",
        "- **Why:** Normalization stabilizes and speeds-up training; batching makes gradient updates practical.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Teacher & Student models\n",
        "- **What (architectures in your example):**\n",
        "  - **Teacher:** MLP with a larger hidden layer (e.g. 512 neurons). Higher capacity → typically better accuracy.\n",
        "  - **Student:** Smaller MLP (e.g. 128 neurons). Faster inference, lower memory/compute, but less representational capacity.\n",
        "- **Why two models:** Distillation transfers the teacher’s knowledge into a smaller model so the student becomes compact yet accurate.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Teacher training (supervised)\n",
        "- **Train teacher normally:**\n",
        "  - Loss: Cross-Entropy between teacher logits and ground-truth labels.\n",
        "  - Optimizer: e.g. Adam or SGD, train until high accuracy on validation set.\n",
        "- **Freeze the teacher:** After teacher is trained, stop updating its weights:\n",
        "  - In code: `teacher.eval()` and `with torch.no_grad()` for forward passes, or set `requires_grad=False` and don’t call `optimizer.step()` for teacher.\n",
        "- **Why:** Teacher must provide stable, high-quality soft targets for the student; we don't want teacher parameters to change during distillation.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Distillation (main training loop for the student)\n",
        "For each mini-batch `(x, y)`:\n",
        "\n",
        "1. **Forward pass through teacher (no grad):**\n",
        "   - `logits_T = teacher(x).detach()`  \n",
        "   - Compute *soft targets* by applying softmax with **temperature `T`**:\n",
        "     \\[\n",
        "     p_T = \\text{softmax}( \\text{logits\\_T} / T )\n",
        "     \\]\n",
        "   - `T` > 1 makes the distribution softer (probabilities more spread out), exposing relative class similarities.\n",
        "\n",
        "2. **Forward pass through student (trainable):**\n",
        "   - `logits_S = student(x)`\n",
        "\n",
        "3. **Compute soft (distillation) loss:**\n",
        "   - Convert student outputs to a distribution at same temperature:\n",
        "     \\[\n",
        "     q_S = \\text{softmax}( \\text{logits\\_S} / T )\n",
        "     \\]\n",
        "   - Use KL divergence (teacher → student) or cross-entropy between `p_T` and `q_S`:\n",
        "     \\[\n",
        "     L_{\\text{soft}} = \\text{KL}(p_T \\,||\\, q_S)\n",
        "     \\]\n",
        "   - Implementation note: many libraries expect `log` inputs, so you may use `KLDivLoss(log_q_S, p_T)`.\n",
        "\n",
        "4. **Compute hard (label) loss:**\n",
        "   - Standard cross-entropy between student logits and the ground-truth labels:\n",
        "     \\[\n",
        "     L_{\\text{hard}} = \\text{CE}(\\text{logits\\_S}, y)\n",
        "     \\]\n",
        "\n",
        "5. **Combine losses:**\n",
        "   - Weighted sum:\n",
        "     \\[\n",
        "     L = \\alpha \\cdot (T^2 \\cdot L_{\\text{soft}}) \\;+\\; (1-\\alpha) \\cdot L_{\\text{hard}}\n",
        "     \\]\n",
        "   - Common choices: `alpha ≈ 0.5`, `T ∈ [2, 5]`. The factor `T^2` compensates for the gradient scaling when using temperature (standard in Hinton et al.).\n",
        "\n",
        "6. **Backprop & update student:**\n",
        "   - `loss.backward()` then `optimizer.step()` for the student only.\n",
        "\n",
        "7. **Repeat for all batches/epochs.**\n",
        "\n",
        "**Why the soft targets?**  \n",
        "The soft teacher distribution contains “dark knowledge”: information about inter-class similarities and relative probabilities that hard labels hide. This guides the student to better generalization.\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Final result / Goal\n",
        "- **What you get:** A *smaller student model* that often achieves accuracy close to the teacher while being much faster/smaller.\n",
        "- **Why it works:** Student learns both:\n",
        "  - the **hard labels** (ground truth),\n",
        "  - and the **teacher’s soft behavior** (how strongly the teacher favors each class), which encodes richer structure about the task.\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Important formulas (condensed)\n",
        "- Teacher soft probabilities:\n",
        "  \\[\n",
        "  p_T = \\text{softmax}\\left(\\frac{z_T}{T}\\right)\n",
        "  \\]\n",
        "- Student soft probabilities:\n",
        "  \\[\n",
        "  q_S = \\text{softmax}\\left(\\frac{z_S}{T}\\right)\n",
        "  \\]\n",
        "- Distillation loss:\n",
        "  \\[\n",
        "  L = \\alpha \\cdot T^2 \\cdot \\text{KL}(p_T \\,||\\, q_S) + (1-\\alpha)\\cdot \\text{CE}(z_S, y)\n",
        "  \\]\n",
        "\n",
        "---\n",
        "\n",
        "## 7. Practical hyperparameters & tips\n",
        "- **Batch size:** 64–256 typical.\n",
        "- **Learning rates:** teacher might use `1e-3` (Adam) or `0.1` (SGD w/ momentum) depending on optimizer; student often similar but tuned separately.\n",
        "- **Epochs:** teacher: train until strong accuracy (e.g. 10–30 on MNIST); student: 10–50 depending on data and size.\n",
        "- **Temperature `T`:** common values `2`–`5` (higher → softer distributions). Try `T=2`, then tune.\n",
        "- **Alpha:** start with `0.5`. If labels are reliable and teacher is very good, you can increase `alpha` to emphasize soft targets (or reduce it if hard labels are more important).\n",
        "- **T² factor:** include it when using temperature in KL term to keep gradient magnitudes balanced.\n",
        "- **Freeze teacher:** ensure teacher gradients are disabled (e.g., `.eval()` + `torch.no_grad()` or `param.requires_grad=False`).\n",
        "- **Monitoring:** track student validation accuracy and both loss components (soft & hard) during training.\n",
        "\n",
        "---\n",
        "\n",
        "## 8. Small numeric illustration of temperature effect\n",
        "- Suppose teacher logits for two classes are `[10, 2]`.\n",
        "  - `T=1` → softmax ≈ `[0.9997, 0.0003]` (very peaked).\n",
        "  - `T=5`: logits/5 → `[2, 0.4]` → softmax ≈ `[0.845, 0.155]` (much softer; student can learn that class 2 is somewhat plausible).\n",
        "- **Interpretation:** Higher `T` reveals secondary preferences of the teacher — useful signals for the student.\n",
        "\n",
        "---\n",
        "\n",
        "## 9. Common pitfalls & debugging\n",
        "- **Teacher too weak:** If teacher accuracy is poor, student can’t learn good priors. Make sure teacher is well-trained.\n",
        "- **Forgetting `detach()` / freezing teacher:** If teacher grads are computed, you might accidentally update the teacher or increase memory use.\n",
        "- **Mismatch in temperature scaling:** Forgetting to scale the KL loss by `T^2` can harm optimization.\n",
        "- **Imbalanced `alpha`:** Too much weight on soft loss may ignore ground truth; too little and student won’t capture teacher's knowledge.\n",
        "- **Leaking test data:** Don’t use test set in distillation (only training/validation).\n",
        "\n",
        "---\n",
        "\n",
        "## 10. Variants & extensions\n",
        "- **Only soft targets:** Sometimes `alpha=1` (no hard labels) if teacher is perfect or dataset noisy.\n",
        "- **Ensemble teacher:** Use ensemble of teachers to produce stronger soft targets.\n",
        "- **Feature distillation:** Match intermediate representations (hints) between teacher and student (not just logits).\n",
        "- **Online distillation:** Jointly train teacher and student (needs careful handling).\n",
        "- **Temperature annealing:** Change `T` over time (e.g., start higher and lower it).\n",
        "\n",
        "---\n",
        "\n",
        "## Summary (one-liner)\n",
        "Train a big teacher to high accuracy, freeze it, and train a smaller student to mimic both the teacher’s soft output distribution (soft targets at temperature `T`) and the ground-truth labels — combining them with a weighted loss so the student becomes small **and** accurate.\n",
        "\n",
        "---\n",
        "\n",
        "If you want, I can now:\n",
        "- provide a short pseudocode of the training loop, or  \n",
        "- give a ready-to-run PyTorch code snippet implementing this exact distillation (teacher+student + loss with `T^2` scaling), or  \n",
        "- suggest specific hyperparameters for MNIST (exact `T`, `alpha`, lr, epochs, batch_size).\n",
        "Which would you like next?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68ORLwV2a4Mb"
      },
      "source": [
        "1. transforms.ToTensor()\n",
        "\n",
        "MNIST images are originally in PIL Image format (28×28 grayscale).\n",
        "\n",
        "This converts them into a PyTorch Tensor, and also scales pixel values to the [0,1] range.\n",
        "\n",
        "Originally, pixel values are between 0–255.\n",
        "\n",
        "After ToTensor(), each pixel becomes pixel / 255.\n",
        "\n",
        "2. transforms.Normalize((0.5,), (0.5,))\n",
        "This further shifts and scales pixel values to the [-1, 1] range.\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "​\n",
        "\n",
        "where x is the pixel value in [0,1] (after ToTensor()).\n",
        "\n",
        "Meaning:\n",
        "\n",
        "0 → -1\n",
        "\n",
        "0.5 → 0\n",
        "\n",
        "1 → +1\n",
        "\n",
        "We normalize like this because:\n",
        "\n",
        "Neural networks train better when inputs are centered around zero (mean ≈ 0).\n",
        "\n",
        "It helps speed up training and prevents issues like exploding/vanishing gradients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QagH2OWDqNaK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "attachments": {
        "image.png": {
          "image/png": "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"
        }
      },
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-ql7edgaaQk"
      },
      "outputs": [],
      "source": [
        "# ----- Dataset (MNIST) -----\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(), # converting normal tensor to pytorch tensor\n",
        "    transforms.Normalize((0.5,), (0.5,)) # Normalize(mean = 0.5, std = 0.5) \n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8DRjcoppGc9",
        "outputId": "577fc910-f3fc-4ceb-b6ec-6a63b698ae57"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:01<00:00, 5.13MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 132kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.28MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 12.8MB/s]\n"
          ]
        }
      ],
      "source": [
        "train_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_data  = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "test_loader  = DataLoader(test_data, batch_size=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nFebLC1Xbdo1"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "images, labels = next(iter(train_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "mwNBRtUBbYvl",
        "outputId": "dc4210ea-8684-453e-a8cc-ada427798d70"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1500x200 with 8 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, axes = plt.subplots(1, 8, figsize=(15, 2))\n",
        "for i, ax in enumerate(axes):\n",
        "    ax.imshow(images[i].squeeze(), cmap='gray')  # grayscale\n",
        "    ax.set_title(f\"Label: {labels[i].item()}\")\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Teacher Model Summary\n",
        "\n",
        "- **Model type:** Multi-Layer Perceptron (MLP)  \n",
        "- **Purpose:** Classify MNIST digits (0–9)  \n",
        "- **Input:** 28×28 grayscale image, flattened into a 784-dimensional vector  \n",
        "\n",
        "---\n",
        "\n",
        "## Architecture and Layers\n",
        "\n",
        "- `nn.Flatten()`  \n",
        "  - Converts 2D input image (28×28) into a 1D tensor of size 784.  \n",
        "  - Necessary because linear layers expect flat vectors.\n",
        "\n",
        "- `nn.Linear(28*28, 512)`  \n",
        "  - Fully connected layer mapping 784 input features to 512 hidden units.\n",
        "\n",
        "- `nn.ReLU()`  \n",
        "  - Activation function adding non-linearity.\n",
        "\n",
        "- `nn.Linear(512, 256)`  \n",
        "  - Fully connected layer mapping 512 hidden units to 256 hidden units.\n",
        "\n",
        "- `nn.ReLU()`  \n",
        "  - Another ReLU activation.\n",
        "\n",
        "- `nn.Linear(256, 10)`  \n",
        "  - Final fully connected layer outputting 10 logits, corresponding to digit classes 0–9.\n",
        "\n",
        "---\n",
        "\n",
        "## Output\n",
        "\n",
        "- The model outputs raw logits (unnormalized scores) for each class.  \n",
        "- These logits are typically passed through a softmax during training or evaluation to get class probabilities.\n",
        "\n",
        "---\n",
        "\n",
        "## Notes\n",
        "\n",
        "- The model is called the **teacher** because it is usually larger and better trained.  \n",
        "- The teacher’s outputs guide the training of a smaller **student** model in knowledge distillation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ImxpDWZqsSj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define the Teacher Model as a Multi-Layer Perceptron (MLP)\n",
        "class TeacherMLP(nn.Module):\n",
        "    def __init__(self, hidden1=512, hidden2=256):\n",
        "        super().__init__()\n",
        "        # Sequential container to stack layers one after another\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Flatten(),               # input layer: Flatten 28x28 image into a vector of size 784\n",
        "            nn.Linear(28*28, hidden1), # hidden layer: First fully connected layer: input 784 → output 512\n",
        "            nn.ReLU(),                 # Apply ReLU activation (introduces non-linearity)\n",
        "            nn.Linear(hidden1, hidden2), # hidden layer: Second fully connected layer: 512 → 256\n",
        "            nn.ReLU(),                 # Another ReLU activation\n",
        "            nn.Linear(hidden2, 10)     # Final output layer: outputs 10 logits, one for each digit class\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Define forward pass: input tensor x goes through the layers sequentially\n",
        "        return self.net(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "0sGV5S3BqxJd"
      },
      "outputs": [],
      "source": [
        "# Create instances\n",
        "teacher = TeacherMLP(hidden1=512, hidden2=256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5N1rHRX2q0r4",
        "outputId": "718a8200-7f67-4fbf-cb5e-337619501d12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TeacherMLP(\n",
            "  (net): Sequential(\n",
            "    (0): Flatten(start_dim=1, end_dim=-1)\n",
            "    (1): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (2): ReLU()\n",
            "    (3): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=256, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(teacher)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training Summary: `train_teacher`\n",
        "\n",
        "- **Purpose:** Train the teacher model on labeled data.  \n",
        "- **Inputs:**  \n",
        "  - `model`: The neural network to train (teacher).  \n",
        "  - `loader`: DataLoader providing batches of (input, label) pairs.  \n",
        "  - `epochs`: Number of passes over the dataset (default: 1).  \n",
        "  - `lr`: Learning rate for optimizer (default: 0.001).\n",
        "\n",
        "---\n",
        "\n",
        "## Key steps\n",
        "\n",
        "- `optim.Adam(model.parameters(), lr=lr)`  \n",
        "  - Initialize the Adam optimizer to update model parameters.  \n",
        "\n",
        "- `nn.CrossEntropyLoss()`  \n",
        "  - Define the loss function suitable for classification.\n",
        "\n",
        "- `model.train()`  \n",
        "  - Set the model to training mode (enables dropout, batch norm, etc.).\n",
        "\n",
        "- For each epoch:  \n",
        "  - For each batch in `loader`:\n",
        "    - `opt.zero_grad()`  \n",
        "      - Clear old gradients before backpropagation.  \n",
        "    - `out = model(x)`  \n",
        "      - Forward pass: compute model predictions (logits).  \n",
        "    - `loss = loss_fn(out, y)`  \n",
        "      - Calculate loss comparing predictions and true labels.  \n",
        "    - `loss.backward()`  \n",
        "      - Backpropagate to compute gradients.  \n",
        "    - `opt.step()`  \n",
        "      - Update model parameters based on gradients.  \n",
        "    - Accumulate loss for monitoring progress.\n",
        "\n",
        "---\n",
        "\n",
        "## Output\n",
        "\n",
        "- Prints average loss per epoch to track training progress:\n",
        "  ```python\n",
        "  print(f\"Teacher Epoch {ep+1}: Loss = {total_loss/len(loader):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZynvfw8q9Hm"
      },
      "outputs": [],
      "source": [
        "# Function to train the teacher model\n",
        "def train_teacher(model, train_loader, epochs=1, lr=1e-3):\n",
        "    \n",
        "    # Create an Adam optimizer to update model parameters with the specified learning rate\n",
        "    opt = optim.Adam(model.parameters(), lr=lr)\n",
        "    \n",
        "    # Define the loss function as Cross-Entropy Loss, suitable for classification\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    \n",
        "    # Set the model to training mode (enables dropout, batch norm if any)\n",
        "    model.train()\n",
        "    \n",
        "    # Loop over the number of epochs\n",
        "    for ep in range(epochs):\n",
        "        total_loss = 0  # Initialize total loss for the epoch\n",
        "        \n",
        "        # Iterate over batches of data from the train_loader\n",
        "        for x, y in train_loader:\n",
        "            opt.zero_grad()       # Clear previous gradients\n",
        "            \n",
        "            out = model(x)        # Forward pass: compute model predictions (logits)\n",
        "            \n",
        "            loss = loss_fn(out, y) # Compute loss comparing predictions with true labels\n",
        "            \n",
        "            loss.backward()       # Backpropagation: compute gradients\n",
        "            \n",
        "            opt.step()            # Update model parameters using gradients\n",
        "            \n",
        "            total_loss += loss.item() # Accumulate loss for monitoring\n",
        "        \n",
        "        # Print average loss for the epoch\n",
        "        print(f\"Teacher Epoch {ep+1}: Loss = {total_loss/len(train_loader):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6QFJCDxq_6q",
        "outputId": "e1eff792-32a1-42a3-ca19-bf2c2ee720da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Teacher Epoch 1: Loss = 0.3027\n"
          ]
        }
      ],
      "source": [
        "train_teacher(teacher, train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDrXRuRyvppk",
        "outputId": "c198abe3-fe42-4bfa-8248-470e54d153b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OrderedDict([('net.1.weight', tensor([[-0.0226,  0.0012, -0.0154,  ..., -0.0175, -0.0362, -0.0267],\n",
            "        [-0.0119, -0.0141, -0.0230,  ...,  0.0003,  0.0189,  0.0281],\n",
            "        [ 0.0184,  0.0174, -0.0294,  ...,  0.0196,  0.0083, -0.0079],\n",
            "        ...,\n",
            "        [ 0.0385,  0.0217,  0.0104,  ..., -0.0297, -0.0022,  0.0197],\n",
            "        [-0.0067, -0.0302, -0.0067,  ..., -0.0211, -0.0273, -0.0380],\n",
            "        [-0.0181, -0.0165, -0.0014,  ...,  0.0462,  0.0410, -0.0159]])), ('net.1.bias', tensor([ 0.0327,  0.0078,  0.0153,  0.0101, -0.0207,  0.0004, -0.0036, -0.0052,\n",
            "        -0.0372, -0.0105, -0.0349, -0.0190, -0.0225,  0.0172,  0.0063, -0.0016,\n",
            "        -0.0292, -0.0367,  0.0319,  0.0065, -0.0353, -0.0167, -0.0175, -0.0036,\n",
            "        -0.0350, -0.0036, -0.0281,  0.0069,  0.0109,  0.0164, -0.0116,  0.0093,\n",
            "         0.0014, -0.0309,  0.0250, -0.0049, -0.0204, -0.0078,  0.0299, -0.0253,\n",
            "        -0.0145,  0.0215, -0.0091,  0.0277, -0.0342, -0.0293, -0.0042,  0.0091,\n",
            "         0.0270,  0.0273, -0.0002, -0.0130, -0.0035, -0.0003, -0.0233,  0.0202,\n",
            "        -0.0072,  0.0134, -0.0185,  0.0244,  0.0086, -0.0177, -0.0166,  0.0023,\n",
            "         0.0023, -0.0409,  0.0189,  0.0063, -0.0071,  0.0100, -0.0105,  0.0093,\n",
            "         0.0336, -0.0121, -0.0355, -0.0328,  0.0014,  0.0260,  0.0222,  0.0251,\n",
            "         0.0081,  0.0179,  0.0006, -0.0233,  0.0093,  0.0162, -0.0324, -0.0058,\n",
            "         0.0033, -0.0065, -0.0269,  0.0287, -0.0109, -0.0278,  0.0183, -0.0099,\n",
            "        -0.0296,  0.0021,  0.0207, -0.0226,  0.0088, -0.0139, -0.0284,  0.0264,\n",
            "         0.0059, -0.0060, -0.0201,  0.0378,  0.0252, -0.0272,  0.0108, -0.0280,\n",
            "        -0.0010, -0.0203, -0.0355,  0.0054, -0.0252, -0.0318, -0.0293,  0.0196,\n",
            "         0.0009, -0.0081, -0.0238, -0.0277, -0.0236, -0.0250,  0.0213,  0.0015,\n",
            "        -0.0110, -0.0044, -0.0146, -0.0350, -0.0243, -0.0133,  0.0049,  0.0255,\n",
            "         0.0216, -0.0328,  0.0124,  0.0137,  0.0169, -0.0006,  0.0119, -0.0214,\n",
            "         0.0027, -0.0198, -0.0285, -0.0239, -0.0008,  0.0215, -0.0291, -0.0154,\n",
            "        -0.0305, -0.0343,  0.0056, -0.0046,  0.0286, -0.0385,  0.0068, -0.0353,\n",
            "         0.0291, -0.0219,  0.0031, -0.0371,  0.0231, -0.0242, -0.0360, -0.0362,\n",
            "         0.0157, -0.0031, -0.0215, -0.0100, -0.0302, -0.0202,  0.0333, -0.0223,\n",
            "         0.0208, -0.0215, -0.0066, -0.0248,  0.0197,  0.0308, -0.0354, -0.0284,\n",
            "         0.0115,  0.0075, -0.0255,  0.0155,  0.0100, -0.0189,  0.0152,  0.0079,\n",
            "        -0.0360,  0.0170,  0.0256, -0.0123, -0.0391,  0.0005,  0.0111, -0.0153,\n",
            "        -0.0158, -0.0178, -0.0365, -0.0232,  0.0056, -0.0169, -0.0415,  0.0311,\n",
            "        -0.0376,  0.0330, -0.0325,  0.0127,  0.0155, -0.0337, -0.0244,  0.0148,\n",
            "        -0.0237, -0.0060, -0.0196, -0.0323,  0.0273, -0.0042, -0.0160, -0.0145,\n",
            "        -0.0452, -0.0210,  0.0050, -0.0029,  0.0067, -0.0072, -0.0043, -0.0094,\n",
            "         0.0270,  0.0114, -0.0286, -0.0287,  0.0139,  0.0019, -0.0173,  0.0109,\n",
            "         0.0009, -0.0046,  0.0043,  0.0100,  0.0007,  0.0276,  0.0202, -0.0167,\n",
            "        -0.0316, -0.0127, -0.0202, -0.0013, -0.0412, -0.0072, -0.0318, -0.0220,\n",
            "        -0.0257, -0.0238,  0.0074,  0.0282, -0.0009, -0.0116, -0.0326,  0.0137,\n",
            "        -0.0115, -0.0349, -0.0290,  0.0253, -0.0245, -0.0171,  0.0190,  0.0218,\n",
            "         0.0232,  0.0165,  0.0349,  0.0100, -0.0305,  0.0173, -0.0037, -0.0142,\n",
            "         0.0262,  0.0022,  0.0150, -0.0077,  0.0254, -0.0229, -0.0082, -0.0139,\n",
            "         0.0255, -0.0143,  0.0017, -0.0086,  0.0155, -0.0397, -0.0020, -0.0177,\n",
            "         0.0221,  0.0313, -0.0404,  0.0133, -0.0289,  0.0207,  0.0319,  0.0123,\n",
            "        -0.0215, -0.0074, -0.0139,  0.0033,  0.0138,  0.0255, -0.0061,  0.0194,\n",
            "         0.0121, -0.0279,  0.0057, -0.0088, -0.0355,  0.0229,  0.0202,  0.0127,\n",
            "        -0.0210, -0.0132, -0.0153, -0.0007, -0.0408, -0.0172, -0.0066,  0.0083,\n",
            "         0.0091, -0.0217,  0.0132, -0.0036,  0.0242, -0.0028,  0.0235, -0.0362,\n",
            "        -0.0077, -0.0333,  0.0154,  0.0118,  0.0062, -0.0071,  0.0059, -0.0273,\n",
            "        -0.0068,  0.0082,  0.0227,  0.0115,  0.0085,  0.0209, -0.0343,  0.0252,\n",
            "        -0.0048, -0.0123,  0.0065, -0.0123,  0.0139, -0.0287,  0.0354, -0.0343,\n",
            "         0.0017, -0.0362,  0.0206, -0.0280, -0.0121, -0.0211,  0.0235, -0.0330,\n",
            "        -0.0112,  0.0212, -0.0310, -0.0226,  0.0302, -0.0208, -0.0103,  0.0259,\n",
            "         0.0137, -0.0037,  0.0182, -0.0339, -0.0239,  0.0311,  0.0098, -0.0301,\n",
            "         0.0171, -0.0103,  0.0103, -0.0192,  0.0045,  0.0185,  0.0291,  0.0249,\n",
            "         0.0089,  0.0151, -0.0289, -0.0169, -0.0103,  0.0060,  0.0020,  0.0327,\n",
            "        -0.0284, -0.0108,  0.0220,  0.0095, -0.0347,  0.0126, -0.0226,  0.0239,\n",
            "        -0.0323,  0.0106,  0.0298, -0.0383, -0.0164,  0.0018, -0.0179,  0.0340,\n",
            "        -0.0184, -0.0250, -0.0155, -0.0006,  0.0068, -0.0137, -0.0301, -0.0280,\n",
            "        -0.0425, -0.0033, -0.0101, -0.0209,  0.0083, -0.0311, -0.0193, -0.0337,\n",
            "         0.0135,  0.0303,  0.0213, -0.0095, -0.0264,  0.0265, -0.0152,  0.0275,\n",
            "        -0.0193,  0.0060, -0.0119,  0.0159,  0.0080,  0.0160, -0.0406,  0.0119,\n",
            "        -0.0012,  0.0291, -0.0024, -0.0254,  0.0057, -0.0269, -0.0013, -0.0050,\n",
            "        -0.0114, -0.0013, -0.0046,  0.0001,  0.0103, -0.0003,  0.0057, -0.0280,\n",
            "        -0.0271,  0.0268, -0.0046,  0.0145, -0.0279,  0.0101, -0.0211, -0.0077,\n",
            "        -0.0364, -0.0253,  0.0057, -0.0036, -0.0103, -0.0062, -0.0120,  0.0076,\n",
            "         0.0290, -0.0221, -0.0128,  0.0232, -0.0140, -0.0111, -0.0128,  0.0107,\n",
            "        -0.0100,  0.0253,  0.0288,  0.0020,  0.0248, -0.0267,  0.0184, -0.0147,\n",
            "         0.0210, -0.0376,  0.0317, -0.0069,  0.0197,  0.0023, -0.0022, -0.0267,\n",
            "        -0.0275,  0.0142, -0.0258,  0.0344,  0.0125,  0.0211,  0.0252, -0.0139])), ('net.3.weight', tensor([[-0.0022, -0.0293,  0.0531,  ...,  0.0219,  0.0222,  0.0024],\n",
            "        [-0.0380, -0.0145,  0.0359,  ...,  0.0374, -0.0671,  0.0224],\n",
            "        [ 0.0008,  0.0334,  0.0189,  ..., -0.0058,  0.0365,  0.0040],\n",
            "        ...,\n",
            "        [-0.0099, -0.0191, -0.0408,  ..., -0.0397,  0.0041, -0.0377],\n",
            "        [-0.0196,  0.0209, -0.0163,  ..., -0.0461,  0.0228, -0.0025],\n",
            "        [-0.0066, -0.0288, -0.0288,  ..., -0.0097, -0.0972,  0.0524]])), ('net.3.bias', tensor([ 0.0317,  0.0182, -0.0279,  0.0397, -0.0573, -0.0068,  0.0185, -0.0295,\n",
            "         0.0030, -0.0307, -0.0083, -0.0075, -0.0115, -0.0155,  0.0658, -0.0471,\n",
            "         0.0332,  0.0385,  0.0154, -0.0343, -0.0041,  0.0275, -0.0014, -0.0096,\n",
            "         0.0165, -0.0349,  0.0327, -0.0364,  0.0019,  0.0160, -0.0158,  0.0561,\n",
            "        -0.0344,  0.0322, -0.0127,  0.0384,  0.0360,  0.0497, -0.0693, -0.0323,\n",
            "         0.0365,  0.0314,  0.0108, -0.0083,  0.0027, -0.0236, -0.0273, -0.0101,\n",
            "         0.0038,  0.0445, -0.0498,  0.0350, -0.0228,  0.0525, -0.0312, -0.0408,\n",
            "        -0.0021, -0.0019,  0.0069,  0.0260, -0.0135,  0.0269,  0.0491,  0.0462,\n",
            "         0.0068, -0.0465,  0.0061, -0.0038, -0.0437,  0.0404, -0.0056,  0.0099,\n",
            "         0.0423,  0.0630, -0.0414,  0.0367,  0.0123, -0.0533,  0.0332,  0.0273,\n",
            "         0.0203, -0.0273,  0.0289,  0.0402,  0.0097,  0.0234,  0.0246,  0.0110,\n",
            "         0.0338, -0.0058, -0.0214, -0.0001, -0.0160,  0.0280, -0.0589, -0.0015,\n",
            "        -0.0232, -0.0136,  0.0212,  0.0238,  0.0376, -0.0061,  0.0049, -0.0439,\n",
            "         0.0498,  0.0437,  0.0450, -0.0341, -0.0257, -0.0291,  0.0305,  0.0066,\n",
            "         0.0432,  0.0082,  0.0335,  0.0277,  0.0458,  0.0043, -0.0216, -0.0309,\n",
            "         0.0206, -0.0321, -0.0003,  0.0017, -0.0223,  0.0144,  0.0193, -0.0448,\n",
            "         0.0287, -0.0221,  0.0263,  0.0023,  0.0312,  0.0285, -0.0136,  0.0520,\n",
            "         0.0216,  0.0531,  0.0463,  0.0075,  0.0115, -0.0011,  0.0231,  0.0284,\n",
            "        -0.0565, -0.0090, -0.0232,  0.0440,  0.0127, -0.0343, -0.0107, -0.0404,\n",
            "         0.0021,  0.0172, -0.0013,  0.0151, -0.0083, -0.0531, -0.0464,  0.0247,\n",
            "         0.0266, -0.0526, -0.0170, -0.0206,  0.0165,  0.0266,  0.0423, -0.0487,\n",
            "        -0.0619,  0.0259,  0.0348, -0.0300,  0.0346,  0.0473, -0.0211,  0.0490,\n",
            "        -0.0017,  0.0259,  0.0765,  0.0277, -0.0134,  0.0121, -0.0473,  0.0417,\n",
            "        -0.0152,  0.0081,  0.0315, -0.0403,  0.0338,  0.0031,  0.0166,  0.0274,\n",
            "         0.0303,  0.0621, -0.0229,  0.0095, -0.0021,  0.0246,  0.0166, -0.0224,\n",
            "         0.0152,  0.0444, -0.0023,  0.0300, -0.0006,  0.0003, -0.0260, -0.0194,\n",
            "         0.0205,  0.0186,  0.0237, -0.0156, -0.0212, -0.0207, -0.0236,  0.0034,\n",
            "        -0.0286, -0.0354, -0.0158,  0.0393, -0.0257,  0.0287,  0.0093,  0.0130,\n",
            "        -0.0202,  0.0054, -0.0141, -0.0337, -0.0004,  0.0065, -0.0101,  0.0625,\n",
            "         0.0719, -0.0109, -0.0251, -0.0446,  0.0221,  0.0352, -0.0093, -0.0502,\n",
            "         0.0158,  0.0465, -0.0325, -0.0552,  0.0280, -0.0379,  0.0226,  0.0241,\n",
            "         0.0041,  0.0244, -0.0380,  0.0114,  0.0448, -0.0005,  0.0229,  0.0302])), ('net.5.weight', tensor([[-0.0621, -0.1246,  0.0308,  ...,  0.0448,  0.0021,  0.0460],\n",
            "        [-0.0271, -0.0221,  0.0062,  ...,  0.0137, -0.0319, -0.0910],\n",
            "        [-0.0798, -0.0252, -0.0625,  ..., -0.0046, -0.0374, -0.0217],\n",
            "        ...,\n",
            "        [ 0.0195,  0.0022, -0.0011,  ..., -0.0319,  0.0260, -0.0776],\n",
            "        [ 0.0209, -0.0700,  0.0182,  ...,  0.0434, -0.0307, -0.0645],\n",
            "        [ 0.0277,  0.0511,  0.0438,  ...,  0.0376, -0.0244,  0.0291]])), ('net.5.bias', tensor([-0.0010,  0.0016, -0.0128, -0.0015, -0.0147,  0.0081, -0.0359, -0.0249,\n",
            "         0.0471,  0.0075]))])\n"
          ]
        }
      ],
      "source": [
        "print(teacher.state_dict())  # Ye updated weights dikhayega\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y58Cr_RwvrKx"
      },
      "outputs": [],
      "source": [
        "# # ----- Freeze Teacher ----- this is one of the way by freezing the teachr model and train student mode their is another way also without freezing like this.\n",
        "# for param in teacher.parameters():\n",
        "#     param.requires_grad = False\n",
        "# teacher.eval()\n",
        "# print(\"Teacher model trained and frozen.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Student Model Explanation (`StudentMLP`)\n",
        "\n",
        "- **Purpose:** A smaller neural network with one hidden layer designed to learn from the teacher model.\n",
        "\n",
        "---\n",
        "\n",
        "## Architecture details:\n",
        "\n",
        "- `nn.Flatten()`  \n",
        "  - Flattens the 2D input image (28×28 pixels) into a 1D tensor of length 784 so it can be fed into linear layers.\n",
        "\n",
        "- `nn.Linear(28*28, hidden)`  \n",
        "  - Fully connected layer that maps the 784 input features to `hidden` neurons (default 128).\n",
        "\n",
        "- `nn.ReLU()`  \n",
        "  - Applies the ReLU activation function, introducing non-linearity to the network.\n",
        "\n",
        "- `nn.Linear(hidden, 10)`  \n",
        "  - Output layer mapping from hidden neurons to 10 logits, one for each MNIST digit class (0–9).\n",
        "\n",
        "---\n",
        "\n",
        "## Summary:\n",
        "\n",
        "- The student model has fewer parameters than the teacher (only 1 hidden layer vs 2).  \n",
        "- It is designed to be smaller and faster for efficient inference.  \n",
        "- Learns to mimic the teacher’s behavior while using less compute.  \n",
        "- The `forward` method simply passes input `x` through `self.net` (the sequence of layers).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JkOosVv4qvTR"
      },
      "outputs": [],
      "source": [
        "# ----- Student Model (1 hidden layer) -----\n",
        "class StudentMLP(nn.Module):\n",
        "    def __init__(self, hidden=128):\n",
        "        super().__init__()\n",
        "        # Define the network as a sequence of layers:\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Flatten(),                # Flatten 28x28 image into a 784-length vector\n",
        "            nn.Linear(28*28, hidden),    # Fully connected layer with 'hidden' neurons (128 by default)\n",
        "            nn.ReLU(),                   # ReLU activation adds non-linearity\n",
        "            nn.Linear(hidden, 10)        # Output layer with 10 neurons (one per digit class)\n",
        "            # This model is smaller than the teacher: only one hidden layer\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass through the network\n",
        "        return self.net(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "QyAaUHQ8qyNn"
      },
      "outputs": [],
      "source": [
        "student = StudentMLP(hidden=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQQO4HjfpMBc",
        "outputId": "5f5ec9dd-3e0f-4fc0-ab0c-919737a46d58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "StudentMLP(\n",
            "  (net): Sequential(\n",
            "    (0): Flatten(start_dim=1, end_dim=-1)\n",
            "    (1): Linear(in_features=784, out_features=128, bias=True)\n",
            "    (2): ReLU()\n",
            "    (3): Linear(in_features=128, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(student)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pretrain Student Function Explanation (`pretrain_student`)\n",
        "\n",
        "- **Purpose:** Optionally warm up the student model by training it on the true labels (hard labels) before distillation.\n",
        "\n",
        "---\n",
        "\n",
        "## Key components:\n",
        "\n",
        "- `student.train()`  \n",
        "  - Sets the student model to training mode (enables dropout, batch norm, etc.).\n",
        "\n",
        "- `optim.Adam(student.parameters(), lr=lr)`  \n",
        "  - Initializes the Adam optimizer for updating the student model parameters.\n",
        "\n",
        "- `nn.CrossEntropyLoss()`  \n",
        "  - Defines the loss function to measure difference between predicted logits and true labels.\n",
        "\n",
        "---\n",
        "\n",
        "## Training loop:\n",
        "\n",
        "- For each epoch (`for ep in range(epochs):`):  \n",
        "  - Loop over batches from `loader` providing `(x, y)` pairs (inputs and labels).\n",
        "  \n",
        "  - `opt.zero_grad()`  \n",
        "    - Clears previous gradients before computing new ones.\n",
        "  \n",
        "  - `out = student(x)`  \n",
        "    - Forward pass: compute student’s output logits for inputs `x`.\n",
        "  \n",
        "  - `loss = ce_loss(out, y)`  \n",
        "    - Compute cross-entropy loss comparing student predictions with true labels `y`.\n",
        "  \n",
        "  - `loss.backward()`  \n",
        "    - Backpropagate to calculate gradients of loss w.r.t. student parameters.\n",
        "  \n",
        "  - `opt.step()`  \n",
        "    - Update student parameters based on gradients computed.\n",
        "\n",
        "---\n",
        "\n",
        "## Summary:\n",
        "\n",
        "- This function trains the student model *only* on ground-truth labels (hard labels).  \n",
        "- It helps the student learn a basic representation before the distillation process begins.  \n",
        "- Useful as a warm-up but not mandatory — distillation usually improves on this baseline.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZ35wlZHywOt"
      },
      "outputs": [],
      "source": [
        "# (A) Pretrain student on hard labels (optional warm-up)\n",
        "def pretrain_student(student, loader, epochs=1, lr=1e-3):\n",
        "    student.train()  # Set model to training mode (enables dropout, batch norm, etc.)\n",
        "    \n",
        "    opt = optim.Adam(student.parameters(), lr=lr)  # Initialize Adam optimizer\n",
        "    \n",
        "    ce_loss = nn.CrossEntropyLoss()  # Define cross-entropy loss function for classification\n",
        "    \n",
        "    for ep in range(epochs):  # Loop over epochs\n",
        "        for x, y in loader:  # Loop over batches of data (inputs x and labels y)\n",
        "            \n",
        "            opt.zero_grad()  # Clear gradients from previous step\n",
        "            \n",
        "            out = student(x)  # Forward pass: compute student outputs (logits)\n",
        "            \n",
        "            loss = ce_loss(out, y)  # Compute loss between predictions and true labels\n",
        "            \n",
        "            loss.backward()  # Backpropagate to compute gradients\n",
        "            \n",
        "            opt.step()  # Update model parameters based on gradients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "5klDTkgczJVP"
      },
      "outputs": [],
      "source": [
        "pretrain_student(student, train_loader, epochs=1)  # optional warm-up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "s3VlGvlfq5xy"
      },
      "outputs": [],
      "source": [
        "# ----- Distillation Training -----\n",
        "temperature = 2.0\n",
        "alpha = 0.7\n",
        "ce_loss = nn.CrossEntropyLoss()\n",
        "kl_loss = nn.KLDivLoss(reduction=\"batchmean\")\n",
        "optimizer = optim.Adam(student.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "MYxZiu2XrHH8"
      },
      "outputs": [],
      "source": [
        "def distill(student, teacher, loader, epochs=1):\n",
        "    for ep in range(epochs):\n",
        "\n",
        "        student.train()\n",
        "\n",
        "        total_loss = 0\n",
        "\n",
        "        for x, y in loader:\n",
        "            # Teacher outputs\n",
        "            with torch.no_grad():\n",
        "                t_logits = teacher(x)\n",
        "                t_probs = torch.softmax(t_logits / temperature, dim=1)\n",
        "\n",
        "            # Student outputs\n",
        "            s_logits = student(x)\n",
        "            s_log_probs = torch.log_softmax(s_logits / temperature, dim=1)\n",
        "\n",
        "            # Losses\n",
        "            loss_soft = kl_loss(s_log_probs, t_probs) * (temperature**2)\n",
        "            loss_hard = ce_loss(s_logits, y)\n",
        "            loss = alpha * loss_soft + (1 - alpha) * loss_hard\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Student Epoch {ep+1}: Loss = {total_loss/len(loader):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HuD_E5K7zFFj"
      },
      "outputs": [],
      "source": [
        "# # (B) Then run your existing distill(...)\n",
        "# distill(student, teacher, train_loader, epochs=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qev8Fm5arkHb",
        "outputId": "57acba36-3ed8-4d48-d8e2-775423670325"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Student Epoch 1: Loss = 0.1682\n"
          ]
        }
      ],
      "source": [
        "distill(student, teacher, train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "d1s_6MqDrmsa"
      },
      "outputs": [],
      "source": [
        "# ----- 5. Evaluation Function -----\n",
        "def evaluate(model, loader, name=\"Model\"):\n",
        "    model.eval()\n",
        "\n",
        "    correct, total = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            out = model(x)\n",
        "            preds = out.argmax(dim=1)\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += y.size(0)\n",
        "    acc = correct / total * 100\n",
        "    print(f\"{name} Accuracy: {acc:.2f}%\")\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqehWMh4eTQ7",
        "outputId": "0ff36a71-8832-4820-ddf7-676269421832"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Teacher Accuracy: 94.20%\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "94.19999999999999"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Evaluate both Teacher and Student\n",
        "evaluate(teacher, test_loader, \"Teacher\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_wEEzD5rsW3",
        "outputId": "df105391-1ac6-4dd5-fb4c-c7c92cb90acc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Student Accuracy: 94.21%\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "94.21000000000001"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate(student, test_loader, \"Student\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "C_UK6yVAru36"
      },
      "outputs": [],
      "source": [
        "# ----- 6. Sample Predictions -----\n",
        "def predict(model, x):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        out = model(x)\n",
        "        return out.argmax(dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "VlPnK1Q6eoZ6"
      },
      "outputs": [],
      "source": [
        "sample_batch, sample_labels = next(iter(test_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "hdWWRB1eeqh7"
      },
      "outputs": [],
      "source": [
        "preds = predict(student, sample_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "563IhiGmes38",
        "outputId": "261547b5-8738-4ce5-ee4e-ab179dfa97f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample predictions (Student): tensor([7, 2, 1, 0, 4, 1, 4, 9, 6, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4])\n"
          ]
        }
      ],
      "source": [
        "print(\"Sample predictions (Student):\", preds[:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FqEfeWBryOr",
        "outputId": "51cad614-e90e-442d-d472-6db6da946185"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True labels: tensor([7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4])\n"
          ]
        }
      ],
      "source": [
        "print(\"True labels:\", sample_labels[:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHFTZlL0rz88",
        "outputId": "186e76d3-365b-41ab-bbd2-03eeb45cc8d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Student model saved as distilled_student.pth\n"
          ]
        }
      ],
      "source": [
        "# ----- 7. Save Student Model -----\n",
        "torch.save(student.state_dict(), \"distilled_student.pth\")\n",
        "print(\"Student model saved as distilled_student.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tz9u6pZNjZNZ"
      },
      "source": [
        "### Classical LLM Distillation (BERT → DistilBERT)\n",
        "\n",
        "| Block                   | Purpose (Hindi explain)                                                                                                        |\n",
        "| ----------------------- | ------------------------------------------------------------------------------------------------------------------------------ |\n",
        "| **0. Imports & Config** | Saare zaroori Python libraries import karo (Transformers, Torch, etc.), GPU/CPU detect karo, aur hyperparameters (batch size, lr, epochs, temperature, alpha) set karo. |\n",
        "| **1. Dataset**          | Demo text dataset load karo, tokenizer se tokenize karo; Data collator automatic padding karega taaki batch uniform ho.      |\n",
        "| **2. Models**           | Pretrained **BERT** ko teacher ke roop me load karo (freeze kar dena), aur **DistilBERT** ko student ke roop me load karo (trainable). |\n",
        "| **3. Losses**           | Do losses use karo: <br>• **CE (CrossEntropy)** = hard labels ke liye <br>• **KL Divergence** = soft labels (teacher ke logits → softmax with temperature). |\n",
        "| **4. Optimizer**        | **AdamW** optimizer use karo with **linear learning rate scheduler** training ke smooth control ke liye.                      |\n",
        "| **5. distill_epoch()**  | Har batch pe: <br>• Teacher ke logits nikalo aur temperature ke saath soft targets banao <br>• Student ke logits nikalo <br>• Soft loss aur hard loss combine karo (α ke weight se) <br>• Sirf student ke parameters pe backprop karo. |\n",
        "| **evaluate()**          | Validation set pe accuracy check karo taaki dekho student ka performance improve ho raha hai ya nahi.                        |\n",
        "| **Loop**                | Har epoch ke liye: `distill_epoch()` run karo + `evaluate()` call karo.                                                       |\n",
        "| **Save**                | Fine-tuned student model ko disk pe save kar do future inference ke liye.                                                     |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ic7PI1D4Rn3h"
      },
      "source": [
        "# Distillation: step-by-step (concise reference)\n",
        "\n",
        "> **Tip:** For very large datasets or multi-GPU/TPU training use Hugging Face’s `DistillationTrainer` or `accelerate`. The core algorithm below stays the same.\n",
        "\n",
        "---\n",
        "\n",
        "## Overview (what’s happening)\n",
        "1. Train a large **teacher** model (high capacity) normally and freeze it.  \n",
        "2. Train a smaller **student** model to mimic the teacher **and** the ground-truth labels.  \n",
        "3. Student loss = weighted combination of a **soft** (teacher) loss and a **hard** (label) loss.\n",
        "\n",
        "---\n",
        "\n",
        "## Step-by-step\n",
        "\n",
        "### 1. Teacher output (`t_soft`)\n",
        "- Compute teacher logits: `z_T = teacher(x)` (teacher is frozen; run under `torch.no_grad()`).\n",
        "- Apply **temperature** `T` and softmax to get *soft targets*:\n",
        "  \\[\n",
        "  p_T = \\text{softmax}\\!\\left(\\frac{z_T}{T}\\right)\n",
        "  \\]\n",
        "- `T > 1` “softens” the distribution (reveals class similarities).\n",
        "\n",
        "### 2. Student output (`s_soft`)\n",
        "- Compute student logits: `z_S = student(x)`.\n",
        "- Convert to log-probabilities at the same temperature:\n",
        "  \\[\n",
        "  \\log q_S = \\log\\text{softmax}\\!\\left(\\frac{z_S}{T}\\right)\n",
        "  \\]\n",
        "\n",
        "### 3. Distillation (soft) loss\n",
        "- Use KL divergence (teacher distribution → student distribution).\n",
        "- In PyTorch style: `nn.KLDivLoss(reduction='batchmean')(log_q_S, p_T)`\n",
        "- Multiply the KL loss by `T^2` to correct gradient scale (Hinton et al.):\n",
        "  \\[\n",
        "  L_{\\text{soft}} = T^2 \\cdot \\text{KL}(p_T \\,\\|\\, q_S)\n",
        "  \\]\n",
        "\n",
        "### 4. Hard (label) loss\n",
        "- Standard cross-entropy between student logits and true labels:\n",
        "  \\[\n",
        "  L_{\\text{hard}} = \\text{CE}(z_S, y)\n",
        "  \\]\n",
        "\n",
        "### 5. Combine\n",
        "- Weighted sum:\n",
        "  \\[\n",
        "  L = \\alpha \\cdot L_{\\text{soft}} + (1-\\alpha)\\cdot L_{\\text{hard}}\n",
        "  \\]\n",
        "- Typical choices: `T ∈ [2,5]`, `α ≈ 0.5` (tune for your task).\n",
        "- If `α = 1` → pure distillation (no hard labels). If `α = 0` → normal fine-tuning (no distillation).\n",
        "\n",
        "---\n",
        "\n",
        "## Implementation notes / best practices\n",
        "- Freeze teacher: `teacher.eval()` and use `with torch.no_grad()` when generating `z_T`. This saves memory and avoids updating teacher weights.\n",
        "- Use `F.softmax(z_T / T, dim=-1)` for teacher targets and `F.log_softmax(z_S / T, dim=-1)` for student input to `KLDivLoss`.\n",
        "- In PyTorch, prefer `nn.KLDivLoss(reduction='batchmean')` for stable gradients.\n",
        "- Multiply KL term by `T**2` (important — otherwise gradients from soft targets are scaled down).\n",
        "- Monitor both components (`L_soft`, `L_hard`) and validation accuracy.\n",
        "\n",
        "---\n",
        "\n",
        "## Small numeric example (temperature effect)\n",
        "- Teacher logits: `[10, 2]`\n",
        "  - `T = 1` → `softmax([10,2]) ≈ [0.9997, 0.0003]` (very peaked)\n",
        "  - `T = 2` → `softmax([5,1]) ≈ [0.982, 0.018]` (softer, reveals second choice)\n",
        "  - `T = 5` → `softmax([2,0.4]) ≈ [0.83, 0.17]` (much softer)\n",
        "- Softer distributions reveal the teacher’s relative beliefs and help the student learn nuanced class relations.\n",
        "\n",
        "---\n",
        "\n",
        "## Why distillation helps\n",
        "- **Soft targets** encode “dark knowledge”: relative similarities between classes that hard labels hide.  \n",
        "- Student learns both the dataset labels **and** the teacher’s nuanced behavior → better generalization for a much smaller model.\n",
        "\n",
        "---\n",
        "\n",
        "## Short pseudocode (conceptual)\n",
        "1. `z_T = teacher(x)`  (no grad)\n",
        "2. `p_T = softmax(z_T / T)`\n",
        "3. `z_S = student(x)`\n",
        "4. `log_q_S = log_softmax(z_S / T)`\n",
        "5. `loss_soft = T^2 * KLDiv(log_q_S, p_T)`\n",
        "6. `loss_hard = CrossEntropy(z_S, y)`\n",
        "7. `loss = alpha * loss_soft + (1 - alpha) * loss_hard`\n",
        "8. `loss.backward()` and `optimizer.step()` (update only student)\n",
        "\n",
        "---\n",
        "\n",
        "## Quick hyperparameter suggestions\n",
        "- `T = 2` (good starting point), try `2–5`.  \n",
        "- `alpha = 0.3–0.7` depending on trust in teacher vs labels.  \n",
        "- `batch size`: 64–256 (task-dependent).  \n",
        "- Ensure teacher has good accuracy before distillation.\n",
        "\n",
        "---\n",
        "\n",
        "## Final note\n",
        "Distillation is **not** just fine-tuning: it explicitly transfers the teacher’s learned distributional knowledge (soft targets) into a compact student while still respecting hard labels. For large-scale runs, use `DistillationTrainer` / `accelerate` to scale cleanly across devices.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sdjDT-ERfra",
        "outputId": "d636c730-48da-495e-f6ce-647fb34523d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.0.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (2025.3.0)\n",
            "Collecting fsspec\n",
            "  Using cached fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.54.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.34.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.7.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade datasets fsspec transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xDFVdc-H7Y7u"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "U1zai2NZxr79"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YsmgAOVS2ckB"
      },
      "outputs": [],
      "source": [
        "batch_size   = 16\n",
        "lr           = 5e-5\n",
        "epochs       = 1\n",
        "temperature  = 2.0\n",
        "alpha_soft   = 0.5\n",
        "max_len      = 128\n",
        "device       = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "69ip12Nz2evJ"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "raw = load_dataset(\"tweet_eval\", \"sentiment\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kCphqBQ_x5q0"
      },
      "outputs": [],
      "source": [
        "label_feature = raw[\"train\"].features[\"label\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mL2TDIQ3-RrC",
        "outputId": "39aed96b-93bb-47c7-b297-fd9678a7c146"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label names: ['negative', 'neutral', 'positive']\n"
          ]
        }
      ],
      "source": [
        "print(\"Label names:\", label_feature.names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "O8h_vsYox8hr"
      },
      "outputs": [],
      "source": [
        "# Subset (2.5k samples for train)\n",
        "train = raw['train'].shuffle(seed=42).select(range(2500))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rK8MRNdHyfeL"
      },
      "source": [
        "Why Train is Subset, but Val is Not\n",
        "\n",
        "🔹 1. Training cost is high, validation cost is low\n",
        "\n",
        "Training = multiple forward + backward passes → GPU heavy\n",
        "\n",
        "Validation = only forward pass, no gradient update → fast\n",
        "\n",
        "So it’s common to reduce training size for quick experiments but keep full validation for accurate metric evaluation.\n",
        "\n",
        "🔹 2. Keeping val full improves generalization check\n",
        "\n",
        "If you also reduce validation (e.g., from 872 → 100), metrics become noisy and unreliable.\n",
        "\n",
        "Full validation gives stable accuracy/loss during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "R344cVlw2kiu"
      },
      "outputs": [],
      "source": [
        "val   = raw['validation']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "pZ7DWOo22oqM"
      },
      "outputs": [],
      "source": [
        "#Tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "343oz61F2rYz"
      },
      "outputs": [],
      "source": [
        "def tokenize(example):\n",
        "    return tokenizer(example[\"text\"], truncation=True, max_length=max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "5GiRzIbhynnV"
      },
      "outputs": [],
      "source": [
        "# Tokenize & remove original text column\n",
        "tokenized = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "b38abe0848384e629c89bfff7ed2c880",
            "105b185aaa804a7aba4a1c441f64c11f",
            "5bf295acb8ab4517aae191a49681cadc",
            "8c027b904a124d2badd7b308127142dc",
            "708f3c5f9e1446d4be67ce89bf4a08d7",
            "5029c89c804143efa74cb4bf95f4f379",
            "77ff366eae15414d926c4647a62712ca",
            "65f08a7f4a18473eaf8d80b7c3ef013e",
            "f860cef2f6554f27ac59e2aa06b33872",
            "8a3b79955c5c4841b599811df227789e",
            "d7e4e24960be4bb4862d3529055c7d39"
          ]
        },
        "id": "E5IsoQQ327B3",
        "outputId": "fd2d5b4e-f310-4b1d-a5f4-cbfa89f419e6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b38abe0848384e629c89bfff7ed2c880",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenized['train'] = train.map(tokenize, batched=True, remove_columns=['text'])\n",
        "tokenized['validation'] = val.map(tokenize, batched=True, remove_columns=['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "6j65Youl2-VV"
      },
      "outputs": [],
      "source": [
        "# Data Collator (auto-padding)\n",
        "collator = DataCollatorWithPadding(tokenizer, pad_to_multiple_of=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_xx7gIvLy9JZ"
      },
      "outputs": [],
      "source": [
        "# DataLoaders\n",
        "train_dl = DataLoader(tokenized['train'], batch_size=batch_size,shuffle=True, collate_fn=collator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "x_DfUjRhSw_u"
      },
      "outputs": [],
      "source": [
        "val_dl = DataLoader(tokenized['validation'], batch_size=batch_size,shuffle=False, collate_fn=collator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "G42tryte3VX0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "vOPWt6vb9nnv"
      },
      "outputs": [],
      "source": [
        "num_labels = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qi44rdyBR96l",
        "outputId": "29398d6b-59de-418e-d148-a192b0f4c719"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "teacher = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"bert-large-uncased\", num_labels=num_labels).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFphv9J-SDwA",
        "outputId": "305e7b76-beb2-4458-f865-47e137b033ff"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "student = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", num_labels=num_labels).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxcJJBxaSDze",
        "outputId": "e415a1b5-9dd0-455b-beec-0665946c4899"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 1024)\n",
              "      (token_type_embeddings): Embedding(2, 1024)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-23): 24 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=1024, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Freeze teacher (no training)\n",
        "for p in teacher.parameters():\n",
        "    p.requires_grad = False\n",
        "teacher.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "R4c9GrXL0y3S"
      },
      "outputs": [],
      "source": [
        "ce_loss = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "1xTj0BAR00m2"
      },
      "outputs": [],
      "source": [
        "kl_loss = nn.KLDivLoss(reduction=\"batchmean\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "k2iu8MuB5sh1"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.AdamW(student.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "IwEFLyk_9LQQ"
      },
      "outputs": [],
      "source": [
        "from transformers import get_scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "cV-wcgUBSGdX"
      },
      "outputs": [],
      "source": [
        "lr_scheduler = get_scheduler(\n",
        "    name=\"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=len(train_dl) * epochs,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "YJMLeUVp9U9N"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "W_BujIB9SGg7"
      },
      "outputs": [],
      "source": [
        "def distill_epoch():\n",
        "    student.train()\n",
        "    pbar = tqdm(train_dl, desc=\"Train\")\n",
        "    for batch in pbar:\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention = batch[\"attention_mask\"].to(device)\n",
        "        labels    = batch[\"labels\"].to(device)\n",
        "\n",
        "        # Teacher predictions (soft targets)\n",
        "        with torch.no_grad():\n",
        "            t_logits = teacher(input_ids, attention_mask=attention).logits\n",
        "            t_soft   = torch.softmax(t_logits / temperature, dim=1)\n",
        "\n",
        "        # Student predictions\n",
        "        s_logits = student(input_ids, attention_mask=attention).logits\n",
        "        s_soft   = torch.log_softmax(s_logits / temperature, dim=1)\n",
        "\n",
        "        # Distillation + CE Loss\n",
        "        loss_soft = kl_loss(s_soft, t_soft) * (temperature ** 2)\n",
        "        loss_hard = ce_loss(s_logits, labels)\n",
        "        loss      = alpha_soft * loss_soft + (1 - alpha_soft) * loss_hard\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "ZdqA2MpaSLNn"
      },
      "outputs": [],
      "source": [
        "def evaluate():\n",
        "    student.eval()\n",
        "    correct = total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in val_dl:\n",
        "            ids  = batch[\"input_ids\"].to(device)\n",
        "            attn = batch[\"attention_mask\"].to(device)\n",
        "            lbl  = batch[\"labels\"].to(device)\n",
        "            out  = student(ids, attention_mask=attn).logits\n",
        "            pred = out.argmax(dim=1)\n",
        "            correct += (pred == lbl).sum().item()\n",
        "            total   += lbl.size(0)\n",
        "    return round(correct / total * 100, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "a4e7e0c4350a448ca8015d14b8c17ea9",
            "df0d001249cd4693b3dd7e61b1cdb21c",
            "707c6de352144b30a445edd786aa0be5",
            "d71dd1d8c66649e6943b4cdbe6e13f4b",
            "4b735c50bb1a473b8d9ff7604c33939b",
            "31877f5c2a3044cea968c0ed1a46aa9b",
            "a1f5e69ece2d40e0b9b784701a1fad4e",
            "97d02b8f51cb4739aa9ce1a8e59441a4",
            "b09050601203426fa2d0ad5ffe49ebab",
            "cc6d0f2d01d84783a4de9be9f44afbe6",
            "0440c704c9804f97ab8689ce6a650308"
          ]
        },
        "id": "QnJRKnQ-SLQh",
        "outputId": "694d7e1c-c9c6-49b0-da50-340d468de8e0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4e7e0c4350a448ca8015d14b8c17ea9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/157 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1 | Validation Accuracy: 62.7%\n"
          ]
        }
      ],
      "source": [
        "for ep in range(1, epochs + 1):\n",
        "    distill_epoch()\n",
        "    acc = evaluate()\n",
        "    print(f\"Epoch {ep}/{epochs} | Validation Accuracy: {acc}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAD-Zj5RxuDC",
        "outputId": "049b2270-150c-447a-c7fe-9c8543111f48"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('distilled_student_model/tokenizer_config.json',\n",
              " 'distilled_student_model/special_tokens_map.json',\n",
              " 'distilled_student_model/vocab.txt',\n",
              " 'distilled_student_model/added_tokens.json',\n",
              " 'distilled_student_model/tokenizer.json')"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ---------- 6. Save Student ----------\n",
        "student.save_pretrained(\"distilled_student_model\")\n",
        "tokenizer.save_pretrained(\"distilled_student_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "khH6Ls1a6zTC"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "import time\n",
        "\n",
        "def predict_and_evaluate(model, name, test_dl):\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "    start_time = time.time()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_dl:\n",
        "            ids = batch[\"input_ids\"].to(device)\n",
        "            attn = batch[\"attention_mask\"].to(device)\n",
        "            lbls = batch[\"labels\"].to(device)\n",
        "\n",
        "            logits = model(ids, attention_mask=attn).logits\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().tolist())\n",
        "            all_labels.extend(lbls.cpu().tolist())\n",
        "\n",
        "    total_time = time.time() - start_time\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    avg_time = total_time / len(test_dl.dataset)\n",
        "\n",
        "    print(f\"\\n {name}\")\n",
        "    print(f\" Accuracy: {acc*100:.2f}%\")\n",
        "    print(f\" Total Inference Time: {total_time:.2f} sec\")\n",
        "    print(f\" Avg Time per Sample: {avg_time:.4f} sec\")\n",
        "    return acc, total_time, avg_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "xlm2vWAG61M3"
      },
      "outputs": [],
      "source": [
        "# --------- Load test set ---------\n",
        "test = load_dataset(\"tweet_eval\", \"sentiment\", split=\"test[:500]\")  # sample test\n",
        "tokenized_test = test.map(tokenize, batched=True, remove_columns=[\"text\"])\n",
        "tokenized_test.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "test_dl = DataLoader(tokenized_test, batch_size=batch_size, shuffle=False, collate_fn=collator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGSKIYvR6oKE",
        "outputId": "d65d7b0e-7bf4-46f2-a043-ea521318a0fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " TEACHER (BERT-Large)\n",
            " Accuracy: 22.00%\n",
            " Total Inference Time: 3.63 sec\n",
            " Avg Time per Sample: 0.0073 sec\n",
            "\n",
            " STUDENT (Distilled BERT)\n",
            " Accuracy: 60.80%\n",
            " Total Inference Time: 1.16 sec\n",
            " Avg Time per Sample: 0.0023 sec\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.608, 1.1580901145935059, 0.0023161802291870115)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# --------- Compare Teacher vs Student ---------\n",
        "predict_and_evaluate(teacher, name=\"TEACHER (BERT-Large)\", test_dl=test_dl)\n",
        "predict_and_evaluate(student, name=\"STUDENT (Distilled BERT)\", test_dl=test_dl)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3b4GLbj8XX9"
      },
      "source": [
        "Backed by Research\n",
        "\n",
        "📄 “Distilling Step-by-Step” (Google, ACL 2023)\n",
        "\n",
        "A 770M T5 student outperformed PaLM-540B teacher on multiple tasks using rationale distillation.\n",
        "\n",
        "📄 TinyBERT paper (Huawei, 2020)\n",
        "\n",
        "Task-specific distillation allowed TinyBERT to beat BERT-base on SST-2 and MNLI."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z99VmmLn8fsn"
      },
      "source": [
        "| Reason                               | Explanation                                                            |\n",
        "| ------------------------------------ | ---------------------------------------------------------------------- |\n",
        "| **TweetEval = small, noisy data** | BERT-Large is overfitting or underconfident due to task size           |\n",
        "| **Student is fine-tuned**         | You updated student weights on TweetEval task                          |\n",
        "| **Teacher is frozen**             | You're using teacher just for soft logits, not re-finetuning           |\n",
        "| **Teacher not task-specific**     | Your BERT-Large is general, but student is task-tuned via distillation |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dojZn3098pJR"
      },
      "source": [
        "| Model   | Accuracy | Speed | Comment                                                 |\n",
        "| ------- | -------- | ----- | ------------------------------------------------------- |\n",
        "| Teacher | 22%      | Slow  | Not tuned, generic, likely overfitting/underfitting     |\n",
        "| Student | 60.8%    | Fast  | Task-specific distilled, learned from soft+hard targets |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "393EE1gZxLpE"
      },
      "source": [
        "## With LLM\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIpzbOSilMuT"
      },
      "source": [
        "Teacher (LLaMA‑2 7B) produces a probability distribution (next‑token probabilities) for each prompt.\n",
        "\n",
        "Student (TinyLLaMA 1.1B) is trained to:\n",
        "\n",
        "Mimic the teacher’s distribution (KLDivLoss → soft targets).\n",
        "\n",
        "Be correct on the ground‑truth labels (CrossEntropyLoss → hard targets).\n",
        "\n",
        "During each prompt, backpropagation updates only the Student’s weights.\n",
        "\n",
        "As a result, the Student copies the Teacher’s reasoning behavior while being smaller and faster.\n",
        "\n",
        "How is it run in practice?\n",
        "\n",
        "The given snippet is just a mini example (3 prompts).\n",
        "\n",
        "In real distillation:\n",
        "\n",
        "Use millions of prompts (including synthetic ones).\n",
        "\n",
        "Train in batches with Accelerate/DeepSpeed to manage GPU memory.\n",
        "\n",
        "Precompute and store teacher outputs offline, then train the Student on those for a faster pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NF2rn5VeVc-P"
      },
      "source": [
        "#### teacher_id = \"meta-llama/Llama-2-7b-chat-hf\"      # big model (teacher)\n",
        "#### student_id = \"TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T\"  # small model (student)\n",
        "\n",
        "#### teacher_id = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "#### student_id = \"TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQJwymo_VkWb",
        "outputId": "ebd338fb-6a22-4c55-92da-fb3308355892"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.54.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.9.0)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.46.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.34.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers accelerate bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "8IAkE7Cpr9Mz"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "021Z6qkALlSN"
      },
      "outputs": [],
      "source": [
        "teacher_id = \"microsoft/phi-2\"\n",
        "student_id = \"microsoft/phi-1_5\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "67YePLQtVtLj"
      },
      "outputs": [],
      "source": [
        "teacher_tokenizer = AutoTokenizer.from_pretrained(teacher_id)\n",
        "student_tokenizer = AutoTokenizer.from_pretrained(student_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "l35QRhI1Vvb9"
      },
      "outputs": [],
      "source": [
        "if teacher_tokenizer.pad_token is None:\n",
        "    teacher_tokenizer.pad_token = teacher_tokenizer.eos_token\n",
        "if student_tokenizer.pad_token is None:\n",
        "    student_tokenizer.pad_token = student_tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "7529b8ad8d8240678596d4aa1117eb6f",
            "97b3001459ea46068195ef1a487dbb6a",
            "8ea441ae61af4d8aae04493679a32061",
            "4dfbaf3ac8e84b8dae80028d5f7b2756",
            "648579bc6bbe49e1b9b1a783b0dbd212",
            "7a760d525e3b443c949724ff5c75bb68",
            "071dcdea4d814305805b5924769f7903",
            "53230f4538e74920b57473a09898f9ff",
            "9dca3fda68304bdab7af54cdf2c30b6f",
            "d4d5eaaa3b384bd5887a3077f8526d8f",
            "0baf82c3bb6a42a0a178a8eb6fdd4f4a"
          ]
        },
        "id": "Z-wOShxgsTdS",
        "outputId": "66073ac9-8052-4e11-d8f8-e1aff982a900"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7529b8ad8d8240678596d4aa1117eb6f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "teacher = AutoModelForCausalLM.from_pretrained(\n",
        "    teacher_id,\n",
        "    device_map=\"auto\",\n",
        "    load_in_8bit=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hn78LfrPV8pc",
        "outputId": "1f573cbc-3220-4eee-a13c-1957627aa740"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 1.6998e-02, -1.3275e-02,  2.0309e-02,  ...,  1.7822e-02,\n",
            "          5.1346e-03, -7.7343e-04],\n",
            "        [ 9.7351e-03,  5.1636e-02,  1.5656e-02,  ..., -6.7329e-03,\n",
            "          6.9389e-03, -1.1322e-02],\n",
            "        [-4.6387e-02, -9.0942e-03, -1.1349e-03,  ..., -3.0945e-02,\n",
            "          3.8940e-02,  1.3847e-02],\n",
            "        ...,\n",
            "        [-5.9605e-08,  5.9605e-08, -5.9605e-08,  ...,  1.5140e-05,\n",
            "         -1.1206e-05,  1.7762e-05],\n",
            "        [-0.0000e+00, -5.9605e-08, -1.1921e-07,  ..., -2.5094e-05,\n",
            "          3.7730e-05,  2.0683e-05],\n",
            "        [ 0.0000e+00, -5.9605e-08,  5.9605e-08,  ..., -1.6034e-05,\n",
            "         -1.5676e-05, -3.5882e-05]], device='cuda:0', dtype=torch.float16,\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 26,  -5, -23,  ..., -30,  15,  11],\n",
            "            [-37, -16, -10,  ...,  15,   0, -26],\n",
            "            [-22, -11,  -4,  ...,   0,   9,   9],\n",
            "            ...,\n",
            "            [-35, -26,   5,  ...,  20,  12,  34],\n",
            "            [-37,  50,  -2,  ...,  58, -21,   7],\n",
            "            [ 31, -28, -71,  ...,  -3, -12,  30]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0104, -0.1927, -0.1383,  ..., -0.0007,  0.0056, -0.0108],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-29,   2,  40,  ...,  -6,   5,  -5],\n",
            "            [ 31,  -1,   5,  ...,   8,   9,  10],\n",
            "            [ 22,  37,  -8,  ...,  12,  16,   0],\n",
            "            ...,\n",
            "            [  2,  10,  12,  ...,  23,   4,  27],\n",
            "            [ 94, -33,  -4,  ..., -44, -19, -26],\n",
            "            [-26,  36,  75,  ...,  -1, -14, -15]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0904, -0.2859, -0.1951,  ..., -0.0099,  0.0070,  0.0075],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-57,  -4, -15,  ...,  19,   9, -75],\n",
            "            [ -5,  -9,  25,  ...,   7,  26,  77],\n",
            "            [ 21,  28,  -5,  ..., -27, -26,  -8],\n",
            "            ...,\n",
            "            [-82,  11,  17,  ..., -60, -41,  -9],\n",
            "            [ 20, -36, -19,  ...,  57, -52, -53],\n",
            "            [-60,  42, -10,  ..., -19, -43,   0]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0001,  0.0042, -0.0034,  ..., -0.0035, -0.0052,  0.0022],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 10,   9, -36,  ...,   8,  33, -34],\n",
            "            [ 49,   1, -19,  ..., -29, -38,   0],\n",
            "            [  8,  27,   3,  ..., -10,  22, -18],\n",
            "            ...,\n",
            "            [  3,  -3,  43,  ...,  10,   0,  21],\n",
            "            [ 17,  83,  15,  ...,  17,  18,  36],\n",
            "            [  5,  11,  33,  ...,  48,  -5,  42]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0291,  0.0069,  0.0309,  ..., -0.0225, -0.0260,  0.0126],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-35,  22,  25,  ...,   7,   3, -27],\n",
            "            [  2,   5, -12,  ..., -24,   0,  -1],\n",
            "            [ -3,  21, -40,  ...,   3, -19,  14],\n",
            "            ...,\n",
            "            [-16,  -3, -30,  ..., -38,  75,  47],\n",
            "            [-19, -21,   5,  ...,  33,   9,  23],\n",
            "            [-85, -25,  24,  ...,  42, -20, -24]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0089, -0.0109, -0.0138,  ..., -0.0003, -0.0011, -0.0001],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 31,  -7,   5,  ...,   0,   0,  -1],\n",
            "            [ 29,   7,  49,  ...,   0,  -1,   2],\n",
            "            [ -2, -19, -46,  ...,   0,  -1,   0],\n",
            "            ...,\n",
            "            [ 35, -33, -61,  ...,   0,   0,   0],\n",
            "            [  2,  -9,  22,  ...,   0,  -1,   1],\n",
            "            [-30, -18, -15,  ...,  -1,  -2,   1]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0034, -0.0016,  0.0121,  ..., -0.0100, -0.0020,  0.0042],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "tensor([0.2576, 0.2559, 0.2637,  ..., 0.2571, 0.2544, 0.2524], device='cuda:0',\n",
            "       dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0062,  0.0076,  0.0087,  ..., -0.0238, -0.0254, -0.0201],\n",
            "       device='cuda:0', dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ -3,  15,  42,  ..., -18,  67,   9],\n",
            "            [-18, -35,  41,  ..., -63, -67,  36],\n",
            "            [-34,  38,  20,  ...,  11,   0, -41],\n",
            "            ...,\n",
            "            [ -9, -54, -20,  ...,  12,   2,  42],\n",
            "            [-61,  33,   2,  ..., -52,  -8,  -5],\n",
            "            [-51,  35,  -6,  ..., -54,   7,  28]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0260, -0.0136,  0.0460,  ..., -0.0315,  0.0221, -0.0188],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-12,  26, -74,  ...,  16, -19, -51],\n",
            "            [ 54,  59,  69,  ...,  73,  19, -24],\n",
            "            [-71, -76,  59,  ...,  18,  51,  25],\n",
            "            ...,\n",
            "            [ 36,  -4,  44,  ...,  -3, -63,  -6],\n",
            "            [ 10, -18,  -3,  ..., -84,  55,  24],\n",
            "            [ 19, -38, -16,  ...,  61,  54, -15]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0420, -0.0201, -0.0484,  ..., -0.0077,  0.0058, -0.0015],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[  3, -17,  54,  ..., -67, -28,   1],\n",
            "            [-14,  61,  17,  ...,  41, -66,   4],\n",
            "            [ 55, -19, -76,  ..., -42,  -8,  19],\n",
            "            ...,\n",
            "            [-54, -77,   8,  ...,  18,  -8,  14],\n",
            "            [ 29, -26,  15,  ...,  11,   6,  14],\n",
            "            [  2,  96, -15,  ...,  23,   0, -25]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0025,  0.0007,  0.0035,  ...,  0.0012, -0.0008, -0.0002],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 11,  37,   1,  ...,   4,  34,   3],\n",
            "            [ 15,  26,  -2,  ..., -73, -45,  54],\n",
            "            [-17, -32,  30,  ...,  10,  -1, -43],\n",
            "            ...,\n",
            "            [  6,  25, -44,  ..., -25,   6,   5],\n",
            "            [  6,   7, -25,  ...,  -4,  34,  20],\n",
            "            [-46,  28,  42,  ...,  25,   5,  23]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0011,  0.0139,  0.0414,  ...,  0.0316,  0.0585,  0.0575],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 14,  44, -22,  ..., -31,  73,  30],\n",
            "            [ 18,  37, -27,  ...,  22,   8,   5],\n",
            "            [ 12,  36,  40,  ...,  29,  37,  21],\n",
            "            ...,\n",
            "            [ 21, -14,   9,  ..., -28,  11, -11],\n",
            "            [ 16,  -1,  -9,  ..., -20,  -8, -26],\n",
            "            [-49,  50, -12,  ..., -38, -51,  30]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0759, -0.0588, -0.0675,  ...,  0.0042, -0.0092, -0.0007],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ -4,   7,   2,  ...,  -9,  -4,  21],\n",
            "            [-25,  -5,  21,  ...,   8,   2, -16],\n",
            "            [-53,  -4,  15,  ...,  -9,   8,   3],\n",
            "            ...,\n",
            "            [-31, -10,  26,  ...,  17,   9,  14],\n",
            "            [ 47,  60,  -7,  ...,   4,  -2,  11],\n",
            "            [-44, -25, -26,  ...,  -2,  11,  -7]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0166, -0.0105,  0.0282,  ...,  0.0156, -0.0084,  0.0034],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "tensor([0.3474, 0.3384, 0.2546,  ..., 0.4014, 0.4192, 0.3977], device='cuda:0',\n",
            "       dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0181, -0.0461, -0.0308,  ..., -0.0376, -0.0509, -0.0167],\n",
            "       device='cuda:0', dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[  7,  36,   1,  ...,  41, -12, -32],\n",
            "            [  5, -16,  28,  ..., -85,  39, -38],\n",
            "            [ -5, -41, -17,  ...,  -6, -35,  14],\n",
            "            ...,\n",
            "            [-11, -22,   9,  ...,  -6,  24,   7],\n",
            "            [  9, -19, -35,  ...,  19,   8,  -3],\n",
            "            [-72,  14, -13,  ...,  44, -21,  -2]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0044,  0.0092, -0.0077,  ..., -0.0303,  0.0091,  0.0315],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 15,  -7, -25,  ...,  -9, -12, -18],\n",
            "            [ 31,  13,  13,  ...,  45, -26,  -1],\n",
            "            [ 12,  37,  21,  ...,  46, -18, -16],\n",
            "            ...,\n",
            "            [ 12, -25, -28,  ...,  31, -89, -19],\n",
            "            [ -4,  31,  37,  ...,  -6,  34, -14],\n",
            "            [ -2,  27, -23,  ...,   3,   5,  17]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0317, -0.0086, -0.0254,  ..., -0.0008,  0.0010, -0.0060],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ -18,  -55,   41,  ...,    3,  -53,  -23],\n",
            "            [ -12,   -8,    8,  ...,   24,  -30,   17],\n",
            "            [ -26,  -42,  -35,  ...,   25,    6,    8],\n",
            "            ...,\n",
            "            [ -25,  -26,  -15,  ...,  -15,    4,   24],\n",
            "            [ -55,   12,   38,  ...,  -51, -100,   67],\n",
            "            [ -23,  -61,  -43,  ...,  -40,   -4,   39]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-9.8884e-05,  2.2602e-03, -6.3801e-04,  ...,  1.6441e-03,\n",
            "         1.1044e-03,  2.1982e-04], device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-47,  13,  17,  ...,   2, -16,  43],\n",
            "            [  2,   2, -17,  ..., -11,  35,  50],\n",
            "            [-44,  13, -34,  ...,  22,   1,  27],\n",
            "            ...,\n",
            "            [-57,  24,  81,  ..., -10,  32,  95],\n",
            "            [ 83,  19, -27,  ..., -29,  66,  19],\n",
            "            [ 38,  13, -21,  ..., -10,   3, -65]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0322, -0.0098,  0.0215,  ..., -0.0195, -0.0062,  0.0864],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-15,   0,  70,  ..., -36,  71,   1],\n",
            "            [ 19, -51,  -5,  ...,  11,  13,  58],\n",
            "            [-12, -12,  -1,  ..., -62,  11,  78],\n",
            "            ...,\n",
            "            [-31,  18,  33,  ...,  26,  75,  13],\n",
            "            [ -1,   3,  26,  ...,   0,  21,  28],\n",
            "            [-16,  -9,  28,  ...,  17,  19,  18]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0568, -0.0500, -0.0627,  ...,  0.0137,  0.0066, -0.0010],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-38,  32,  47,  ...,  11,   1,  11],\n",
            "            [-38, -19, -28,  ...,  -9, -10,   2],\n",
            "            [-51, -16, -26,  ..., -18,  -9,  -7],\n",
            "            ...,\n",
            "            [-44,  -7, -21,  ...,   0,   6,  -1],\n",
            "            [-48,  36,  58,  ..., -19, -17,  -9],\n",
            "            [  9,  19,  20,  ..., -15, -12,   4]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0198, -0.0131,  0.0277,  ...,  0.0086,  0.0075, -0.0081],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "tensor([0.4011, 0.3906, 0.3223,  ..., 0.4294, 0.4387, 0.4277], device='cuda:0',\n",
            "       dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0210, -0.0227,  0.0398,  ..., -0.0077, -0.0091, -0.0241],\n",
            "       device='cuda:0', dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 21, -24,  54,  ...,  11,  -5, -18],\n",
            "            [ 23, -28,  93,  ...,   8,  15,   2],\n",
            "            [  2, -29,  78,  ...,  -7,   3,  19],\n",
            "            ...,\n",
            "            [ 18, -10,   2,  ..., -10,   7,  28],\n",
            "            [ -8,   1,  35,  ...,  18, -13,  -3],\n",
            "            [ 15, -26,  -1,  ...,  -1,   0,  15]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0484,  0.1321,  0.0542,  ...,  0.0470,  0.0821,  0.0778],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 12,  52, -46,  ...,  28, -38,  62],\n",
            "            [-12,  24,  11,  ...,   9,  10, -37],\n",
            "            [ -1, -64,  45,  ...,  -4,  33, -26],\n",
            "            ...,\n",
            "            [  8,  23, -74,  ...,   6,   4,  -5],\n",
            "            [ -2,   3,   0,  ..., -29,  10,   4],\n",
            "            [ 26,  14, -46,  ..., -41,  29,  -7]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0340, -0.1097, -0.0490,  ..., -0.0017,  0.0052,  0.0001],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 37, -32,  33,  ..., -61, -59,   1],\n",
            "            [  1, -18,   4,  ...,  22,  44,  26],\n",
            "            [-37,  53, -30,  ...,  86, -61,  15],\n",
            "            ...,\n",
            "            [-57,   2,  -8,  ...,  28, -16,   0],\n",
            "            [ 20,  91, -18,  ...,   3, -19, -26],\n",
            "            [-66, -46,   5,  ...,  -6,   8,  23]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0010, -0.0014,  0.0021,  ...,  0.0026, -0.0019, -0.0017],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[  9, -26,  10,  ...,  12,  58,  37],\n",
            "            [ 18,  12, -12,  ...,  13, -49,  -5],\n",
            "            [ -1, -18,  -3,  ..., -16,  93, -10],\n",
            "            ...,\n",
            "            [ 40, -26,  24,  ...,  -7, -13, -11],\n",
            "            [ 37, -15, -32,  ...,  25,  48, -55],\n",
            "            [ 39,  15,  28,  ...,  -2, -28, -11]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0014,  0.0163,  0.0272,  ..., -0.0083, -0.0203,  0.0158],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-13,   7, -57,  ..., -19,   5,  -5],\n",
            "            [ 57, -16, -28,  ..., -41,  43,  34],\n",
            "            [ 18, -40, -18,  ...,  21,   7,  -4],\n",
            "            ...,\n",
            "            [  8, -26,  23,  ...,  19,  79, -47],\n",
            "            [-32,  24, -18,  ...,  37,  32, -18],\n",
            "            [-22,   7,  22,  ...,  10,  19, -23]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0497, -0.0173, -0.0459,  ..., -0.0139, -0.0004, -0.0074],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-12, -29, -24,  ...,   1,   7,   0],\n",
            "            [ 22, -19, -50,  ..., -41,   1, -23],\n",
            "            [-29,  16,  23,  ...,  17,   6,  -8],\n",
            "            ...,\n",
            "            [ 16,   2,   9,  ...,   4,  -2,  11],\n",
            "            [  4, -18,  12,  ...,  13, -15,  39],\n",
            "            [-25,  -5,  39,  ...,  18, -13, -30]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0010, -0.0224,  0.0431,  ..., -0.0035,  0.0067,  0.0150],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "tensor([0.4709, 0.4551, 0.4177,  ..., 0.4868, 0.4917, 0.4888], device='cuda:0',\n",
            "       dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0213, -0.0114,  0.0718,  ..., -0.0094, -0.0103, -0.0165],\n",
            "       device='cuda:0', dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 34, -21, 111,  ..., -21,   3,  -7],\n",
            "            [ -1,  26, -52,  ..., -24, -27,  30],\n",
            "            [-20, -46,  46,  ...,  -6,   0,  44],\n",
            "            ...,\n",
            "            [ 30,  -9, -21,  ..., -35,  -5, -19],\n",
            "            [ 18,  12,   3,  ..., -21,  21,  -8],\n",
            "            [-17,   0,  22,  ...,   0,  -2,  29]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0419, -0.0155,  0.0351,  ..., -0.0059,  0.0024, -0.0299],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ -7,  12,   3,  ...,  59,  69, -32],\n",
            "            [-41,  -1, -60,  ...,  -2,  19, -44],\n",
            "            [ 58,  -1, -11,  ...,   8,  18, -40],\n",
            "            ...,\n",
            "            [ 29,  19,  14,  ..., -14, -13,  25],\n",
            "            [ 20,  -8, -10,  ...,  -8, -38,  15],\n",
            "            [ 16,  41, -25,  ...,  -9,   0,   4]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0301,  0.0121, -0.0194,  ...,  0.0117,  0.0052, -0.0046],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[  6, -49,  14,  ...,  -7, -23,  25],\n",
            "            [-44,  10,  31,  ..., -23,  33, -56],\n",
            "            [-56,  70,  -8,  ..., -60,  21,   9],\n",
            "            ...,\n",
            "            [-40,  -2,  34,  ...,  43, -43, -55],\n",
            "            [ 49,  54,  37,  ...,  37,  13, -25],\n",
            "            [-38,  21,   6,  ...,  13,  64,  37]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0026,  0.0036, -0.0013,  ..., -0.0044,  0.0006, -0.0013],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 54, -33,   3,  ..., -25,  17, -43],\n",
            "            [ -2,  -5,  11,  ...,  76, -19, -39],\n",
            "            [  5,  24,  -8,  ...,   7,  21,   3],\n",
            "            ...,\n",
            "            [ 14, -19,  11,  ...,   4,  26,  11],\n",
            "            [-12,  -1, -17,  ...,  -9,  -9,  20],\n",
            "            [ 15, -13, -45,  ..., -34,   8,  21]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0271, -0.0133,  0.0334,  ..., -0.0179,  0.0064, -0.0078],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 20, -31,  47,  ...,  70, -14,  40],\n",
            "            [-30,  29, -46,  ..., -15,  50, -18],\n",
            "            [  5, -24,  -3,  ...,  49, -17, -37],\n",
            "            ...,\n",
            "            [ 31,  -9, -19,  ...,  24, -31, -86],\n",
            "            [ 26, -22, -15,  ...,  48, -23,  -2],\n",
            "            [ 37,  11, -22,  ..., -19, -18, -29]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0415, -0.0056, -0.0331,  ...,  0.0166, -0.0050, -0.0006],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[  9,  28,  11,  ..., -15, -15,  -9],\n",
            "            [-11, -36,  -7,  ..., -16, -12,  14],\n",
            "            [ 13,   7, -16,  ...,  -2, -14,   2],\n",
            "            ...,\n",
            "            [-19,  24,  18,  ..., -14, -27,  -1],\n",
            "            [  5,   0, -24,  ...,  33,   8,  23],\n",
            "            [ 40, -31,  -4,  ...,  23,  -8, -11]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0056, -0.0193,  0.0410,  ...,  0.0058,  0.0120,  0.0101],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "tensor([0.4580, 0.4580, 0.4241,  ..., 0.4858, 0.4751, 0.4773], device='cuda:0',\n",
            "       dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0183, -0.0162,  0.0682,  ..., -0.0079, -0.0137, -0.0155],\n",
            "       device='cuda:0', dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[  2,  34,  24,  ..., -15,  -5,  34],\n",
            "            [ 34,  -7, -45,  ...,  64, -14, -84],\n",
            "            [ 46, -68,  19,  ...,  -4,   8,  45],\n",
            "            ...,\n",
            "            [ -2,  23,  -5,  ..., -16,  20,  -2],\n",
            "            [ 65,  11,  10,  ...,  -8, -68, -51],\n",
            "            [ 54, -31, -23,  ..., -11,  -7, -43]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0545, -0.0359,  0.0290,  ...,  0.0062, -0.0049, -0.0007],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-10, -34, -22,  ...,  10,  11, -16],\n",
            "            [  5,   5,  28,  ...,  10, -64,  67],\n",
            "            [-42,  -3,  41,  ...,  -4,  44, -21],\n",
            "            ...,\n",
            "            [ 36,  16,  59,  ...,  -5, -17,   5],\n",
            "            [-74, -28, -55,  ...,  -3,  71, -40],\n",
            "            [-33,  58,  47,  ...,  26, -15,  63]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0312,  0.0304, -0.0128,  ...,  0.0103, -0.0034,  0.0107],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-16,  60,  -1,  ...,   6,  14, -19],\n",
            "            [-14, -46,   2,  ..., -52, -31, -26],\n",
            "            [-18,  26, -37,  ...,  28,  21,  39],\n",
            "            ...,\n",
            "            [-12, -22, -13,  ..., -16,  17,  71],\n",
            "            [ -5,  45,  13,  ...,  -7, -48, -21],\n",
            "            [-39, -11,  40,  ...,  45, -20, -28]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 5.1765e-03,  2.6941e-04, -1.9169e-03,  ...,  2.0981e-05,\n",
            "        -6.9618e-04,  3.2496e-04], device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[  1,  68, -19,  ..., -43,  12,  -8],\n",
            "            [  1, -69, -25,  ..., -51,  22, -47],\n",
            "            [ -4,  32, -33,  ...,   0,  -3,  11],\n",
            "            ...,\n",
            "            [ -5,   2,  24,  ...,  -7,  55, -25],\n",
            "            [ 11, -22, -61,  ...,   4,  41,   3],\n",
            "            [  3,  12,  15,  ..., -36,  30,  -4]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0115, -0.0013,  0.0188,  ..., -0.0446,  0.0236,  0.0071],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 42, -60, -62,  ..., -75, -38,  -6],\n",
            "            [-49,  -2, -12,  ...,  15,  10, -92],\n",
            "            [-33,  -5,   2,  ...,  23,  68,  34],\n",
            "            ...,\n",
            "            [  7, -20, -16,  ..., -61,  61, -84],\n",
            "            [ 41, -38, -14,  ...,  78, -19, -30],\n",
            "            [ 17,  59, -45,  ...,  24,  15, -14]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-3.4729e-02, -4.4342e-02, -5.1666e-02,  ..., -3.4928e-05,\n",
            "        -3.9368e-03, -1.9608e-03], device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 15, -22,  -5,  ..., -17,  -3, -21],\n",
            "            [-30,   2,  13,  ...,   7,   7, -11],\n",
            "            [ 13,  -1,  31,  ...,  -4,  -8,  37],\n",
            "            ...,\n",
            "            [ -4,  -1,  22,  ...,  39, -33, -19],\n",
            "            [-21,  18,  -6,  ..., -35,  17, -16],\n",
            "            [  8,  -9,  -9,  ...,  47,   3,  -1]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0128, -0.0145,  0.0635,  ...,  0.0260,  0.0016, -0.0041],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "tensor([0.4224, 0.4263, 0.4116,  ..., 0.4309, 0.4329, 0.4336], device='cuda:0',\n",
            "       dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0174, -0.0139,  0.0710,  ..., -0.0078, -0.0114, -0.0136],\n",
            "       device='cuda:0', dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[  8, -12, -50,  ..., -25, -70, -45],\n",
            "            [ 14,  23, -13,  ..., -10,  18, -22],\n",
            "            [ 24,  26,   2,  ...,  17,  26, -60],\n",
            "            ...,\n",
            "            [ 60,   8,  36,  ...,  67, -41,  53],\n",
            "            [-31,  32,  -7,  ...,  18,  16,  38],\n",
            "            [-40, -22,   1,  ...,  -7,  -3,   0]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0515, -0.0522, -0.0067,  ..., -0.0058, -0.0175,  0.0065],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 38,  12, -14,  ...,   1,  -8,  38],\n",
            "            [-45,  21,  12,  ...,  23, -17,  14],\n",
            "            [-22,  13,  30,  ...,  20, -29, -15],\n",
            "            ...,\n",
            "            [-58,  49,  22,  ...,  21, -79,   7],\n",
            "            [-23,  28,  20,  ...,  46, -16,  -7],\n",
            "            [ 46,  46, -58,  ..., -30, -22,  38]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0225,  0.0105,  0.0130,  ..., -0.0177, -0.0017,  0.0040],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[  2, -13, -22,  ...,  14, -54, -17],\n",
            "            [ -7,  20, -23,  ...,  24,  25,   3],\n",
            "            [-15, -58, -36,  ..., -26,   6,  43],\n",
            "            ...,\n",
            "            [ 50,  -4, -17,  ..., -58,  11, -16],\n",
            "            [ 26,  38,  27,  ..., -11, -42, -38],\n",
            "            [-27,  59,  10,  ...,  59, -42,  33]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 4.4861e-03,  6.0499e-05,  4.7922e-04,  ...,  1.3609e-03,\n",
            "         9.0313e-04, -2.4681e-03], device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[  3,  22,  11,  ...,  38, -59, -22],\n",
            "            [-31,  33, -60,  ...,   0,  33,  -6],\n",
            "            [-23, -14, -27,  ...,  -3, -46, -16],\n",
            "            ...,\n",
            "            [ 44,   0,  -1,  ...,  39,  -8,  13],\n",
            "            [ 17,  -5,  15,  ...,  18, -34,  20],\n",
            "            [-16,   9, -21,  ...,  10,  14, -42]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0053,  0.0113, -0.0191,  ..., -0.0374,  0.0113,  0.0245],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 22, -82, -36,  ..., -23, -79, -12],\n",
            "            [ -3, -37, -98,  ...,  32,  80, -26],\n",
            "            [ 41,  28,  49,  ..., -48,  37,  83],\n",
            "            ...,\n",
            "            [-16,  25,  69,  ...,  -6,  34, -58],\n",
            "            [-34,  58,   1,  ...,  14,  24,  -5],\n",
            "            [ -6,  18,  32,  ...,   4,  15, -44]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0321, -0.0439, -0.0569,  ..., -0.0095, -0.0272, -0.0102],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 50,  13,  23,  ...,  -5,  40,  11],\n",
            "            [-30, -26,  -6,  ...,  -4,  -8,  -2],\n",
            "            [ -1,  -2,  -3,  ...,  -7,   2,  -8],\n",
            "            ...,\n",
            "            [ -3,   6, -14,  ..., -11, -30,   8],\n",
            "            [ 34,   1,  -5,  ...,   9,  76,  21],\n",
            "            [ -9,   3,  16,  ...,  25, -28,  17]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0329, -0.0193,  0.0616,  ...,  0.0328,  0.0147,  0.0137],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "tensor([0.4507, 0.4495, 0.4343,  ..., 0.4597, 0.4465, 0.4534], device='cuda:0',\n",
            "       dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0160, -0.0143,  0.0925,  ..., -0.0066, -0.0086, -0.0194],\n",
            "       device='cuda:0', dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-10,  68,  15,  ...,  46,   5,  32],\n",
            "            [ -2, -67,  -1,  ..., -40, -59,   6],\n",
            "            [ 22, -24, -16,  ...,  12, -37,  -9],\n",
            "            ...,\n",
            "            [ -9,  41,  -1,  ..., -17, -47, -61],\n",
            "            [ -3, -68,  -1,  ..., -30,  40,  12],\n",
            "            [-14,   3,  -6,  ...,   7,   4,   4]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0019,  0.0036, -0.0125,  ..., -0.0049,  0.0181, -0.0079],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[  2,  -7,  21,  ...,   7,   9,   6],\n",
            "            [ 34, -29, -26,  ...,   3, -30, -21],\n",
            "            [ -3,   1, -47,  ..., -64,  24, -11],\n",
            "            ...,\n",
            "            [ 17, -90, -11,  ...,  31,  16,  46],\n",
            "            [-30,  11,  22,  ...,  23,  -9,  -3],\n",
            "            [-11,  24,  28,  ...,  24, -25,  24]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0229, -0.0227, -0.0065,  ...,  0.0050,  0.0190, -0.0527],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 36,  27, -25,  ...,  17,   1,  28],\n",
            "            [  2,  44,   0,  ..., -44,  11, -22],\n",
            "            [-30,  10,  -6,  ...,  71,  -5,  27],\n",
            "            ...,\n",
            "            [-77,  -9,   2,  ...,  18,  -7, -16],\n",
            "            [ 18, -11,  -4,  ...,   4,  40, -28],\n",
            "            [-10,  14,   8,  ..., -11,  26,  54]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0007, -0.0004, -0.0008,  ...,  0.0017,  0.0007, -0.0015],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-32,  15, -33,  ...,  11, -14,   2],\n",
            "            [ 32,   2,   2,  ...,  -4, -27,  -7],\n",
            "            [ 32,  18,  72,  ...,  -7,  20, -25],\n",
            "            ...,\n",
            "            [ 22, -18,  32,  ...,  14,  19,  24],\n",
            "            [ 34,   2, -87,  ...,  -5,  88,  -6],\n",
            "            [ -7, -63, -57,  ...,  -3,  42, -10]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([0.0299, 0.0041, 0.0151,  ..., 0.0077, 0.0111, 0.0247], device='cuda:0',\n",
            "       dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 56,  40, -41,  ..., -17,  33, -45],\n",
            "            [ 17, -45, -58,  ...,  -6,  12,   0],\n",
            "            [ -5, -30, -47,  ..., -36, -19, -46],\n",
            "            ...,\n",
            "            [ 24, -55, -26,  ..., -16, -49, -18],\n",
            "            [-48,  11, -11,  ...,  -8, -51,   2],\n",
            "            [  9,  31, -17,  ...,  -8, -11,  45]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0374, -0.0427, -0.0417,  ...,  0.0103,  0.0071,  0.0121],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 54,  28,  -5,  ..., -21,  28,   2],\n",
            "            [ 23,  -6,   4,  ...,  14,   3,  -7],\n",
            "            [-24,  -7,   3,  ...,  13,   6,   0],\n",
            "            ...,\n",
            "            [ 25,  22, -19,  ...,   5,  12,  23],\n",
            "            [ 11, -12,  13,  ...,  32,  25, -11],\n",
            "            [ 32, -13, -30,  ...,  -9,   6, -17]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0213, -0.0051,  0.0466,  ...,  0.0431, -0.0113, -0.0084],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "tensor([0.4543, 0.4556, 0.4368,  ..., 0.4595, 0.4497, 0.4585], device='cuda:0',\n",
            "       dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0157, -0.0177,  0.0913,  ..., -0.0037, -0.0090, -0.0137],\n",
            "       device='cuda:0', dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-102,   20,   11,  ...,   15,   17,   33],\n",
            "            [   3,   51,   86,  ...,  -26,   66,  -40],\n",
            "            [  34,  -49,   32,  ...,   28,   -8,   -3],\n",
            "            ...,\n",
            "            [ -38,  -17,    1,  ...,  -39,   33,   -1],\n",
            "            [  17,   33,   33,  ...,  -11,  -40,   -5],\n",
            "            [ -21,  -57,   13,  ...,   -6,  -13,   18]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0179,  0.0158,  0.0170,  ...,  0.0077, -0.0018, -0.0085],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[  8, -46,  39,  ..., -30,  30,  -6],\n",
            "            [ 12,   7,  25,  ...,  28,   8,  -5],\n",
            "            [  6,  15,   7,  ...,  27, -15, -51],\n",
            "            ...,\n",
            "            [ 25,   1, -27,  ..., -19,  58,  16],\n",
            "            [  3,   9,   9,  ...,  13,  -3, -40],\n",
            "            [-53,   7,   9,  ...,   0,   4,  40]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0284, -0.0167, -0.0194,  ...,  0.0068, -0.0113,  0.0036],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-24,  21, -11,  ...,  10,  19, -27],\n",
            "            [-19, -46, -11,  ...,   2, -24,   5],\n",
            "            [ 38, -19, -17,  ..., -22,  20, -41],\n",
            "            ...,\n",
            "            [-60,  -1, -11,  ...,  45,   2, -18],\n",
            "            [ 29, -13,  29,  ...,  10,  39, -15],\n",
            "            [-44, -12,  -6,  ..., -11, -36,   5]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0020,  0.0024,  0.0028,  ..., -0.0003, -0.0005,  0.0018],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-41,  21, -48,  ...,   8, -14,  -7],\n",
            "            [ -8, -70, -31,  ..., -42,  -3,  38],\n",
            "            [-33,  41,   1,  ...,  15, -17, -43],\n",
            "            ...,\n",
            "            [-19,  26,   1,  ...,  -1, -25,  15],\n",
            "            [ -2,  31,   4,  ..., -67,  17,  -6],\n",
            "            [ -9,   4, -42,  ...,   5,  34,  23]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0104, -0.0029,  0.0104,  ..., -0.0240,  0.0224, -0.0060],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[  3, -43,   3,  ...,  28, -52,  58],\n",
            "            [-26,  -5,  -3,  ..., -17, -33,   8],\n",
            "            [-21, -35, -42,  ..., -50,  28,  -2],\n",
            "            ...,\n",
            "            [ -1, -42, -33,  ...,  97,   4, -43],\n",
            "            [  6,  13, -37,  ...,  79,  11,   7],\n",
            "            [  7,  28,   0,  ..., -25, -83, -15]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0462, -0.0233, -0.0525,  ...,  0.0061, -0.0135, -0.0105],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 17, -10,  26,  ..., -12,   7,   1],\n",
            "            [  9, -26,  23,  ...,  25,   2,  22],\n",
            "            [  1, -13, -20,  ...,  15,   3,  -4],\n",
            "            ...,\n",
            "            [ 35, -31,  25,  ...,  -3, -25,  24],\n",
            "            [ 13, -10,   2,  ...,  11, -14,  40],\n",
            "            [  0,  32, -13,  ..., -18,   0,  28]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0039,  0.0040,  0.0622,  ...,  0.0499, -0.0087,  0.0111],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "tensor([0.4629, 0.4592, 0.4199,  ..., 0.4731, 0.4595, 0.4592], device='cuda:0',\n",
            "       dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0170, -0.0168,  0.0950,  ..., -0.0042, -0.0135, -0.0182],\n",
            "       device='cuda:0', dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-48, -29,  74,  ...,  17,  33,  -1],\n",
            "            [-32,  -5,  18,  ..., -16,   3, -16],\n",
            "            [-26,  47,  -3,  ...,  25,   2,  22],\n",
            "            ...,\n",
            "            [  8,  34,  -6,  ...,  10,   5, -42],\n",
            "            [ 50, -69,  11,  ...,  30,  39, -20],\n",
            "            [  9, -24,  -6,  ...,  86,  15, -27]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0220,  0.0423, -0.0207,  ..., -0.0199, -0.0189,  0.0167],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-15,  22, -27,  ...,  -5,   4,  -2],\n",
            "            [ 10,  10,   6,  ...,  -6, -17,  11],\n",
            "            [ 15,  56,  46,  ..., -19, -20,  71],\n",
            "            ...,\n",
            "            [-24, -34,  11,  ...,   7,   9, -24],\n",
            "            [ -3, -37,  14,  ...,  44, -28, -36],\n",
            "            [-20,  43,  52,  ..., -20, -17,  29]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0271,  0.0054, -0.0447,  ..., -0.0090,  0.0168, -0.0059],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-10,  78,  39,  ...,  -1,  42, -25],\n",
            "            [-63,   5,   6,  ...,   3, -45,  12],\n",
            "            [  0, -67,  36,  ...,  29,  38,  52],\n",
            "            ...,\n",
            "            [  5,  59,  -4,  ...,  17,  -4,   5],\n",
            "            [ 37, -10,  13,  ...,  13,  36,  41],\n",
            "            [-41,  41,  -3,  ..., -71, -41,  -7]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 1.8377e-03,  1.0347e-03,  4.5002e-05,  ...,  1.4601e-03,\n",
            "        -1.0328e-03,  1.5688e-03], device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-19,  65, -25,  ...,   9,   5, -36],\n",
            "            [-32, -42,  48,  ...,  22, -36, -14],\n",
            "            [-41, -21, -36,  ...,  18, -27, -12],\n",
            "            ...,\n",
            "            [  2, -14, -56,  ..., -24,  26,   7],\n",
            "            [-42,  54, -34,  ...,  -3, -33,  25],\n",
            "            [ 29, -17,  13,  ...,   7, -38,  49]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0109,  0.0095, -0.0092,  ..., -0.0059,  0.0447,  0.0030],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ -8, -62,  -3,  ...,  49, -85, -33],\n",
            "            [ -7,  16,   9,  ..., -24,  61, -30],\n",
            "            [  7, -26, -30,  ...,  -3,  -7,  16],\n",
            "            ...,\n",
            "            [ 23,   7, -46,  ..., -13, -28,  -7],\n",
            "            [ 81, -10, -52,  ...,  -5,  14,  35],\n",
            "            [-15,  27, -13,  ...,   5, -67,  96]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0136, -0.0301,  0.0002,  ...,  0.0161, -0.0032,  0.0123],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 38,  -4,   5,  ...,  22, -21,  23],\n",
            "            [  7,  51,  15,  ...,  -9,  12, -27],\n",
            "            [ -2,   2,   3,  ...,  10,   4,  -1],\n",
            "            ...,\n",
            "            [-22,   9,  14,  ...,  22,  -6,  -2],\n",
            "            [  9,  -9,  31,  ...,   6,   9,  47],\n",
            "            [-12,  -8, -45,  ...,  29,  -7, -19]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0072,  0.0025,  0.0485,  ...,  0.0339, -0.0624, -0.0143],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "tensor([0.4541, 0.4553, 0.4238,  ..., 0.4729, 0.4585, 0.4590], device='cuda:0',\n",
            "       dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0178, -0.0173,  0.1076,  ...,  0.0015, -0.0130, -0.0144],\n",
            "       device='cuda:0', dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 32,  67,  48,  ..., -35,  54,  36],\n",
            "            [  4,  44,  50,  ...,  50, -29, -25],\n",
            "            [-43,  47,  -7,  ..., -21,  33,   0],\n",
            "            ...,\n",
            "            [-45, -28,  16,  ...,  29,  26,  24],\n",
            "            [  5,  56,  27,  ...,  10,  25,  15],\n",
            "            [ 34, -17, -42,  ..., -61,  24,  38]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0128,  0.0129, -0.0062,  ..., -0.0205, -0.0129,  0.0127],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 29,  39,  30,  ..., -48,   1,   0],\n",
            "            [-14,   3,  -2,  ..., -39,  49,   4],\n",
            "            [ -5,  10,   6,  ...,  11,   9,   0],\n",
            "            ...,\n",
            "            [ 42,  13,  -8,  ...,  19,  63, -27],\n",
            "            [  7, -10, -19,  ...,  11,  48, -28],\n",
            "            [-14,  73, -26,  ...,  20,  -3, -27]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0206,  0.0066, -0.0180,  ...,  0.0083, -0.0056,  0.0065],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 27, -14,   3,  ..., -12,  12,  16],\n",
            "            [  9, -10, -48,  ...,  36,  25,  -3],\n",
            "            [  8,  -2, -23,  ...,  38,   7,   9],\n",
            "            ...,\n",
            "            [-49, -44, -24,  ...,  30, -38,  -4],\n",
            "            [-40,  -6,   1,  ..., -30, -17, -31],\n",
            "            [ 70, -33,   2,  ..., -28, -40,  71]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0014,  0.0011, -0.0011,  ..., -0.0005, -0.0045,  0.0013],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-17, -19, -41,  ...,  25,  -5,  -5],\n",
            "            [-25,  26,  32,  ...,  31,  62,  30],\n",
            "            [-28,  37,  35,  ...,  -8,  11,   2],\n",
            "            ...,\n",
            "            [ 34, -88,  29,  ...,  -1,   2,  40],\n",
            "            [ -9, -54, -28,  ...,  16,  -2,  16],\n",
            "            [ 65, -10, -39,  ...,  -3, -30,  39]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([0.0210, 0.0162, 0.0228,  ..., 0.0125, 0.0410, 0.0018], device='cuda:0',\n",
            "       dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-12, -46, -22,  ..., -23,  30, -19],\n",
            "            [-45, -57, -15,  ...,  79,  26, -40],\n",
            "            [-59, -16,  -2,  ..., -17,   3,   5],\n",
            "            ...,\n",
            "            [ 13, -26,  -4,  ..., -14,  87,  39],\n",
            "            [ 79,  30,  45,  ..., -10, -15,  -6],\n",
            "            [ 73,  35, -29,  ...,  -9, -31,  54]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0075, -0.0345,  0.0022,  ..., -0.0104, -0.0084, -0.0035],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 39,   8,  26,  ..., -10, -30, -18],\n",
            "            [  4,  10,  40,  ...,  33,  -9, -35],\n",
            "            [ -2, -33, -23,  ...,  -1, -11,   3],\n",
            "            ...,\n",
            "            [ 20, -10,  -1,  ...,   7,  -4,   9],\n",
            "            [-19,   0,  20,  ..., -33,   9,   6],\n",
            "            [  6,   8, -11,  ...,  -1,   2, -12]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0093, -0.0021,  0.0353,  ...,  0.0368, -0.0518, -0.0007],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "tensor([0.4529, 0.4470, 0.4116,  ..., 0.4658, 0.4539, 0.4478], device='cuda:0',\n",
            "       dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0185, -0.0145,  0.0875,  ...,  0.0041, -0.0168, -0.0168],\n",
            "       device='cuda:0', dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 15, -10, 109,  ...,   8,  -1,  14],\n",
            "            [  0,  29, -93,  ...,   8,  12, -26],\n",
            "            [  0, -34, 118,  ...,  37,  -1,  37],\n",
            "            ...,\n",
            "            [ 43,  27,  -6,  ..., -13,  21, -19],\n",
            "            [ 67,   6,  44,  ...,  13, -28,  50],\n",
            "            [  4, -16,  10,  ...,  27,  30, -65]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0204,  0.0079, -0.0015,  ..., -0.0290,  0.0069, -0.0108],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-34, -11, -62,  ..., -44,   2,  11],\n",
            "            [-14,   1,  43,  ...,  44, -35,   3],\n",
            "            [ -8,  55, -50,  ..., -86,   7,   8],\n",
            "            ...,\n",
            "            [ 24, -12, -13,  ...,  36,   0,  30],\n",
            "            [-25,  34, -19,  ..., -24,  19, -46],\n",
            "            [-52,   5,  56,  ...,  59,   7, -33]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0354,  0.0035, -0.0197,  ...,  0.0696, -0.1002,  0.0058],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 17,  -4,  12,  ...,  29,  13,  -2],\n",
            "            [ 21,  18, -43,  ..., -28,  12, -39],\n",
            "            [-42, -11,  40,  ..., -28,  59,  14],\n",
            "            ...,\n",
            "            [ -8,  13, -22,  ...,  37, -33,   9],\n",
            "            [ 13,  13,  12,  ..., -18, -42, -24],\n",
            "            [ 46,   2,  14,  ..., -20,  80,  23]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-2.1038e-03, -2.4967e-03, -1.4658e-03,  ...,  3.4199e-03,\n",
            "        -2.4052e-03, -8.7559e-05], device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ -18,  -31,   42,  ...,    0,  -25,   21],\n",
            "            [  53,  -43,    2,  ...,   44,  -12,   34],\n",
            "            [   5,    2,   -4,  ...,   20,  -23,   -8],\n",
            "            ...,\n",
            "            [  27,  -50,  -30,  ...,  -21,    2,   31],\n",
            "            [  -6,  -50,   41,  ...,  -66,   75, -116],\n",
            "            [ -24,   42,   74,  ...,   28,  -87,  -30]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0110,  0.0179, -0.0231,  ...,  0.0182,  0.0482,  0.0119],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ -29,  -27,  -34,  ...,    9,    2,   14],\n",
            "            [  31,    2,   -5,  ...,   35,  -12,   23],\n",
            "            [  43,   53, -101,  ...,    6,   12,    0],\n",
            "            ...,\n",
            "            [  37,   15,   18,  ...,   35,   -8,   -8],\n",
            "            [ -25,    0,  -12,  ...,   -3,   15,   10],\n",
            "            [  32,   15,  -47,  ...,   13,   25,   -2]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0380, -0.0257, -0.0081,  ...,  0.0014,  0.0054, -0.0007],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ -9,  47, -20,  ...,   2,  16,  -9],\n",
            "            [-11, -10,   9,  ..., -10,   5,  -1],\n",
            "            [-12,  18,   6,  ...,  -5,   1,  13],\n",
            "            ...,\n",
            "            [-51, -28,   0,  ...,   6,  -3,  -2],\n",
            "            [-43,  -8, -32,  ..., -13,  15,  -7],\n",
            "            [-33, -10,  22,  ...,  -4,  -8,   2]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0024, -0.0076,  0.0539,  ...,  0.0246, -0.0445, -0.0205],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "tensor([0.4475, 0.4507, 0.4153,  ..., 0.4653, 0.4482, 0.4500], device='cuda:0',\n",
            "       dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0179, -0.0137,  0.0818,  ...,  0.0018, -0.0211, -0.0139],\n",
            "       device='cuda:0', dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 37,  -5, -32,  ..., -12,  11, -16],\n",
            "            [-13, -24,  61,  ..., -36, -11, -22],\n",
            "            [-23, -25,  41,  ..., -35,  20,  90],\n",
            "            ...,\n",
            "            [ 10, -26,  16,  ...,  35, -25,  49],\n",
            "            [  7,  -8, -58,  ...,  18, -22, -13],\n",
            "            [ 60,  18,  12,  ..., -54,  30, -28]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0254,  0.0124,  0.0133,  ...,  0.0144, -0.0022, -0.0039],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 10, -11,   7,  ..., -23, -30, -10],\n",
            "            [-18,  14,  42,  ...,  -8,  -2,  27],\n",
            "            [-49, -42, -10,  ...,  37, -14,  39],\n",
            "            ...,\n",
            "            [ -5, -63,  -5,  ..., -42, -68, -67],\n",
            "            [ 11,  33, -26,  ..., -15, -57,  -5],\n",
            "            [  7,  29,  -2,  ..., -29,  37,  47]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0154, -0.0199, -0.0187,  ...,  0.0121,  0.0092,  0.0014],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-22, -19,  19,  ..., -11,   4,  10],\n",
            "            [ 23,   3,   0,  ...,  51,  19, -19],\n",
            "            [ 56, -51,  34,  ..., -33, -27, -94],\n",
            "            ...,\n",
            "            [  3,  15,  12,  ...,  49, -39,  11],\n",
            "            [ 29,  10, -16,  ..., -31,  16,  30],\n",
            "            [-19, -48,  -1,  ..., -63, -15,  52]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0040,  0.0012, -0.0009,  ...,  0.0006,  0.0026, -0.0002],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ -9, -38, -65,  ..., -17,  54,  18],\n",
            "            [-11,   7, -10,  ...,  61,   6, -48],\n",
            "            [-46,  -4, -39,  ...,   6, -13, -19],\n",
            "            ...,\n",
            "            [ -6,  37,  12,  ...,  17, -47, -25],\n",
            "            [ 23,  57,  24,  ..., -22,  38,  -4],\n",
            "            [ 78, -23,  12,  ...,  13,  12,   5]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0232,  0.0072, -0.0164,  ...,  0.0232,  0.0066,  0.0240],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-21, -11,  34,  ..., -14,  11, -12],\n",
            "            [ 46,  61,  -7,  ..., -23, -49,  22],\n",
            "            [ 10, -35,  -5,  ...,   9,  33, -39],\n",
            "            ...,\n",
            "            [ 38,  35,  18,  ...,   2, -20,  32],\n",
            "            [ 21, -34, -29,  ...,   7, -29,  -9],\n",
            "            [ 43, -13, -18,  ...,  17,  47, -50]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0209, -0.0515,  0.0085,  ...,  0.0056,  0.0047,  0.0067],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ -1,  27,  18,  ..., -43, -11, -27],\n",
            "            [  6,   6,  29,  ..., -34,  49, -23],\n",
            "            [-53,  -8,  14,  ...,   8,  12,  27],\n",
            "            ...,\n",
            "            [ 13,  -3,  -2,  ..., -12,   9,  -2],\n",
            "            [ 29,   9,  38,  ...,   5,   6, -32],\n",
            "            [ 20, -10, -10,  ..., -12,  -1,   3]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0023, -0.0037,  0.0640,  ...,  0.0093, -0.0182, -0.0168],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "tensor([0.4500, 0.4529, 0.4165,  ..., 0.4746, 0.4551, 0.4619], device='cuda:0',\n",
            "       dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0201, -0.0125,  0.0879,  ...,  0.0022, -0.0192, -0.0152],\n",
            "       device='cuda:0', dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 44,  16,  34,  ...,  34, -27, -74],\n",
            "            [-17, -38, -11,  ..., -32,   2, -54],\n",
            "            [-10,  54,  19,  ...,   0,  -6, -62],\n",
            "            ...,\n",
            "            [-39,  28,  -5,  ...,  52, -15,  64],\n",
            "            [ 24,  92, -36,  ...,   8, -77,  -2],\n",
            "            [ 14, -36, -24,  ..., -22,  -7, -17]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0174,  0.0150,  0.0098,  ..., -0.0033, -0.0128,  0.0116],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-48, -14,   1,  ...,  16,  32, -11],\n",
            "            [ 31,   6,  11,  ...,  31,  11, -16],\n",
            "            [  9,  -8,  13,  ...,  39,  14,  14],\n",
            "            ...,\n",
            "            [ -4,  33,  28,  ..., -35,  13,   1],\n",
            "            [  3, -20,  43,  ...,  61,  10, -17],\n",
            "            [ -1,  61, -26,  ...,  34,  -6,  11]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0379,  0.0354,  0.0424,  ..., -0.0376,  0.0102,  0.0321],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-37, -72,  -9,  ...,  30,  12, -19],\n",
            "            [-15,  21, -36,  ..., -21,  21, -17],\n",
            "            [ 10,  17,  17,  ...,  10,  27, -22],\n",
            "            ...,\n",
            "            [  3, -64,  28,  ...,  16, -22, -39],\n",
            "            [-28,  -8,  -3,  ...,   7,  -9,  84],\n",
            "            [ -7, -27,  26,  ...,  15,  25,  11]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0017,  0.0041, -0.0017,  ..., -0.0034, -0.0018,  0.0007],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-13, -25, -63,  ...,  32,  32, -61],\n",
            "            [-18,  39,  44,  ..., -46,  17, -13],\n",
            "            [ 31,  15,  -1,  ...,  41, -16,   6],\n",
            "            ...,\n",
            "            [ 32,  42, -29,  ..., -51, -30,  70],\n",
            "            [  4, -18,  19,  ...,   5,  39, -15],\n",
            "            [-13,  -6,  47,  ...,  32, -15,  38]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0108, -0.0124, -0.0181,  ...,  0.0481, -0.0050, -0.0231],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ -56,   -1,   33,  ...,   -1,   31,  -55],\n",
            "            [ -79,    3,  -15,  ...,   -3,  -42,    7],\n",
            "            [  43,    0, -107,  ...,   48,   10,   -8],\n",
            "            ...,\n",
            "            [  -1,    5,   37,  ...,   -9,  -54,   -4],\n",
            "            [  17,  -33,   -6,  ...,    8,    8,   -2],\n",
            "            [   7,    7,  -33,  ...,   23,   36,   16]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0119, -0.0477,  0.0108,  ..., -0.0139,  0.0195,  0.0170],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-16, -39, -22,  ...,  21,  -8, -34],\n",
            "            [-19,  31,  -4,  ..., -30,  18,  15],\n",
            "            [ -9,  24,  25,  ..., -15,  -3,  -2],\n",
            "            ...,\n",
            "            [-37, -25, -13,  ...,  -7,  21, -12],\n",
            "            [-31, -32, -21,  ...,  30, -10, -17],\n",
            "            [ 40,  11,  19,  ...,  15, -11, -15]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0093, -0.0205,  0.0549,  ...,  0.0239, -0.0451, -0.0077],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "tensor([0.4570, 0.4531, 0.4268,  ..., 0.4746, 0.4619, 0.4668], device='cuda:0',\n",
            "       dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0199, -0.0120,  0.0975,  ...,  0.0012, -0.0177, -0.0125],\n",
            "       device='cuda:0', dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-65, -14,  -6,  ...,   0, -42,  58],\n",
            "            [ 42,  -5, -17,  ...,   7,  50,  -4],\n",
            "            [ 26, -15,  66,  ..., -26,  24, -50],\n",
            "            ...,\n",
            "            [ 48, -11,   7,  ...,  -6, -19,  22],\n",
            "            [-46,  -2,  19,  ...,  25, -80,  26],\n",
            "            [ 20,  11, -21,  ...,  40,  28,  10]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0326, -0.0154,  0.0443,  ...,  0.0006, -0.0169,  0.0024],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ -20,   13,   35,  ...,   10,   11,   -5],\n",
            "            [ -44,   29,  -12,  ...,  -88,   38,   -7],\n",
            "            [  -7,  -34,   22,  ...,   14,   -9,   30],\n",
            "            ...,\n",
            "            [ -70,   17,   52,  ...,   16,   28,  -16],\n",
            "            [ -81,   31,   51,  ...,   42,   -1,    7],\n",
            "            [  -1,  -26,  -62,  ...,   46, -112,   13]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0633, -0.0067,  0.0330,  ...,  0.0048,  0.0894,  0.0213],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-25,  16, -11,  ...,  15,  16,  -8],\n",
            "            [-27,  -9, -15,  ..., -17,  13,   6],\n",
            "            [ 44, -63,  18,  ...,  12,  18, -36],\n",
            "            ...,\n",
            "            [-79, -59,  24,  ...,  14, -16,   4],\n",
            "            [-18,  -2,  23,  ...,  53, -36, 116],\n",
            "            [ 14,  34,   0,  ...,  15,   7, -19]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0024,  0.0005,  0.0016,  ...,  0.0037,  0.0010, -0.0010],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 34,  98, -20,  ...,  13,  28, -42],\n",
            "            [-20,  35,  73,  ...,  32,   4,   5],\n",
            "            [ 20, -14, -33,  ..., -22,   3, -39],\n",
            "            ...,\n",
            "            [ -9,  14,   2,  ...,  37, -17, -13],\n",
            "            [-22, -32, -44,  ...,  26,  19,  12],\n",
            "            [ 20,  -3,  28,  ...,  23,  -3,  49]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0182, -0.0003, -0.0136,  ...,  0.0406,  0.0339,  0.0035],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 69,  63,  23,  ...,  28,   5,   6],\n",
            "            [ 25,  67, -28,  ...,  17, -13,  82],\n",
            "            [ 62,   9, -84,  ...,  -4, -23,  62],\n",
            "            ...,\n",
            "            [-28, -12,  12,  ...,   0,  78, -19],\n",
            "            [ -5, -48,  22,  ..., -46, -35, -40],\n",
            "            [ 73,  60,  37,  ...,   6, -50,  31]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0049, -0.0486,  0.0123,  ..., -0.0020,  0.0252, -0.0051],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ -6,  -2, -32,  ...,  23,   5, -31],\n",
            "            [-12,   8,  21,  ...,  16,   0, -32],\n",
            "            [-13, -11,  13,  ..., -19,  -4, -18],\n",
            "            ...,\n",
            "            [-10,   1, -18,  ...,  18,  44,  28],\n",
            "            [  7,  -7,   8,  ..., -34,  19,  19],\n",
            "            [ 18, 106, -57,  ..., -27,  15, -35]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0054, -0.0096,  0.0554,  ...,  0.0271, -0.0453,  0.0170],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "tensor([0.4475, 0.4480, 0.4207,  ..., 0.4712, 0.4575, 0.4653], device='cuda:0',\n",
            "       dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0173, -0.0159,  0.1003,  ..., -0.0006, -0.0224, -0.0118],\n",
            "       device='cuda:0', dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ -8,  -1,  26,  ...,   0,  13,  -7],\n",
            "            [-35,   0,  -6,  ...,  54,  -2,  38],\n",
            "            [ -2,  53,  40,  ...,  13,  16, -22],\n",
            "            ...,\n",
            "            [-14, -11, -11,  ...,  70,  21,   4],\n",
            "            [ 22,  15,  29,  ..., -12, -19,  10],\n",
            "            [ 24,   7, -23,  ...,  17, -17, -34]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0012, -0.0215,  0.0204,  ...,  0.0197, -0.0309, -0.0461],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-61, -51, -16,  ...,  22,  19,  16],\n",
            "            [-25, -42, -13,  ...,  -4,  17,  -5],\n",
            "            [-11, -20,  18,  ..., -11,   0,   3],\n",
            "            ...,\n",
            "            [  3, -39,  10,  ..., -31,  12, -24],\n",
            "            [-14,  -1,  21,  ...,  43, -96, -61],\n",
            "            [ 27, -23,   7,  ...,  31,  17,  47]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0618,  0.0498,  0.0680,  ..., -0.0031,  0.0267,  0.1565],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[  3, -47, -15,  ..., -41, -22,  36],\n",
            "            [-29,  13,   2,  ...,   9,  10,  41],\n",
            "            [ -2,   1,  10,  ...,   5,  19,  44],\n",
            "            ...,\n",
            "            [-47,  47,  21,  ..., -14,  58,  11],\n",
            "            [ 52, -62,  39,  ...,   2,  84,   3],\n",
            "            [-48, -81,  -2,  ...,  38,  -1, -29]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0022,  0.0006, -0.0001,  ...,  0.0019,  0.0055,  0.0062],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-30,  -8,  -8,  ...,  40, -11, -17],\n",
            "            [-30,  12,  12,  ...,  20,  29,  85],\n",
            "            [ 13,   2,   9,  ...,  62,  10,  57],\n",
            "            ...,\n",
            "            [ 35,  44, -33,  ...,  20,   8,  15],\n",
            "            [-10,  39, -27,  ...,  -1,  -5, -11],\n",
            "            [-24,   3,  -7,  ..., -54,  26,  49]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0146,  0.0167, -0.0452,  ...,  0.0113,  0.0273, -0.0203],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-11,  49, -67,  ...,  -9,  12, -30],\n",
            "            [-42,  13,  -1,  ..., -10, -39,  13],\n",
            "            [ 20,  17, -38,  ..., -15,  17,   8],\n",
            "            ...,\n",
            "            [-34,  52, -40,  ...,  41, -21,  -5],\n",
            "            [-20,  41, -15,  ..., -23,  37,  31],\n",
            "            [ 48,   0, -13,  ...,  -4,  38,  57]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0312, -0.0079, -0.0145,  ..., -0.0066, -0.0079,  0.0009],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 19,  26, -14,  ...,  30, -19, -16],\n",
            "            [-26,  25, -14,  ...,  -1,  -4, -24],\n",
            "            [-27,   8, -24,  ..., -21,  -3,  -3],\n",
            "            ...,\n",
            "            [-30,  43,  41,  ..., -21, -12, -10],\n",
            "            [ 20,  13,  15,  ...,  -6, -10, -27],\n",
            "            [ 16, -23, -36,  ...,  22,  24,  -4]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0106, -0.0278,  0.0740,  ...,  0.0080, -0.0142,  0.0239],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "tensor([0.4451, 0.4429, 0.4114,  ..., 0.4609, 0.4492, 0.4546], device='cuda:0',\n",
            "       dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0188, -0.0124,  0.0906,  ...,  0.0012, -0.0197, -0.0080],\n",
            "       device='cuda:0', dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ -6,   4, -38,  ...,  10,  19,  15],\n",
            "            [ 67,  -7, -37,  ...,  32,  71, -31],\n",
            "            [ 13,  23, -17,  ...,   9, -65,  -6],\n",
            "            ...,\n",
            "            [  9,   7, -25,  ...,  -2,  35, -35],\n",
            "            [-20,  -1, -17,  ...,  33,   2,  40],\n",
            "            [ 77, -46,   6,  ...,   6,   4,  -1]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0208, -0.0151,  0.0017,  ..., -0.0304,  0.0094, -0.0352],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-42,  36, -12,  ..., -64,   1,  28],\n",
            "            [-24,  24, -19,  ..., -45, -13,  34],\n",
            "            [ 28,   0, -13,  ...,   3,  -6,  -5],\n",
            "            ...,\n",
            "            [-16,   7,  -1,  ...,  -2, -58, -27],\n",
            "            [  0,  29,  42,  ...,   4, -39, -16],\n",
            "            [  2,   2, -36,  ...,  -8,  -4,   5]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0080,  0.0066, -0.0204,  ...,  0.0199,  0.0261, -0.0031],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[  3, -17, -13,  ...,   5, -25,  12],\n",
            "            [ 30,   6,  -1,  ...,  -8,   8,   3],\n",
            "            [ 42,  -7, -32,  ...,  -8,  30, -11],\n",
            "            ...,\n",
            "            [ 29,  19, -25,  ...,  38, -28, -21],\n",
            "            [  9,   4, -21,  ...,  42, -69,  47],\n",
            "            [-26, -13,   1,  ...,  24,  51,   3]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0015,  0.0009,  0.0044,  ...,  0.0006, -0.0005,  0.0008],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-37,  41,  -8,  ..., -18,  35,  -6],\n",
            "            [  7,  -3,  12,  ..., -46,  -7,  24],\n",
            "            [ 11,  44,  -8,  ...,  59,   2, -20],\n",
            "            ...,\n",
            "            [ 35,  53,  42,  ..., -14, -17,   4],\n",
            "            [ 10,  -2, -15,  ..., -37,  40, -27],\n",
            "            [ 13, -29,  47,  ...,  27,  26,   3]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0173,  0.0281, -0.0245,  ...,  0.0456,  0.0075, -0.0281],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[  15,   -8,  -22,  ...,  -27,   21,  -18],\n",
            "            [-104,   30,    3,  ...,   32,  -62,  -20],\n",
            "            [  61,    3,  -22,  ...,   -5,  -54,   19],\n",
            "            ...,\n",
            "            [ -52,  -36,  -18,  ...,   28,  -24,   13],\n",
            "            [ -10,   -6,  -45,  ...,   56,   40,   -2],\n",
            "            [  25,  -30,   -2,  ...,  -29,   -3,   18]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0406,  0.0183, -0.0406,  ..., -0.0016,  0.0145, -0.0037],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[  2,  48,  10,  ...,  38,  44, -15],\n",
            "            [-25, -41,  16,  ...,  43, -22, -52],\n",
            "            [ 34,  -8,  -5,  ...,   0,  15,  14],\n",
            "            ...,\n",
            "            [-33, -25,   3,  ..., -37, -23,  36],\n",
            "            [  7,  60,  -5,  ...,  11, -18,   6],\n",
            "            [ 18,  10,  30,  ..., -38,  36,  19]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0109, -0.0118,  0.0604,  ..., -0.0211, -0.0114,  0.0089],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "tensor([0.4514, 0.4502, 0.4150,  ..., 0.4685, 0.4590, 0.4685], device='cuda:0',\n",
            "       dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0210, -0.0183,  0.1039,  ..., -0.0012, -0.0176, -0.0060],\n",
            "       device='cuda:0', dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 15,  10, -54,  ...,   1,  11,  16],\n",
            "            [-44, -54,   7,  ..., -12,  30,  43],\n",
            "            [-21,  -7,  61,  ...,  -2, -32, -35],\n",
            "            ...,\n",
            "            [ 73,  69,   2,  ..., -32,  34,  -2],\n",
            "            [-13,  21,  26,  ...,   5,  31, -15],\n",
            "            [ 18, -26,  31,  ..., -10,  -6,  13]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0678, -0.0031,  0.0508,  ..., -0.0100,  0.0077,  0.0132],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[  3,  14, -26,  ...,   9,  -4,  -2],\n",
            "            [-51,  15,  16,  ..., -57, -33,  50],\n",
            "            [  1,  -5,  32,  ..., -13, -35, -46],\n",
            "            ...,\n",
            "            [-19,  22, -14,  ...,   4,   3,  -5],\n",
            "            [  8,  14,  33,  ..., -19,   5,  14],\n",
            "            [ 27,  60,  24,  ...,  27,  -6, -41]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0885,  0.0077,  0.0466,  ..., -0.0863, -0.0213,  0.0362],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 53, -32,   4,  ...,  33, -55, -25],\n",
            "            [-38,   6,  27,  ...,  10, -23,  25],\n",
            "            [  9, -18,  52,  ...,   7, -27,  -4],\n",
            "            ...,\n",
            "            [-23,  36,  51,  ..., -15,  54,  20],\n",
            "            [ 66,  -1,  41,  ..., -33,  39,  26],\n",
            "            [ -6, -28, -20,  ...,  13,  20,  28]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([0.0005, 0.0037, 0.0005,  ..., 0.0010, 0.0021, 0.0025], device='cuda:0',\n",
            "       dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-17,  30,  22,  ...,  50, -97,  17],\n",
            "            [ 11,  -9,  -3,  ..., -27,  32,  -6],\n",
            "            [ 11, -45, -96,  ..., -22, -56,  -7],\n",
            "            ...,\n",
            "            [-24, -16,  -4,  ...,  29,  36,  47],\n",
            "            [ 19,   2,  33,  ..., -97, -64, -34],\n",
            "            [ 33,  12, -10,  ..., -37,  45,  -1]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0070,  0.0275, -0.0242,  ...,  0.0582, -0.0170,  0.0365],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 39,   2,   6,  ...,   7, -27,   5],\n",
            "            [ -6,  -6, -20,  ...,  11,  -6,   6],\n",
            "            [-39, -51, -34,  ...,  -7,  20, -11],\n",
            "            ...,\n",
            "            [ 23,  12, -16,  ...,  -2, -48, -40],\n",
            "            [-38, -45,  15,  ...,  -2, -27, -11],\n",
            "            [ 30, -17,  24,  ...,  49,  18, -24]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0379, -0.0257, -0.0060,  ..., -0.0401, -0.0081, -0.0018],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 25, -11,   0,  ...,  25,   2,   6],\n",
            "            [ -2, -37,  12,  ...,  27, -47,   2],\n",
            "            [-21,  17,   7,  ...,  19, -12, -11],\n",
            "            ...,\n",
            "            [-31,  37,   4,  ...,   6,   8, -13],\n",
            "            [-41,  -7,  12,  ...,  35, -15,  -9],\n",
            "            [  9,  -4,  44,  ...,  16,   6,  28]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0043, -0.0052,  0.0795,  ..., -0.0308, -0.0108,  0.0011],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "tensor([0.4309, 0.4399, 0.4221,  ..., 0.4539, 0.4475, 0.4526], device='cuda:0',\n",
            "       dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0176, -0.0139,  0.1109,  ..., -0.0072, -0.0156, -0.0072],\n",
            "       device='cuda:0', dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[  29,   38,    8,  ...,   -9,  -39,   19],\n",
            "            [  32,   67,   28,  ...,  -14,    4,   17],\n",
            "            [  39,  113,   46,  ...,   49,  -67,   10],\n",
            "            ...,\n",
            "            [  21,  -15,  -20,  ...,  -62,    6,  -34],\n",
            "            [   1,   18,  -28,  ..., -100,   13,   22],\n",
            "            [   7,   -7,   -7,  ...,   18,    1,   10]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 3.9459e-02,  2.9068e-02, -7.5102e-05,  ...,  1.9348e-02,\n",
            "        -7.7343e-04, -7.9811e-05], device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 25, -34,  18,  ...,   6,  -2,  23],\n",
            "            [  5, -58,   0,  ...,   8,  26, -12],\n",
            "            [-45,  44,  28,  ...,  41, -70,  -2],\n",
            "            ...,\n",
            "            [  8,  57, -12,  ...,  33,   5,  17],\n",
            "            [-24, -45, -18,  ...,   6,  13,   0],\n",
            "            [-38,  53, -14,  ..., -23, -15, -33]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0571,  0.0286,  0.0009,  ..., -0.2817, -0.0139, -0.1594],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ -2,  40,  -9,  ..., -33, -24,  16],\n",
            "            [-46,  31, -29,  ..., -27,  -7,  24],\n",
            "            [-59,  18, -20,  ...,  15,  -3, -38],\n",
            "            ...,\n",
            "            [ 11,  20,  18,  ...,  35,  -2, -24],\n",
            "            [ 18, -44,  11,  ...,  30,  47,  -4],\n",
            "            [-26, -54,   9,  ...,  23, -14,  -9]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0012, -0.0021, -0.0003,  ...,  0.0015,  0.0007, -0.0006],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[  6,  77,  39,  ..., -11, -31,  61],\n",
            "            [-63, -63, -36,  ..., -75,  41,  79],\n",
            "            [ 25,  53,  17,  ..., -40, -31,  22],\n",
            "            ...,\n",
            "            [ 10,  65, -19,  ..., -21,  34,  11],\n",
            "            [ 50,  28, -34,  ...,  35, -30,  -5],\n",
            "            [-27, -21,  39,  ..., -40,  20,  21]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0152,  0.0083, -0.0514,  ...,  0.0526, -0.0085,  0.0039],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[103,  67, -59,  ..., -46, -10, -40],\n",
            "            [ 60,  56,  21,  ..., -14,  20,  24],\n",
            "            [ 47,  57,  45,  ..., -41,   9,  50],\n",
            "            ...,\n",
            "            [-51,   0, -17,  ...,  14, -17, -12],\n",
            "            [-10, -52,   2,  ...,  -7,  -5, -10],\n",
            "            [ 14, -22,  -7,  ...,   1,  -7,  55]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0325, -0.0349, -0.0073,  ..., -0.0068,  0.0066, -0.0116],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 65,  11,  -6,  ...,  17,  13, -21],\n",
            "            [ 55, -22, -37,  ...,   3,   3,  -2],\n",
            "            [ -3,  30, -18,  ...,  10,   3, -20],\n",
            "            ...,\n",
            "            [ -6,  42,  29,  ..., -11,  10,   3],\n",
            "            [ 10,  -4,   3,  ...,   6,  18,   0],\n",
            "            [-30,  18, -26,  ...,   7,   2, -10]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0111, -0.0141,  0.0723,  ..., -0.0114, -0.0070, -0.0062],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "tensor([0.4453, 0.4487, 0.4443,  ..., 0.4570, 0.4463, 0.4629], device='cuda:0',\n",
            "       dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0303, -0.0246,  0.1056,  ..., -0.0147, -0.0162, -0.0124],\n",
            "       device='cuda:0', dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[  9, -47, -16,  ...,  49,  10,  11],\n",
            "            [ 36, -42, -66,  ...,  16,  -5, -15],\n",
            "            [-48,   9, -26,  ...,  -7, -45,  59],\n",
            "            ...,\n",
            "            [ 17,  -4, -22,  ...,  -7,  43,   5],\n",
            "            [ -7,  -2, -42,  ..., -13,  89,  -7],\n",
            "            [ 24,  53,  -3,  ...,   9,  14,  16]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0145, -0.0451, -0.0053,  ..., -0.0007, -0.0063,  0.0315],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ -6, -36,   6,  ...,  25,  -6,  16],\n",
            "            [ 11, -37,  15,  ..., -25,   1, -22],\n",
            "            [-23,  22,  59,  ...,   1, -12,  -4],\n",
            "            ...,\n",
            "            [  1, -42, -14,  ..., -28,  23,  -6],\n",
            "            [ 13,  -3,   3,  ...,   4,  48,  47],\n",
            "            [ -1, -52, -21,  ...,  19,  10,   3]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0284, -0.0363, -0.0120,  ...,  0.0386,  0.0879,  0.1543],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-53, -15,  39,  ...,  22, -15, -37],\n",
            "            [-41, -51, -25,  ...,   3,   6, -35],\n",
            "            [ -2,  15,   0,  ...,   2,   0, -12],\n",
            "            ...,\n",
            "            [ 68,  23,  16,  ..., -68,  21, -40],\n",
            "            [-74, -86,  15,  ..., -51,  36, -45],\n",
            "            [ -3, -50, -27,  ...,   6, -61,  -3]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0003, -0.0004, -0.0016,  ...,  0.0009,  0.0002,  0.0013],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 36,  63,  24,  ..., -35,  15, -10],\n",
            "            [ 13,  -9,  -8,  ...,  -3,  33,   7],\n",
            "            [-38, -15, -26,  ...,  67, -26,  55],\n",
            "            ...,\n",
            "            [-63,  -9,  -9,  ...,  85,   2, -10],\n",
            "            [  9, -34,  36,  ...,   8,  29,  45],\n",
            "            [ 42, -53,  24,  ...,  25,   8,  25]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0092, -0.0057, -0.0505,  ...,  0.0225, -0.0073,  0.0055],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-75,  -7, -12,  ...,  47,  17,  50],\n",
            "            [-42,   2,  -9,  ..., -29,  -8,  -2],\n",
            "            [-32, 102,  10,  ...,   6,  44,  19],\n",
            "            ...,\n",
            "            [-12, -10,  -3,  ...,  35,   1, -20],\n",
            "            [ 10,  26, -19,  ...,   6, -21, -23],\n",
            "            [-17,  -3, -67,  ..., -20, -36,  22]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0364, -0.0307, -0.0108,  ...,  0.0126,  0.0052, -0.0009],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-58,   2,  13,  ..., -16,  -2,  -7],\n",
            "            [ 22,  -8, -60,  ...,   2, -25, -16],\n",
            "            [ 16,  -6,  -9,  ...,  -5,   3,  26],\n",
            "            ...,\n",
            "            [ 72,  12,  10,  ...,  15,  -6, -15],\n",
            "            [ 68,  18, -44,  ...,  -2,  23,  14],\n",
            "            [ 28,  28,  20,  ...,  36,  43, -19]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0023, -0.0091,  0.0575,  ...,  0.0049, -0.0065, -0.0035],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "tensor([0.4551, 0.4578, 0.4358,  ..., 0.4641, 0.4622, 0.4746], device='cuda:0',\n",
            "       dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0215, -0.0224,  0.1087,  ..., -0.0102, -0.0132, -0.0117],\n",
            "       device='cuda:0', dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-17,  -2,  40,  ...,  14,  16,  -3],\n",
            "            [-15,  14,  26,  ...,   8,  94, -15],\n",
            "            [ 50,   9, -38,  ..., -41, -49,  21],\n",
            "            ...,\n",
            "            [ 13, -28,  60,  ..., -12,   6, -20],\n",
            "            [ 30,   8,  17,  ...,  -7,  50,  29],\n",
            "            [-39, -17, -56,  ...,  29, -48,  53]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0012, -0.0089,  0.0100,  ...,  0.0974,  0.1038, -0.0726],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[  3,  -7, -19,  ..., -10,  52, -30],\n",
            "            [ 79,  13, -19,  ..., -55,  24,  19],\n",
            "            [  0,  23,   3,  ...,   9, -24,  -7],\n",
            "            ...,\n",
            "            [  4,  11,   2,  ...,   3,  -7,  -6],\n",
            "            [  2,  20, -33,  ...,  -2,   1,   4],\n",
            "            [-11, -15,  -9,  ...,  -4,  21,  15]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0026,  0.0052, -0.0226,  ..., -1.4189, -1.4453,  1.1035],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-52,   8, -18,  ..., -33,  44, -20],\n",
            "            [-58,  29, -16,  ...,  40,  -5, -41],\n",
            "            [ 37,  51,  10,  ...,   5,  11,  22],\n",
            "            ...,\n",
            "            [ 17,  34, -11,  ...,  31,  37, -46],\n",
            "            [ 15,  41,  77,  ...,  55, -44,  35],\n",
            "            [-16,  36,  -8,  ..., -27,   6,  -3]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-1.0643e-03,  4.3845e-04, -2.5005e-03,  ..., -2.8825e-04,\n",
            "        -4.3333e-05,  1.7576e-03], device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-12,   7,  27,  ..., -45,  60,   5],\n",
            "            [ 37,  79,   3,  ..., -31, -19, -64],\n",
            "            [-22,   5, -21,  ...,  -4, -36,  10],\n",
            "            ...,\n",
            "            [ 22,   6,  46,  ..., -15,   3,  42],\n",
            "            [ 12,   8,   9,  ..., -38,  32,  23],\n",
            "            [ 21,  22,   8,  ...,  52, -33,   5]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0254,  0.0094, -0.0605,  ..., -0.0178, -0.0482,  0.0677],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 47,  27,  19,  ...,  28,  35,  10],\n",
            "            [-19,  -1,   6,  ...,  22,  29,  15],\n",
            "            [-34, -19,   9,  ...,  33,  -2,  -1],\n",
            "            ...,\n",
            "            [  1, -69, -26,  ...,  10, -80,  11],\n",
            "            [ 20,  11,  25,  ..., -32, -31,  -3],\n",
            "            [-25, -18,  21,  ...,   5,  -3,  -6]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0384, -0.0315, -0.0075,  ..., -0.0044, -0.0151, -0.0134],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 36, -22,  15,  ...,  17,  -5,  33],\n",
            "            [ 23,   2, -35,  ...,   9,  -6, -15],\n",
            "            [ -3,  -8, -45,  ...,  27, -17,   1],\n",
            "            ...,\n",
            "            [ 13,  -8,   4,  ...,  -1,   5, -13],\n",
            "            [  0, -28,  10,  ...,  20,  62, -14],\n",
            "            [-54,   6, -23,  ..., -29,   2,   8]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0078, -0.0244,  0.0550,  ..., -0.0007, -0.0086, -0.0117],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "tensor([0.4578, 0.4634, 0.4514,  ..., 0.4524, 0.4519, 0.4722], device='cuda:0',\n",
            "       dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0246, -0.0273,  0.1160,  ..., -0.0076, -0.0181, -0.0170],\n",
            "       device='cuda:0', dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 15, -43,  49,  ...,  28,  10,  76],\n",
            "            [-11,   9, -34,  ...,  -5, -83,  17],\n",
            "            [-35,  58, -13,  ..., -82, -44, -51],\n",
            "            ...,\n",
            "            [ -3, -13,  28,  ...,  -1, -19, -42],\n",
            "            [-12,  18,  19,  ...,  29, -40,  49],\n",
            "            [ -8,   0, -13,  ..., -18,  19, -14]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0075, -0.0188, -0.0121,  ...,  0.0137,  0.0184, -0.0160],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-46,  15,   0,  ...,   1,  10, -47],\n",
            "            [-18, -58,  47,  ..., -90,  70,  43],\n",
            "            [ 19,  -3,  45,  ...,  29,  43, -21],\n",
            "            ...,\n",
            "            [ 25,  -5,  20,  ...,  92, -44,  14],\n",
            "            [  3, -42,  -8,  ..., -40, -39, -41],\n",
            "            [-58,  19,   8,  ..., -64,  15,  -3]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0090,  0.0095,  0.0092,  ...,  0.1039, -0.1881,  0.3750],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 45, -30, -49,  ..., -74, -17, -20],\n",
            "            [ 35, -21, -19,  ...,  15,  17,   0],\n",
            "            [-37, -48, -51,  ..., -19, -68, -32],\n",
            "            ...,\n",
            "            [ 15,   6,  29,  ...,  10, -53, -11],\n",
            "            [-25,  11,  -4,  ...,  14,  13,  -2],\n",
            "            [-50,  28,  20,  ...,  51,   0, -34]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 3.1888e-05, -1.4172e-03,  1.1358e-03,  ...,  4.0436e-03,\n",
            "         1.6747e-03,  3.6669e-04], device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-28, -55,  -9,  ...,  45,   4, -12],\n",
            "            [ -6,   4, -14,  ..., -34, -28,  39],\n",
            "            [  0,   1, -40,  ...,  61,  82,  57],\n",
            "            ...,\n",
            "            [-22, -28, -55,  ...,   6,   3,   4],\n",
            "            [-19,   9,  -9,  ..., -58, -30,  17],\n",
            "            [ 21, -36,   0,  ..., -21, -30,  19]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0272,  0.0106, -0.0667,  ...,  0.0182, -0.0192,  0.0601],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[  19,  -17,  -35,  ...,   17,  -57,  -18],\n",
            "            [  60,   58,  -63,  ...,  -37,  -10,  -51],\n",
            "            [   7,  -21,  -24,  ...,   72,   64,   67],\n",
            "            ...,\n",
            "            [  -3,    6,   -2,  ...,  -27,   12,    7],\n",
            "            [ -40,   29,    0,  ...,  -29, -105,   17],\n",
            "            [   2,   13,   16,  ...,    7,   -6,    8]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0621, -0.0251, -0.0283,  ..., -0.0166, -0.0580, -0.0498],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ -2,  -8, -21,  ...,  10,  14,   7],\n",
            "            [-30,  43, -44,  ...,  45, -16,  -2],\n",
            "            [ 13,  -7,  42,  ..., -10,   1,   8],\n",
            "            ...,\n",
            "            [  5, -10, -28,  ...,  29,  31,  -7],\n",
            "            [-63,  -2, -40,  ...,  41,  56,  19],\n",
            "            [ -6,  -7,  55,  ..., -22, -28,  21]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0194, -0.0203,  0.0432,  ...,  0.0070, -0.0119, -0.0181],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "tensor([0.4722, 0.4807, 0.4565,  ..., 0.4763, 0.4885, 0.5015], device='cuda:0',\n",
            "       dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0236, -0.0270,  0.1196,  ..., -0.0084, -0.0152, -0.0146],\n",
            "       device='cuda:0', dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 60, -32,  -1,  ...,  42,  20,   0],\n",
            "            [-11,   9,  13,  ...,  71, -91, -53],\n",
            "            [  7, -53, -22,  ..., -36,  10,  26],\n",
            "            ...,\n",
            "            [-32,  23,  34,  ...,  -2,  12,   7],\n",
            "            [  0,  -8,  38,  ..., -27,  -4, -35],\n",
            "            [-16,  24, -42,  ...,  -5, -30, -19]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0271,  0.0036, -0.0158,  ...,  0.0358,  0.0117, -0.0049],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 39,  28, -23,  ...,  -9, -19, -22],\n",
            "            [ -1,  71,  51,  ...,  35,  22,   1],\n",
            "            [ -2,   7, -32,  ...,  41,  -4,   7],\n",
            "            ...,\n",
            "            [ -2,  36, -15,  ...,  39,  30,   2],\n",
            "            [ 18, -23, -12,  ..., -13,  -8,  11],\n",
            "            [  4,  61,  68,  ...,  12, -22, -13]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0340, -0.0146, -0.0245,  ..., -0.1035, -0.1501,  0.1511],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 12,  36,   1,  ..., -32,  16, -16],\n",
            "            [ 36, -19, -31,  ...,  45,  15,  47],\n",
            "            [-54,  38,  14,  ...,  -2, -42, -25],\n",
            "            ...,\n",
            "            [-50, -34, -34,  ..., -18,  62, -33],\n",
            "            [  7,  55,  32,  ..., -35, -22,  -8],\n",
            "            [ 26,  31,  -8,  ..., -72, -49, -13]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-1.5764e-03, -2.5272e-04,  1.7059e-04,  ...,  4.5891e-03,\n",
            "        -2.2137e-04,  6.5565e-05], device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-15, -13,   4,  ...,  -8, -12,  21],\n",
            "            [ 30, -19, -29,  ...,  18,  -2,  14],\n",
            "            [ -4,  43,   6,  ..., -13,  25, -20],\n",
            "            ...,\n",
            "            [ -6, -51,  25,  ...,  21, -58,  -6],\n",
            "            [ 20, -15,  30,  ..., -16,   7,  36],\n",
            "            [ 22,   1,   2,  ...,   0,  36,  29]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0040, -0.0107, -0.0611,  ...,  0.0219,  0.0132,  0.0422],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-12,  -4, -37,  ..., -34,  -4,   6],\n",
            "            [ 14, -22, -66,  ...,  46, -12, -19],\n",
            "            [  5,   0, -37,  ..., -14,  61, -27],\n",
            "            ...,\n",
            "            [ 70, -40,  34,  ...,  96,  30, -51],\n",
            "            [-22,  -1, -83,  ...,   1,   4,  36],\n",
            "            [ -2, -19, -45,  ..., -22,   4,  22]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0396, -0.0310, -0.0202,  ...,  0.0098, -0.0145,  0.0016],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-29, -22, -22,  ...,   2, -26, -18],\n",
            "            [-16,  48,   7,  ...,  13,  19, -10],\n",
            "            [ -5, -12,  27,  ..., -17,  28, -36],\n",
            "            ...,\n",
            "            [-11, -17,  10,  ..., -19,  11,  19],\n",
            "            [ 29, -62,  10,  ..., -20,  14,  25],\n",
            "            [ 23,   8,  12,  ...,  27,  29,  -3]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0179, -0.0172,  0.0493,  ...,  0.0059, -0.0098, -0.0451],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "tensor([0.4797, 0.4946, 0.4717,  ..., 0.4785, 0.4912, 0.5156], device='cuda:0',\n",
            "       dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0220, -0.0267,  0.1263,  ..., -0.0115, -0.0215, -0.0168],\n",
            "       device='cuda:0', dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ -15,  -18,   20,  ...,   15,  -28,  -20],\n",
            "            [   1,  -38,    1,  ...,   18,  -13, -104],\n",
            "            [ -46,   14,   27,  ...,  -70,  -22,   16],\n",
            "            ...,\n",
            "            [  30,   29,   -2,  ...,   32,   49,   -3],\n",
            "            [   5,   12,   -9,  ...,    9,  -19,   30],\n",
            "            [ -28,  -57,    3,  ...,   18,    8,  -33]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0007,  0.0005, -0.0165,  ...,  0.0101, -0.1359, -0.0311],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 29,  37,   4,  ..., -17,  19, -20],\n",
            "            [ 44,  21,  19,  ...,  80,  57,  26],\n",
            "            [ 23, -17, -54,  ..., -39, -20, -30],\n",
            "            ...,\n",
            "            [  8,  -8,  -7,  ...,  10,   5, -18],\n",
            "            [ -9,  -1,   9,  ...,   5,  -9,  -6],\n",
            "            [ 40,  18,  14,  ..., -30,  11,  -5]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 1.1909e-02, -9.8953e-03, -8.5020e-04,  ...,  1.6394e-01,\n",
            "        -1.1475e+00, -1.4050e-01], device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-11, -50, -17,  ..., -11, -28,  23],\n",
            "            [ 21, -49,  12,  ...,   9, -82, -33],\n",
            "            [  9,  13,  -1,  ...,  20, -21,  24],\n",
            "            ...,\n",
            "            [ 44, -81,  33,  ...,  30,  16, -29],\n",
            "            [ 39, -29, -11,  ...,  65, -49,  41],\n",
            "            [-30, -11, -10,  ...,   6, -38,  30]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0003,  0.0012,  0.0009,  ..., -0.0017,  0.0004, -0.0015],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 21,  28,  65,  ...,  -6,  59,   2],\n",
            "            [-53,  -9, -20,  ...,  35,  18,  48],\n",
            "            [-22,   2, -16,  ..., -36, -22,  34],\n",
            "            ...,\n",
            "            [-16, -28,  29,  ..., -14,   2,  80],\n",
            "            [ 20,   0, -14,  ..., -17, -21, -23],\n",
            "            [ 32,  39,   3,  ...,  20, -28,  31]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0219,  0.0543, -0.0291,  ...,  0.0451, -0.0251,  0.0208],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-36,   4,  27,  ...,  51, -21,  22],\n",
            "            [-34, -32,   0,  ...,  34,   5,  54],\n",
            "            [  2,  -3, -10,  ...,   3,   7, -19],\n",
            "            ...,\n",
            "            [  2,  90,  37,  ...,  11,  19,  -1],\n",
            "            [ 31, -58, -13,  ..., -34,  10,  25],\n",
            "            [ 26,  -4, -73,  ..., -24,  33,  62]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0220, -0.0258, -0.0254,  ...,  0.0008,  0.0025, -0.0040],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 10,  16,   7,  ...,   7, -15, -14],\n",
            "            [ 12,  -4, -14,  ..., -25,  -6,  18],\n",
            "            [ 15, -17,  13,  ...,   3, -14,   3],\n",
            "            ...,\n",
            "            [-20,  40,  -9,  ..., -34, -34,  14],\n",
            "            [ -6, -25,  20,  ..., -14, -29, -29],\n",
            "            [ 22,  39,  -7,  ...,   4,   4,  10]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0127, -0.0108,  0.0503,  ...,  0.0015, -0.0052, -0.0223],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "tensor([0.4897, 0.4961, 0.4919,  ..., 0.4736, 0.4971, 0.5107], device='cuda:0',\n",
            "       dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0270, -0.0334,  0.1161,  ..., -0.0165, -0.0232, -0.0206],\n",
            "       device='cuda:0', dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-29, -16,  -5,  ...,  -8, -57,  15],\n",
            "            [-18, -19, -15,  ...,  36,   9,  44],\n",
            "            [-42,  -8,  36,  ..., -11,  18,  16],\n",
            "            ...,\n",
            "            [  1,  30,  29,  ..., -24,  -8,  19],\n",
            "            [ 17,   2,   8,  ...,  52,   5, -27],\n",
            "            [-88,  30,  14,  ...,  56, -38, -39]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0049, -0.0096, -0.0066,  ...,  0.0491, -0.0264, -0.0346],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 16,  79,  -4,  ...,  27, -44,  60],\n",
            "            [ 43,  17, -14,  ..., -56, -28, -20],\n",
            "            [-13, -24, -62,  ..., -11, -45, -37],\n",
            "            ...,\n",
            "            [-14,  15,  27,  ...,   8, -31, -46],\n",
            "            [ 31,   0,  14,  ...,  11,   4,   8],\n",
            "            [-36, -19,  -4,  ...,  -6, -13,   2]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0062,  0.0012, -0.0136,  ...,  0.3013, -0.3738, -0.1541],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 25,  69, -19,  ...,  67,   1,  50],\n",
            "            [-58, -20,  19,  ...,  -2,  76,  15],\n",
            "            [ 18,  19,   9,  ...,  -7,  50,  -4],\n",
            "            ...,\n",
            "            [-39,  -4,  15,  ...,   6, 107, -10],\n",
            "            [-25, -29, -42,  ..., -26,  54,  -3],\n",
            "            [ 19,  -3,  -8,  ...,  -8,  97,  26]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0002,  0.0005, -0.0061,  ...,  0.0033,  0.0012, -0.0031],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-35, -14, -23,  ...,  22,   6,   6],\n",
            "            [-30,  53,  28,  ..., -26, -18, -19],\n",
            "            [-64,  -4, -19,  ...,  58,  24,   6],\n",
            "            ...,\n",
            "            [-42,  37,  19,  ..., -35, -22,  66],\n",
            "            [-44,  73,  -4,  ...,  20, -55,  -8],\n",
            "            [ 22, -19,  77,  ..., -41, -32,  23]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0251,  0.0080, -0.0458,  ...,  0.0392,  0.0123, -0.0061],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-14,  -4,  -7,  ..., -37,  43,   6],\n",
            "            [-20, -11, -28,  ..., -26,  -8,   3],\n",
            "            [-14, -23, -31,  ...,   8,  33,   0],\n",
            "            ...,\n",
            "            [-54,  22, -40,  ...,   2,  29,   7],\n",
            "            [ 15,  46,  83,  ..., -19,  49, -13],\n",
            "            [ -1, -10,  -7,  ...,   2, -52,  67]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0183, -0.0136, -0.0282,  ..., -0.0114, -0.0182, -0.0282],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-50,   6, -20,  ...,  36,  -4,  -1],\n",
            "            [ 32,  -9, -39,  ..., -47,  -3, -17],\n",
            "            [-11, -24,  25,  ...,  -7,  11,   1],\n",
            "            ...,\n",
            "            [ -8,  11,   2,  ...,  -7,  -6,  -3],\n",
            "            [ 15,  10, -23,  ..., -16, -32,  21],\n",
            "            [-24, -12,  -3,  ..., -16,   7,   2]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0174, -0.0074,  0.0462,  ...,  0.0115, -0.0104, -0.0369],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "tensor([0.5112, 0.5200, 0.4910,  ..., 0.4983, 0.5273, 0.5435], device='cuda:0',\n",
            "       dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0174, -0.0238,  0.1125,  ..., -0.0140, -0.0161, -0.0125],\n",
            "       device='cuda:0', dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ -5,  53, -22,  ...,  -7,   3,  -4],\n",
            "            [  0,  11,  53,  ..., -28, -14,  17],\n",
            "            [ 10,  -7, -15,  ..., -35, -39,  46],\n",
            "            ...,\n",
            "            [  9,  37,  -2,  ..., -29,   7, -30],\n",
            "            [-41,  57,  26,  ..., -23,   0,  30],\n",
            "            [ -3,   0, -33,  ..., -35,  24,  47]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0081,  0.0111,  0.0015,  ...,  0.0602,  0.0552,  0.0002],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-50,   8,  37,  ...,  -4,  76, -43],\n",
            "            [ 49,  22, -23,  ...,  19, -22, -15],\n",
            "            [ -9,  50, -17,  ..., -45, -15,  74],\n",
            "            ...,\n",
            "            [-10,   3,  12,  ..., -30,  21,   2],\n",
            "            [ -2, -11,   5,  ...,  -2, -10,   0],\n",
            "            [ 21,  21, -15,  ...,  11,  22,  24]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0171, -0.0193, -0.0359,  ...,  1.0225,  1.7412, -0.1588],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[  8,   1, -14,  ..., -14, -18,  14],\n",
            "            [-26, -39, -19,  ..., -34,   1, -13],\n",
            "            [-10,  -6, -24,  ..., -21, -23,   8],\n",
            "            ...,\n",
            "            [  2, -64, -21,  ..., -71, -51, -23],\n",
            "            [ -3,  54,  -8,  ...,  57, -20,   7],\n",
            "            [-83, -79,   9,  ...,  16, -43,  19]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0019,  0.0002,  0.0006,  ..., -0.0002, -0.0029, -0.0025],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-13,  22, -12,  ..., -15,   2, -94],\n",
            "            [ -9,  35,  -7,  ..., -67,  24, -24],\n",
            "            [  8,  25,  12,  ...,  -5, -35, -15],\n",
            "            ...,\n",
            "            [  1,  -6, -16,  ...,   5,  25,  13],\n",
            "            [ 13, -20,   1,  ..., -64, -22, -30],\n",
            "            [-23,  -4, -42,  ..., -42,  42, -28]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0240, -0.0002, -0.0646,  ...,  0.0443, -0.0088, -0.0147],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 26,  -1,  -6,  ...,  -8, -39,   6],\n",
            "            [-33,  31, -67,  ...,  48, -31, -13],\n",
            "            [ 48, -26,  39,  ...,   3,  -2,  -4],\n",
            "            ...,\n",
            "            [-15,  37,  65,  ...,  11,  31,  39],\n",
            "            [-20, -35,  23,  ...,  14,  -8,  15],\n",
            "            [-33,  18, -96,  ..., -40,  18,   8]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0275, -0.0127,  0.0005,  ..., -0.0219,  0.0028,  0.0043],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ -8, -56,  -7,  ...,  13,  24,  10],\n",
            "            [-15, -18,   4,  ...,   0, -14,   9],\n",
            "            [ -5,  11, -46,  ...,  21, -41,  15],\n",
            "            ...,\n",
            "            [ 26,   6,  18,  ..., -13,   7,  17],\n",
            "            [-20,  23,   2,  ..., -25,  37,  17],\n",
            "            [ 74,  23,  18,  ..., -19,   4,   5]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0094,  0.0013,  0.0413,  ..., -0.0048, -0.0298, -0.0243],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "tensor([0.5264, 0.5371, 0.5205,  ..., 0.4990, 0.5410, 0.5654], device='cuda:0',\n",
            "       dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0242, -0.0344,  0.1235,  ..., -0.0200, -0.0275, -0.0226],\n",
            "       device='cuda:0', dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[  3, -21,  10,  ..., -33,   0, -10],\n",
            "            [-30,  21, -19,  ..., -22,  28, -19],\n",
            "            [ 77,  -8, -79,  ...,  55,  82,  19],\n",
            "            ...,\n",
            "            [-33, -16, -60,  ..., -19, -56, -45],\n",
            "            [ 13,   6,   8,  ..., -37,   5,  42],\n",
            "            [ -4,  55, -45,  ...,   9,  21,  71]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0058,  0.0040, -0.0010,  ...,  0.0087,  0.0045, -0.0118],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-78,  41,   7,  ..., -11,   7,  32],\n",
            "            [ 19, -22,  -6,  ...,   2,  52,  69],\n",
            "            [ -5,   4, -33,  ...,  -9, -34,   3],\n",
            "            ...,\n",
            "            [ 16,  61, -90,  ...,  42, -13,  21],\n",
            "            [-33,  17,  11,  ...,  10,  21, -25],\n",
            "            [-23,  -5, -46,  ..., -12,  19,  14]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0067, -0.0040, -0.0032,  ..., -0.0931,  0.0309,  0.0334],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[  4,  30, -13,  ..., -45,  12, -25],\n",
            "            [-73, -22, -19,  ..., -10,  -1, -21],\n",
            "            [ -7,  -4,  34,  ..., -24, -47,   0],\n",
            "            ...,\n",
            "            [-43, -10,   1,  ...,  15,  -3,  40],\n",
            "            [-23,  45,  19,  ...,  11,  -1,  31],\n",
            "            [ 17,  38,  24,  ..., -31,  10, -38]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([2.3689e-03, 2.0466e-03, 4.8280e-06,  ..., 3.3684e-03, 4.2892e-04,\n",
            "        1.4715e-03], device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-32,  10,  39,  ..., -46,  -1,   6],\n",
            "            [ -3,  26,   7,  ..., -10,  54,  40],\n",
            "            [-44,  22,  -8,  ..., -24, -28,  48],\n",
            "            ...,\n",
            "            [ 42, -16,  13,  ...,  38,  19,  24],\n",
            "            [-31,   4,  -9,  ...,  93,   4,  -1],\n",
            "            [-44,  -2, -20,  ..., -26, -29, -21]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0190, -0.0038, -0.0720,  ...,  0.0460,  0.0177, -0.0032],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-43,  18,   4,  ..., -14, -54,  72],\n",
            "            [-20, -14, -71,  ...,  19, -26,   9],\n",
            "            [ -9,  39,   1,  ..., -24,   5,  -4],\n",
            "            ...,\n",
            "            [-14,  -4,   2,  ...,  -5,  12,  26],\n",
            "            [ 72,  28,   3,  ..., -27,  17,  30],\n",
            "            [ 39,  20, -15,  ..., -64,  30, -35]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0359, -0.0172,  0.0053,  ..., -0.0074,  0.0099, -0.0054],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-15,  24,  -6,  ...,  -5, -26, -15],\n",
            "            [  6,  34, -28,  ...,  78, -15, -40],\n",
            "            [-21, -34,  15,  ..., -12,  -5, -30],\n",
            "            ...,\n",
            "            [ 32,  24,  20,  ...,  -9,  23,   4],\n",
            "            [-80, -20, -23,  ..., -21, -12, -36],\n",
            "            [ 27, -14,  -4,  ...,  21, -21,   5]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0044, -0.0035,  0.0583,  ...,  0.0017,  0.0029, -0.0083],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "tensor([0.5151, 0.5312, 0.5444,  ..., 0.4846, 0.5444, 0.5640], device='cuda:0',\n",
            "       dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0662, -0.0515,  0.1157,  ..., -0.0722, -0.1097, -0.1206],\n",
            "       device='cuda:0', dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 15,   4,   5,  ...,   3,  16,  -1],\n",
            "            [-11, -13,  15,  ...,   1, -19,  15],\n",
            "            [ -8,   1,  -7,  ...,  25,   6,  -7],\n",
            "            ...,\n",
            "            [-18,  15, -18,  ..., -20, -42,   3],\n",
            "            [  5,   8,  -7,  ...,   2, -21,   5],\n",
            "            [ 94, -41,   8,  ..., -31, -38,  -5]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0713,  0.0418,  0.0420,  ..., -0.0276, -0.1603, -0.0153],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 14, -16,  10,  ...,  -5, -33,  -2],\n",
            "            [-34, -21,  21,  ..., -19,  27, -16],\n",
            "            [ 28,  32,  37,  ...,  -4,  11,  -7],\n",
            "            ...,\n",
            "            [-10,   9, -20,  ...,  -3, -26, -27],\n",
            "            [  9,  -4,  17,  ...,  -9,   7,  -8],\n",
            "            [ 35,  -6,  -5,  ..., -29,  -6, -33]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([0.0331, 0.0480, 0.0573,  ..., 0.0268, 0.8477, 0.1139], device='cuda:0',\n",
            "       dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-16,  40,  27,  ..., -22,  20, -13],\n",
            "            [ -7,  74,   1,  ...,  58,   0,  -5],\n",
            "            [-25,  48, -36,  ...,  30, -52, -38],\n",
            "            ...,\n",
            "            [-53,  -7,  26,  ...,  -7, -14, -52],\n",
            "            [ 15, -23,  -8,  ..., -39, -23, -13],\n",
            "            [ 31, -11,  -9,  ..., -29,  -7,  25]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0012,  0.0004,  0.0017,  ...,  0.0041, -0.0060,  0.0030],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-18,  22,  -8,  ...,  -1, -21,  60],\n",
            "            [ 35,  52,  18,  ...,   7, -29,   4],\n",
            "            [ 33,  -4, -51,  ..., -39,  34, -41],\n",
            "            ...,\n",
            "            [-26,  43, -17,  ...,  54,  15,  19],\n",
            "            [-22, -10, -52,  ...,  52,   2,  -4],\n",
            "            [ 24,  30,  -8,  ..., -39,  33, -20]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0036,  0.0023, -0.0674,  ...,  0.0191,  0.0141, -0.0195],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 26, -35, -44,  ..., -42, -17,  14],\n",
            "            [ 30,  -5, -37,  ..., -40,  23, -25],\n",
            "            [-16,   5, -26,  ..., -31, -70, -12],\n",
            "            ...,\n",
            "            [-53, -29, -38,  ...,   3, -16,  -6],\n",
            "            [ -7,  -9, -26,  ...,  30,  11,  -2],\n",
            "            [ 18,  -5,   5,  ..., -15,  41,  26]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0168, -0.0161, -0.0093,  ..., -0.0259, -0.0116, -0.0055],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ -4,  12, -11,  ...,   1,  20,  10],\n",
            "            [ 32,   4,   5,  ...,  -9,  14, -52],\n",
            "            [  6,  11, -21,  ...,  28, -18, -25],\n",
            "            ...,\n",
            "            [  6,  -2,  19,  ...,   8,  13,   8],\n",
            "            [ 26,  15, -19,  ...,   8,  -6,  14],\n",
            "            [ 10,   8,  19,  ...,  12, -18,  27]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0061,  0.0027,  0.0692,  ...,  0.0158,  0.0001, -0.0463],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "tensor([0.5469, 0.5557, 0.5503,  ..., 0.4814, 0.5601, 0.5630], device='cuda:0',\n",
            "       dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0294, -0.0356,  0.1141,  ..., -0.0225, -0.0189, -0.0191],\n",
            "       device='cuda:0', dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ -1, -24,  -1,  ...,  52,  55, -36],\n",
            "            [ 26,  58,  66,  ...,  32, -27, -21],\n",
            "            [-26, -11,  42,  ...,  63,  11, 102],\n",
            "            ...,\n",
            "            [-21,  -1,  16,  ...,  55,  36,  40],\n",
            "            [  4, -33,  -3,  ...,  16,  16,   3],\n",
            "            [ 12,  81,  38,  ..., -40,  -2,  -8]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0022,  0.0116,  0.0150,  ...,  0.0171,  0.0032, -0.0004],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-38, -77,  14,  ..., -55,   0,  90],\n",
            "            [ 11, -15, -16,  ..., -60, -23, -26],\n",
            "            [ 19, -46,   1,  ..., -14, -15,  35],\n",
            "            ...,\n",
            "            [ 21,  28,   3,  ...,  32,   9, -51],\n",
            "            [ 58,  17,  -2,  ..., -18,  -1,   1],\n",
            "            [  0, -13, -20,  ..., -39, -11,  55]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0056, -0.0141, -0.0139,  ..., -0.2081,  0.1104, -0.0789],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 27,  -4,   8,  ...,   3,  11,  28],\n",
            "            [  6,  43,  27,  ..., -20, -20, -32],\n",
            "            [-80,  48,  16,  ...,   9,  10,  60],\n",
            "            ...,\n",
            "            [ 23,   4, -11,  ..., -27,  28, -40],\n",
            "            [ 13,  56,  17,  ...,  -3,  59,  32],\n",
            "            [  3,  53,  -2,  ..., -46, -22,   3]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0015,  0.0005,  0.0006,  ..., -0.0014, -0.0008, -0.0014],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 24, -29, -44,  ..., -23, -24,  43],\n",
            "            [-23,   8,  82,  ..., -35,  -2,  33],\n",
            "            [-24,  21,  -1,  ...,  -5,   0,   2],\n",
            "            ...,\n",
            "            [-16,  -8,  -8,  ..., -12,  -7,  55],\n",
            "            [ 28, -12,  52,  ..., -27,   1, -31],\n",
            "            [ 36, -34,  33,  ..., -59,  -2, -20]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 1.0078e-02, -6.9916e-05, -9.8938e-02,  ...,  4.0588e-02,\n",
            "        -1.1673e-02,  1.2074e-03], device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 71, -11, -15,  ...,  52,   2,  -2],\n",
            "            [ -5,  -5,  -1,  ...,  32, -46,  22],\n",
            "            [-40,  71,  20,  ...,  14, -32, -15],\n",
            "            ...,\n",
            "            [-18, -51,  27,  ..., -40, -47,  20],\n",
            "            [-17, -30, -14,  ..., -61, -38,  19],\n",
            "            [-48,   7, -36,  ..., -74,  -5,  41]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-2.3193e-02, -3.4760e-02, -1.7319e-02,  ..., -1.6663e-02,\n",
            "        -7.5877e-05, -3.5034e-02], device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 21, -15,  -9,  ...,  12, -13, -40],\n",
            "            [ 20,   2,   9,  ...,  36, -12,  53],\n",
            "            [ 11,   3,   5,  ...,   4,  16,   7],\n",
            "            ...,\n",
            "            [-19,  -6,  -3,  ...,  16,  -4, -10],\n",
            "            [ 48,   8, -17,  ...,  30, -29,   5],\n",
            "            [ -9,  -9,  21,  ...,  -4,  21,   5]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0195, -0.0298,  0.1044,  ...,  0.0280,  0.0282, -0.0365],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "tensor([0.5537, 0.5615, 0.5767,  ..., 0.4548, 0.5659, 0.5591], device='cuda:0',\n",
            "       dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0189, -0.0367,  0.1530,  ..., -0.0134, -0.0060, -0.0136],\n",
            "       device='cuda:0', dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 34,   7, -30,  ...,  -9, -55,  15],\n",
            "            [-13,  16,  -5,  ...,  -4,  -5, -29],\n",
            "            [ 22,  -8,   6,  ..., -17,  37, -55],\n",
            "            ...,\n",
            "            [ 13,  15, -18,  ..., -85,  -5, -43],\n",
            "            [  4,  -5,  -6,  ..., -78,  -5, -41],\n",
            "            [  7,   5, -21,  ..., -80,   0, -47]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0280, -0.0242,  0.0195,  ..., -0.0707, -0.0325, -0.0608],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[  6, -12, -35,  ...,   8,  43, -29],\n",
            "            [-25,  38, -50,  ...,   2, -12, -20],\n",
            "            [-17,  16,  38,  ..., -23,  22, -16],\n",
            "            ...,\n",
            "            [  5,   0,   4,  ...,   2,  -1,   4],\n",
            "            [ 10,  -8,   1,  ...,  -1,   6,   7],\n",
            "            [  0,   4,  12,  ...,   1,   1,   1]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 1.0290e-03, -7.3791e-05,  6.2675e-03,  ..., -1.3330e+00,\n",
            "        -6.2158e-01, -1.0225e+00], device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 17, -43,  -6,  ...,   7, 108, -76],\n",
            "            [-33, -12,  39,  ...,  38, -12,   2],\n",
            "            [-37, -61,  -5,  ...,   9,  38, -11],\n",
            "            ...,\n",
            "            [-10,   1,  -6,  ...,  17, -20,  38],\n",
            "            [-14,  28, -38,  ..., -11,  42,  -8],\n",
            "            [-43,  -2,   7,  ..., -10,  19, -17]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-6.0272e-04, -7.2181e-05,  8.9741e-04,  ..., -2.7204e-04,\n",
            "         3.2783e-04, -3.7074e-05], device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-42, -78,  -9,  ..., -11, -21, -32],\n",
            "            [ 15,  23,   0,  ...,  15,  29,  73],\n",
            "            [  9,  52,  -7,  ..., -21,  12,  29],\n",
            "            ...,\n",
            "            [ -2, -42, -12,  ...,  -2, -50, -17],\n",
            "            [-59, -37,  74,  ..., -18, -13,   6],\n",
            "            [-19, -24,  -5,  ...,  -1, -22,  24]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0092, -0.0228, -0.0704,  ...,  0.0194, -0.0532, -0.0037],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 12, -59, -20,  ...,  18,  33,  47],\n",
            "            [-19, -68,   6,  ...,   7,  24,  26],\n",
            "            [ -2,  29,  -4,  ...,   5,   9,   6],\n",
            "            ...,\n",
            "            [-58,   5,  -5,  ...,   8, -19, -16],\n",
            "            [  9,  54, -26,  ..., -15,  13,  -9],\n",
            "            [-49, -19, -14,  ..., -14, -29, -50]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0095, -0.0101, -0.0110,  ..., -0.0061,  0.0060, -0.0043],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ -5,  -3,   6,  ...,   9,  15,  30],\n",
            "            [ -2,  32,  -4,  ..., -15, -35,   6],\n",
            "            [ 17,   4, -19,  ...,   2,  26, -18],\n",
            "            ...,\n",
            "            [ -6, -27,  -9,  ...,   0,  -7,  -6],\n",
            "            [  2,  37,   8,  ...,  16, -39,  12],\n",
            "            [  2,  -4,  -1,  ...,  -3, -22, -11]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0322,  0.0006,  0.0816,  ..., -0.0012,  0.0018, -0.0859],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "tensor([0.5171, 0.4604, 0.5869,  ..., 1.2354, 0.5566, 0.6953], device='cuda:0',\n",
            "       dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.5830, -0.7422, -0.3333,  ..., -0.4463, -0.5610, -0.5410],\n",
            "       device='cuda:0', dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 19,   3,   5,  ..., -10,   0, -14],\n",
            "            [ 50, -11,  48,  ...,  10,  49, -28],\n",
            "            [-58,  12, -12,  ...,  13,  17,  62],\n",
            "            ...,\n",
            "            [ -5,   8,  -5,  ...,  47,  -3,  23],\n",
            "            [  8, -14,  12,  ..., -32,  14, -44],\n",
            "            [ -3,   0,  -7,  ...,  50,  -3,  26]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0154,  0.0055, -0.0118,  ...,  0.0761, -0.0358,  0.0478],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[  4,  -6,   4,  ...,  10,  18,   0],\n",
            "            [  8,  29,  -7,  ..., -17, -10,  -4],\n",
            "            [-27,  15,   0,  ...,   4,  26, -10],\n",
            "            ...,\n",
            "            [ -1,   0,  -1,  ...,   0,   1,  -1],\n",
            "            [  0,   1,   5,  ...,   0,   1,   2],\n",
            "            [  0,  -1,  -1,  ...,  -1,  -1,   0]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-2.8095e-03, -6.0730e-03, -4.0770e-04,  ...,  1.8555e+00,\n",
            "        -6.6504e-01,  1.3516e+00], device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-14, -35,  -3,  ..., -10,  39,   5],\n",
            "            [-32,  73,  32,  ...,   3, -64, -22],\n",
            "            [ 36, -32, -26,  ...,  12, -46,  20],\n",
            "            ...,\n",
            "            [ -3, -23,  37,  ..., -15,  62,  34],\n",
            "            [ 34,   9, -56,  ..., -22, -43,  14],\n",
            "            [-29,  53,  26,  ...,  -1,  73,  60]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 2.4605e-04, -5.7638e-05,  7.7200e-04,  ..., -1.9443e-04,\n",
            "        -4.0102e-04, -5.0354e-04], device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 40,  -7,  31,  ...,  -1,  22,  19],\n",
            "            [-19,   7, -48,  ..., -31, -23, -35],\n",
            "            [ -5,  69,   8,  ...,  10, -24,  48],\n",
            "            ...,\n",
            "            [ -1, -13,   8,  ...,   3, -59, -40],\n",
            "            [-23,  13, -22,  ...,  -6, -11,  40],\n",
            "            [ 32, -49,  -4,  ...,  11, -20,  15]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0007, -0.0060, -0.0281,  ...,  0.0326, -0.0261,  0.0015],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 64, -25, -27,  ...,  -5,  30,  -9],\n",
            "            [-51, -29,  22,  ...,  14,   8,   6],\n",
            "            [-23, -14, -32,  ...,  -5,  12, -12],\n",
            "            ...,\n",
            "            [ 39,  -8,  42,  ...,  -2,  38,  25],\n",
            "            [-51,   9, -24,  ..., -15,   6,  14],\n",
            "            [ -4, -19,  -3,  ..., -25, -10,  15]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0041, -0.0025, -0.0058,  ...,  0.0047,  0.0010,  0.0008],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-15,  36,  24,  ..., -44,  10, -15],\n",
            "            [-10,  14, -46,  ...,   9,   8,  23],\n",
            "            [ 11,  10, -12,  ...,  -9,   8, -33],\n",
            "            ...,\n",
            "            [-14, -40,  -9,  ...,  12,  -6, -12],\n",
            "            [-33, -37,   1,  ...,  12, -11,  27],\n",
            "            [ -6,   8,  -9,  ...,  16, -44, -36]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0250, -0.0088,  0.0503,  ...,  0.0091,  0.0423, -0.0527],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "tensor([0.5039, 0.4917, 0.5337,  ..., 1.0439, 0.4871, 0.5776], device='cuda:0',\n",
            "       dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.1458, -0.1716, -0.0774,  ..., -0.2529, -0.1372, -0.1197],\n",
            "       device='cuda:0', dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[  4,   0,   4,  ...,   1,   1,  -2],\n",
            "            [ 24, -15, -37,  ...,  22, -25,  10],\n",
            "            [-12, -12,   0,  ...,  -6, -20,   0],\n",
            "            ...,\n",
            "            [ -4,   3,   7,  ...,   0,  -1,  17],\n",
            "            [  6,  -4,  -9,  ...,   1,   2, -20],\n",
            "            [  4,  -3,  -7,  ...,   0,   1, -15]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0589, -0.0167,  0.0082,  ..., -0.0707,  0.0670,  0.0690],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ 44,  -3,  11,  ...,  66,   8, -23],\n",
            "            [ -2,  -8,  -5,  ...,  -2, -15, -11],\n",
            "            [ -3,   8, -20,  ...,  -8,  -4,  -3],\n",
            "            ...,\n",
            "            [  5,  15,   3,  ...,   7,   4,   5],\n",
            "            [ -5, -15,  -4,  ...,  -6,  -4,  -5],\n",
            "            [ -5, -15,  -2,  ...,  -7,  -4,  -5]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([-0.0376, -0.0465, -0.0056,  ..., -0.3926,  0.3521,  0.4011],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-21,  -3,  18,  ...,  58, -23,  -3],\n",
            "            [  1,  -4, -41,  ...,  24,   3, -13],\n",
            "            [ 45, -30,  36,  ...,   5,  74,  -7],\n",
            "            ...,\n",
            "            [ 40,  23,  -8,  ...,   9,   1,  31],\n",
            "            [ 10,  21, -76,  ...,   3,   1, -11],\n",
            "            [ 29,  22,  -7,  ..., -29,  20, -46]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 2.3823e-03, -2.6093e-03, -2.4376e-03,  ...,  2.3663e-05,\n",
            "        -9.3317e-04, -4.5300e-06], device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[-13,   1,  12,  ..., -26, -16,  31],\n",
            "            [-22,  -2,   3,  ..., -35, -39,  -8],\n",
            "            [-13, -42,  14,  ..., -21,   7,  22],\n",
            "            ...,\n",
            "            [ 27,  13, -19,  ...,  -4, -26,  17],\n",
            "            [ 23,  20,   4,  ...,  -4,  30,  -6],\n",
            "            [  0, -24,  18,  ...,  -6, -13,   3]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0032,  0.0005, -0.0264,  ...,  0.0139, -0.0339, -0.0049],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[ -7,  37,  -2,  ..., -12, -15, -17],\n",
            "            [-17,  60, -43,  ...,   1, -21, -49],\n",
            "            [ -1,  63,  30,  ...,  -6, -27,  -2],\n",
            "            ...,\n",
            "            [  6,  25,  -1,  ..., -38,  62, -34],\n",
            "            [ -2,  26,  40,  ..., -19,  -3,  15],\n",
            "            [ 46, -28, -18,  ..., -52, -39, -42]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0171, -0.0107, -0.0218,  ...,  0.0016,  0.0017,  0.0028],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "Parameter(Int8Params([[  0,   5,  -1,  ...,  -9,   6,   4],\n",
            "            [ 21,   4,  -7,  ...,   7,   3,  16],\n",
            "            [ -8,  19,  -6,  ...,  -2,  -9, -19],\n",
            "            ...,\n",
            "            [ 53, -22, -46,  ...,  32,   9,  -3],\n",
            "            [ 12,  -3,  -3,  ..., -12,  18,  -4],\n",
            "            [ 50, -36,  -3,  ...,  17, -38,  -5]], device='cuda:0',\n",
            "           dtype=torch.int8))\n",
            "Parameter containing:\n",
            "tensor([ 0.0009, -0.0168,  0.0076,  ..., -0.0131,  0.0164, -0.0091],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "Parameter containing:\n",
            "tensor([0.4692, 0.4309, 0.4402,  ..., 0.4702, 0.4026, 0.5635], device='cuda:0',\n",
            "       dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.1868, -0.2676, -0.1121,  ..., -0.2856, -0.0979, -0.2125],\n",
            "       device='cuda:0', dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([1.3301, 1.4346, 1.2207,  ..., 0.7881, 1.1143, 1.1895], device='cuda:0',\n",
            "       dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0117,  0.0499, -0.0923,  ...,  0.1569, -0.0720, -0.0215],\n",
            "       device='cuda:0', dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[ 0.0457,  0.0233,  0.0140,  ...,  0.0389,  0.0362,  0.0141],\n",
            "        [ 0.0039,  0.0307, -0.0015,  ...,  0.0143,  0.0643,  0.0245],\n",
            "        [ 0.0399,  0.0514, -0.0778,  ...,  0.0217, -0.0256,  0.0157],\n",
            "        ...,\n",
            "        [-0.0001, -0.0006, -0.0073,  ...,  0.0007, -0.0113, -0.0007],\n",
            "        [-0.0001, -0.0006, -0.0073,  ...,  0.0008, -0.0112, -0.0006],\n",
            "        [-0.0001, -0.0006, -0.0073,  ...,  0.0008, -0.0112, -0.0005]],\n",
            "       device='cuda:0', dtype=torch.float16, requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.0233,  0.1755,  0.0953,  ..., -0.1032, -0.1032, -0.1032],\n",
            "       device='cuda:0', dtype=torch.float16, requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "for p in teacher.parameters():\n",
        "    print(p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "W_wyjhmHV1v2"
      },
      "outputs": [],
      "source": [
        "teacher.eval()\n",
        "for p in teacher.parameters():\n",
        "    p.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKcADJNtV4DY",
        "outputId": "28a10aa7-de2e-412b-a820-36722d01a53d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
          ]
        }
      ],
      "source": [
        "student = AutoModelForCausalLM.from_pretrained(\n",
        "    student_id,\n",
        "    device_map=\"auto\",\n",
        "    load_in_8bit=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "gCdJ4VzMvPpm"
      },
      "outputs": [],
      "source": [
        "prompts = [\n",
        "    \"Explain why the sky is blue. ### The sky appears blue because molecules in Earth's atmosphere scatter sunlight, and blue light is scattered more than other colors due to its shorter wavelength.\",\n",
        "    \"What is the capital of France? ### The capital of France is Paris.\",\n",
        "    \"Write a short story about a robot and a cat. ### Once upon a time, a lonely robot found a stray cat. They became best friends, exploring the city together, and the robot learned the meaning of companionship.\"\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "6x-v_luBvQTa"
      },
      "outputs": [],
      "source": [
        "# ----- Distillation Hyperparams -----\n",
        "temperature = 2.0\n",
        "alpha_soft  = 0.7\n",
        "ce_loss     = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
        "kl_loss     = nn.KLDivLoss(reduction=\"batchmean\")\n",
        "optimizer   = optim.AdamW(student.parameters(), lr=2e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMFCntuivsUq",
        "outputId": "56ff1073-62c2-40be-b42a-6250ac165826"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt: Explain why the sky is blue. ### The sky..., Loss: nan\n",
            "Prompt: What is the capital of France? ### The c..., Loss: nan\n",
            "Prompt: Write a short story about a robot and a ..., Loss: nan\n"
          ]
        }
      ],
      "source": [
        "for prompt in prompts:\n",
        "    # --- Tokenize separately ---\n",
        "    t_inputs = teacher_tokenizer(prompt, return_tensors=\"pt\", padding=True).to(teacher.device)\n",
        "    s_inputs = student_tokenizer(prompt, return_tensors=\"pt\", padding=True).to(student.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        t_logits = teacher(**t_inputs).logits[:, :-1, :]\n",
        "        t_soft = torch.softmax(t_logits / temperature, dim=-1)\n",
        "        t_soft = torch.clamp(t_soft, min=1e-8)  # 🛠️ avoid log(0) in KLDiv\n",
        "\n",
        "    s_logits = student(**s_inputs).logits[:, :-1, :]\n",
        "    s_log_soft = torch.log_softmax(s_logits / temperature, dim=-1)\n",
        "\n",
        "    labels = s_inputs[\"input_ids\"][:, 1:].contiguous()\n",
        "\n",
        "    loss_hard = ce_loss(s_logits.reshape(-1, s_logits.size(-1)), labels.reshape(-1))\n",
        "    loss_soft = kl_loss(s_log_soft, t_soft) * (temperature ** 2)\n",
        "\n",
        "    loss = alpha_soft * loss_soft + (1 - alpha_soft) * loss_hard\n",
        "\n",
        "    if torch.isnan(loss):\n",
        "        print(\"⚠️ NaN detected on prompt:\", prompt[:50])\n",
        "        continue  # skip to next prompt\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f\"Prompt: {prompt[:40]}..., Loss: {loss.item():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FlWvohLw2Qj"
      },
      "outputs": [],
      "source": [
        "student.save_pretrained(\"distilled_phi1_5\")\n",
        "student_tokenizer.save_pretrained(\"distilled_phi1_5\")\n",
        "print(\"Distillation complete. Model saved in 'distilled_phi1_5/'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIylJOdKWYpq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyOdiUiGfMiuAdrasI4+bGEW",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0440c704c9804f97ab8689ce6a650308": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "071dcdea4d814305805b5924769f7903": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0baf82c3bb6a42a0a178a8eb6fdd4f4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "105b185aaa804a7aba4a1c441f64c11f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5029c89c804143efa74cb4bf95f4f379",
            "placeholder": "​",
            "style": "IPY_MODEL_77ff366eae15414d926c4647a62712ca",
            "value": "Map: 100%"
          }
        },
        "31877f5c2a3044cea968c0ed1a46aa9b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b735c50bb1a473b8d9ff7604c33939b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4dfbaf3ac8e84b8dae80028d5f7b2756": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4d5eaaa3b384bd5887a3077f8526d8f",
            "placeholder": "​",
            "style": "IPY_MODEL_0baf82c3bb6a42a0a178a8eb6fdd4f4a",
            "value": " 2/2 [00:27&lt;00:00, 11.70s/it]"
          }
        },
        "5029c89c804143efa74cb4bf95f4f379": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53230f4538e74920b57473a09898f9ff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bf295acb8ab4517aae191a49681cadc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65f08a7f4a18473eaf8d80b7c3ef013e",
            "max": 2000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f860cef2f6554f27ac59e2aa06b33872",
            "value": 2000
          }
        },
        "648579bc6bbe49e1b9b1a783b0dbd212": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65f08a7f4a18473eaf8d80b7c3ef013e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "707c6de352144b30a445edd786aa0be5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97d02b8f51cb4739aa9ce1a8e59441a4",
            "max": 157,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b09050601203426fa2d0ad5ffe49ebab",
            "value": 157
          }
        },
        "708f3c5f9e1446d4be67ce89bf4a08d7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7529b8ad8d8240678596d4aa1117eb6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_97b3001459ea46068195ef1a487dbb6a",
              "IPY_MODEL_8ea441ae61af4d8aae04493679a32061",
              "IPY_MODEL_4dfbaf3ac8e84b8dae80028d5f7b2756"
            ],
            "layout": "IPY_MODEL_648579bc6bbe49e1b9b1a783b0dbd212"
          }
        },
        "77ff366eae15414d926c4647a62712ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a760d525e3b443c949724ff5c75bb68": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a3b79955c5c4841b599811df227789e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c027b904a124d2badd7b308127142dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a3b79955c5c4841b599811df227789e",
            "placeholder": "​",
            "style": "IPY_MODEL_d7e4e24960be4bb4862d3529055c7d39",
            "value": " 2000/2000 [00:00&lt;00:00, 8381.31 examples/s]"
          }
        },
        "8ea441ae61af4d8aae04493679a32061": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53230f4538e74920b57473a09898f9ff",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9dca3fda68304bdab7af54cdf2c30b6f",
            "value": 2
          }
        },
        "97b3001459ea46068195ef1a487dbb6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a760d525e3b443c949724ff5c75bb68",
            "placeholder": "​",
            "style": "IPY_MODEL_071dcdea4d814305805b5924769f7903",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "97d02b8f51cb4739aa9ce1a8e59441a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9dca3fda68304bdab7af54cdf2c30b6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a1f5e69ece2d40e0b9b784701a1fad4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4e7e0c4350a448ca8015d14b8c17ea9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df0d001249cd4693b3dd7e61b1cdb21c",
              "IPY_MODEL_707c6de352144b30a445edd786aa0be5",
              "IPY_MODEL_d71dd1d8c66649e6943b4cdbe6e13f4b"
            ],
            "layout": "IPY_MODEL_4b735c50bb1a473b8d9ff7604c33939b"
          }
        },
        "b09050601203426fa2d0ad5ffe49ebab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b38abe0848384e629c89bfff7ed2c880": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_105b185aaa804a7aba4a1c441f64c11f",
              "IPY_MODEL_5bf295acb8ab4517aae191a49681cadc",
              "IPY_MODEL_8c027b904a124d2badd7b308127142dc"
            ],
            "layout": "IPY_MODEL_708f3c5f9e1446d4be67ce89bf4a08d7"
          }
        },
        "cc6d0f2d01d84783a4de9be9f44afbe6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4d5eaaa3b384bd5887a3077f8526d8f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d71dd1d8c66649e6943b4cdbe6e13f4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc6d0f2d01d84783a4de9be9f44afbe6",
            "placeholder": "​",
            "style": "IPY_MODEL_0440c704c9804f97ab8689ce6a650308",
            "value": " 157/157 [00:44&lt;00:00,  4.96it/s, loss=0.4200]"
          }
        },
        "d7e4e24960be4bb4862d3529055c7d39": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df0d001249cd4693b3dd7e61b1cdb21c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31877f5c2a3044cea968c0ed1a46aa9b",
            "placeholder": "​",
            "style": "IPY_MODEL_a1f5e69ece2d40e0b9b784701a1fad4e",
            "value": "Train: 100%"
          }
        },
        "f860cef2f6554f27ac59e2aa06b33872": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
