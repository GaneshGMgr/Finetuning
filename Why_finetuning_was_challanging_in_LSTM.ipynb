{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ip2j3In3yjUb"
      },
      "source": [
        "# Why Fine-tuning Was Not Possible in LSTM\n",
        "## Training\n",
        "This project attempts to fine-tune a sentiment classification model built with LSTM, and later repurpose it for a sequence-to-sequence task. However, several architectural and practical issues make this fine-tuning ineffective.\n",
        "\n",
        "## What This Notebook Does\n",
        "\n",
        "1. Trains an LSTM-based sentiment classifier using the IMDB dataset.\n",
        "2. Saves the trained model.\n",
        "3. Loads the model and attempts to fine-tune it on new data with a different vocabulary size.\n",
        "4. Tries to reuse the LSTM’s hidden states from the classifier as encoder states in a seq2seq architecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "SQf2rqDptOJl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "qElPEDVGyrs-"
      },
      "outputs": [],
      "source": [
        "max_len = 200\n",
        "vocab_size = 10000\n",
        "embedding_dim = 128\n",
        "latent_dim = 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "J6-GlVuHyr3g"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train), _ = tf.keras.datasets.imdb.load_data(num_words=vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCV3SkxBz_7r",
        "outputId": "8ef24cfd-35b1-457f-8a21-699e74b3a9ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(x_train)\n",
        "len(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "2iv5YndG0TZt"
      },
      "outputs": [],
      "source": [
        "x_train = x_train[:3000]\n",
        "y_train = y_train[:3000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Z2k3NO_0ZDP",
        "outputId": "bc0455bd-27f6-46fd-db22-d331a64131cf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(x_train)\n",
        "len(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "yHkaedfsz8Ev"
      },
      "outputs": [],
      "source": [
        "x_train = pad_sequences(x_train, maxlen=max_len, padding='post', truncating='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "CDD7GUoNyr6J"
      },
      "outputs": [],
      "source": [
        "input_layer = Input(shape=(max_len,))\n",
        "embedding_layer = Embedding(vocab_size, embedding_dim)(input_layer)\n",
        "lstm_layer, state_h, state_c = LSTM(latent_dim, return_state=True)(embedding_layer)\n",
        "output_layer = Dense(1, activation='sigmoid')(state_h)\n",
        "classification_model = Model(input_layer, output_layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfXjefP10m-_",
        "outputId": "c2b75c7b-2613-414e-94b9-77f46656e657"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<InputLayer name=input_layer_5, built=True>,\n",
              " <Embedding name=embedding_3, built=True>,\n",
              " <LSTM name=lstm_3, built=True>,\n",
              " <Dense name=dense_3, built=True>]"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classification_model.layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "A8RsBQPO0pqs",
        "outputId": "2eec5d1b-4f7f-4943-ab86-c812f487a7d8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_12\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_12\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,   │       <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │\n",
              "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]     │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_5 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m1,280,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,   │       \u001b[38;5;34m394,240\u001b[0m │\n",
              "│                                 │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]     │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m257\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,023,493</span> (19.16 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,023,493\u001b[0m (19.16 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,674,497</span> (6.39 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,674,497\u001b[0m (6.39 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,348,996</span> (12.78 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m3,348,996\u001b[0m (12.78 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "classification_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "vut9vsCrwpVg"
      },
      "outputs": [],
      "source": [
        "classification_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDofTrv0y21-",
        "outputId": "1cb7ee63-a736-4fc1-edc7-cc72098ada14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 1s/step - accuracy: 0.5011 - loss: 0.6942 - val_accuracy: 0.5180 - val_loss: 0.6926\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7de319237d50>"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classification_model.fit(x_train, y_train, batch_size=64, epochs=1, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0xvd6-6tjXp",
        "outputId": "b00805a8-12eb-4750-edf3-750c9a87d6c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357ms/step\n",
            "Predicted sentiment probability (positive): 0.4902157\n",
            "Predicted Sentiment: Negative 😞\n"
          ]
        }
      ],
      "source": [
        "sample_review = x_train[0].reshape(1, -1)  # 1 sample with shape (1, max_len)\n",
        "prediction = classification_model.predict(sample_review)\n",
        "\n",
        "print(\"Predicted sentiment probability (positive):\", prediction[0][0])\n",
        "print(\"Predicted Sentiment:\", \"Positive 😊\" if prediction[0][0] > 0.5 else \"Negative 😞\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3Hrb87Pv3GC",
        "outputId": "2941a229-cd41-4323-edd2-9f45bdfa9916"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "****Decoded Review:****\n",
            "<START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was\n"
          ]
        }
      ],
      "source": [
        "word_index = imdb.get_word_index()\n",
        "\n",
        "reverse_word_index = {index + 3: word for word, index in word_index.items()}\n",
        "\n",
        "reverse_word_index[0] = \"<PAD>\"\n",
        "reverse_word_index[1] = \"<START>\"\n",
        "reverse_word_index[2] = \"<UNK>\"\n",
        "reverse_word_index[3] = \"<UNUSED>\"\n",
        "# Step 3: Decode the review\n",
        "decoded_review = \" \".join([reverse_word_index.get(i, \"<UNK>\") for i in sample_review[0]])\n",
        "\n",
        "print(\"****Decoded Review:****\")\n",
        "print(decoded_review)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0u5N1_Stcp6",
        "outputId": "3158c586-2688-4d09-bab0-56bd32690cc8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "classification_model.save(\"lstm_imdb_model.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here, I take a small subset of 3000 samples and pad the sequences. I define a model like this:\n",
        "\n",
        "Embedding Layer\n",
        "\n",
        "LSTM Layer (with return_state=True)\n",
        "\n",
        "Dense Layer (for binary classification)\n",
        "\n",
        "I compile the model and train it for 1 epoch. This model outputs a sentiment (positive or negative). I save it as: `lstm_imdb_model.h5`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_j5RF-t1a8_"
      },
      "source": [
        "## Retraininig\n",
        "#### fine-tune the saved model `lstm_imdb_model.h5`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "SsRfI1gStRbb"
      },
      "outputs": [],
      "source": [
        "max_len = 200\n",
        "vocab_size = 1000\n",
        "embedding_dim = 128\n",
        "latent_dim = 256\n",
        "\n",
        "# Load IMDB dataset\n",
        "(x_train, y_train), _ = tf.keras.datasets.imdb.load_data(num_words=vocab_size)\n",
        "x_train = pad_sequences(x_train, maxlen=max_len, padding='post', truncating='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "INNfD0eF1rAl"
      },
      "outputs": [],
      "source": [
        "x_train = x_train[:1000]\n",
        "y_train = y_train[:1000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I load the IMDB data again using this new vocab size. I take a smaller sample of 1000 sequences. I load the previously saved model: `lstm_imdb_model.h5`\n",
        "Then I attempt to fine-tune this model by calling .fit() again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ym5i_3Hths2",
        "outputId": "4b1ebaf9-5991-43a3-a26c-7646e5f3be76"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "load_classification_model = load_model(\"lstm_imdb_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "uiRry9snttc8"
      },
      "outputs": [],
      "source": [
        "load_classification_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPUjl0Ptt1ML",
        "outputId": "1fb25676-e06c-440b-d45f-a313f464030e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 0.5386 - loss: 0.6876 - val_accuracy: 0.6000 - val_loss: 0.6835\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7de32eda6a90>"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "load_classification_model.fit(x_train, y_train, batch_size=64, epochs=1, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMB8rp3BwNEe",
        "outputId": "400da41d-93aa-4b6f-eebd-cc3c65c05d80"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "load_classification_model.save(\"lstm_imdb_model_updated.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7hwdnaH1zaa"
      },
      "source": [
        "## Retraining for Summarization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLMbcKgNwNMe",
        "outputId": "275feeda-b3db-4052-fe2a-284948bd577b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "updated_classification_model = load_model(\"lstm_imdb_model_updated.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "Dwn2PLpYrcl3"
      },
      "outputs": [],
      "source": [
        "encoder_inputs = Input(shape=(max_len,))\n",
        "encoder_embedding = updated_classification_model.layers[1](encoder_inputs)\n",
        "encoder_outputs, state_h, state_c = updated_classification_model.layers[2](encoder_embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "GvgxpJQbriY5"
      },
      "outputs": [],
      "source": [
        "output_vocab_size = 8000\n",
        "target_max_len = 50\n",
        "\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "decoder_embedding = Embedding(output_vocab_size, embedding_dim)(decoder_inputs)\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=[state_h, state_c])\n",
        "decoder_dense = Dense(output_vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "L0T48zu3rk4P"
      },
      "outputs": [],
      "source": [
        "seq2seq_model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "seq2seq_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "eXfnCeo0rm8w"
      },
      "outputs": [],
      "source": [
        "encoder_input_data = x_train[:1000]  # using IMDB input for now\n",
        "decoder_input_data = np.random.randint(1, output_vocab_size, (1000, target_max_len))\n",
        "decoder_target_data = np.random.randint(1, output_vocab_size, (1000, target_max_len, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qBxOw1CronF",
        "outputId": "e0686ef3-59f6-43b4-f691-360b33926861"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 2s/step - accuracy: 1.2756e-04 - loss: 8.9872 - val_accuracy: 0.0000e+00 - val_loss: 8.9875\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7de3310b3190>"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "seq2seq_model.fit(\n",
        "    [encoder_input_data, decoder_input_data],\n",
        "    decoder_target_data,\n",
        "    batch_size=32,\n",
        "    epochs=1,\n",
        "    validation_split=0.1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Why Fine-Tuning Fails\n",
        "\n",
        "### 1. Vocabulary Size Changed\n",
        "\n",
        "- Initially trained with `vocab_size = 10000`\n",
        "- Later fine-tuned with `vocab_size = 1000`\n",
        "\n",
        "The Embedding layer was trained to handle 10,000 tokens. When using only 1,000 tokens during fine-tuning, the token indices refer to **different words**, and the embedding layer now receives **incorrect word meanings**. This leads to corrupted input representations.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. Token-to-Word Mapping Is Inconsistent\n",
        "\n",
        "Even if token IDs are reused, their meanings change when the vocabulary size is reduced. For example:\n",
        "\n",
        "- In the 10,000-word vocab: token 500 = “great”\n",
        "- In the 1,000-word vocab: token 500 = “boring”\n",
        "\n",
        "This breaks the embedding layer, which relies on consistent token mappings.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. Using Classifier LSTM State in a Decoder\n",
        "\n",
        "The model extracts the hidden state from a classifier LSTM:\n",
        "\n",
        "```python\n",
        "encoder_outputs, state_h, state_c = classification_model.layers[2](embedding_output)\n",
        "```\n",
        "\n",
        "These states are passed into a new decoder LSTM for sequence generation. But this LSTM was **trained to classify sentiment**, not to encode full language meaning. Its hidden states are not meaningful for generation tasks.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. No Joint Training of Encoder-Decoder\n",
        "\n",
        "In proper seq2seq architectures, the encoder and decoder are trained together, so the encoder learns to output useful representations for the decoder. Here, the decoder is randomly initialized and receives context from a classifier encoder — making the setup incompatible.\n",
        "\n",
        "---\n",
        "\n",
        "### 5. No Freezing or Layer Control During Fine-Tuning\n",
        "\n",
        "The model is fine-tuned without freezing layers:\n",
        "\n",
        "```python\n",
        "load_classification_model.fit(...)\n",
        "```\n",
        "\n",
        "All weights are updated using a new dataset with a different vocabulary and different mappings. This causes **catastrophic forgetting**, where the model loses what it learned in the initial training.\n",
        "\n",
        "---\n",
        "\n",
        "## Summary of Why Fine-Tuning Fails\n",
        "\n",
        "| Problem                         | Why It Breaks Fine-Tuning                                          |\n",
        "|---------------------------------|---------------------------------------------------------------------|\n",
        "| Vocabulary size changed         | Embedding layer mismatches the token IDs                           |\n",
        "| Token mapping changed           | Same IDs now represent different words                             |\n",
        "| Classification LSTM used as encoder | Hidden states not suitable for generation                        |\n",
        "| No attention mechanism          | LSTM lacks ability to model long-term dependencies                 |\n",
        "| No layer freezing               | Entire model updates and forgets previous learning                 |\n",
        "\n",
        "---\n",
        "\n",
        "## How to Fix It\n",
        "\n",
        "To make fine-tuning work properly:\n",
        "\n",
        "1. Use the **same vocabulary size** across training and fine-tuning (e.g., always `vocab_size = 10000`)\n",
        "2. Reuse the **same tokenizer and word index**.\n",
        "3. **Freeze the embedding and LSTM layers** when fine-tuning to prevent forgetting.\n",
        "4. If using for generation, train the **encoder and decoder together**.\n",
        "5. Consider using **transformer-based models** (like BERT, GPT, or T5) for more effective transfer learning and modularity.\n",
        "\n",
        "---\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "Fine-tuning is technically possible in LSTMs, but **difficult to get right** due to tight coupling of components, lack of pretraining, and sensitivity to data shifts. Modern architectures like Transformers are better suited for robust fine-tuning and transfer learning.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sxk_LEQ2yOBJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
